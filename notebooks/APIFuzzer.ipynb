{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Fuzzing APIs\n",
    "\n",
    "So far, we have always generated _system input_, i.e. data that the program as a whole obtains via its input channels.  However, we can also generate input that goes directly into individual functions, gaining flexibility and speed in the process.  In this chapter, we explore the use of grammars to synthesize code for function calls, which allows you to generate _program code that very efficiently invokes functions directly._  On top, we also explore how such API grammars can be synthesized from existing executions; this means that we can _synthesize API tests without having to write a grammar at all._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Prerequisites**\n",
    "\n",
    "* You have to know how grammar fuzzing work, e.g. from the [chapter on grammars](Grammars.ipynb).\n",
    "* To synthesize API grammars, we make use of [recorded (\"carved\") function calls](Carver.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    },
    "toc-hr-collapsed": false
   },
   "source": [
    "## Fuzzing a Function\n",
    "\n",
    "Let us start with our first problem: How do we fuzz a given function?  For an interpreted language like Python, this pretty straight-forward.  All we need to do is to generate _calls_ to the function(s) we want to test.  This is something we can easily do with a grammar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Testing a URL Parser\n",
    "\n",
    "As an example, consider the `urlparse()` function from the Python library.  `urlparse()` takes a URL and decomposes it into its individual components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import fuzzingbook_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlparse('https://www.fuzzingbook.com/html/APIFuzzer.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see how the individual elements of the URL – the _scheme_ (`\"http\"`), the _network location_ (`\"www.fuzzingbook.com\"`), or the path (`\"//html/APIFuzzer.html\"`) are all properly identified.  Other elements (like `params`, `query`, or `fragment`) are empty, because they were not part of our input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test `urlparse()`, we'd want to feed it a large set of different URLs.  We can obtain these from the URL grammar we had defined in the [\"Grammars\"](Grammars.ipynb) chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Grammars import URL_GRAMMAR, is_valid_grammar, START_SYMBOL, new_symbol\n",
    "from GrammarFuzzer import GrammarFuzzer, display_tree, all_terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_fuzzer = GrammarFuzzer(URL_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    url = url_fuzzer.fuzz()\n",
    "    print(urlparse(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, we can easily test any Python function – by setting up a scaffold that runs it.  How would we proceed, though, if we wanted to have a test that can be re-run again and again, without having to generate new calls every time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthesizing Code\n",
    "\n",
    "The \"scaffolding\" method, as sketched above, has an important downside: It couples test generation and test execution into a single unit, disallowing running both at different times, or for different languages.  To decouple the two, we take another approach: Rather than generating inputs and immediately feeding this input into a function, we _synthesize code_ instead that invokes functions with a given input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, if we generate the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call = \"urlparse('http://www.example.com/')\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can execute this string as a whole (and thus run the test) at any time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To systematically generate such calls, we can again use a grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPARSE_GRAMMAR = {\n",
    "    \"<call>\":\n",
    "        ['urlparse(\"<url>\")']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This grammar creates calls in the form `urlparse(<url>)`, where `<url>` is yet to be defined; the idea is to create many of these calls and to feed them into the Python interpreter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us add definitions for `<url>` from the previously defined URL grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPARSE_GRAMMAR.update(URL_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPARSE_GRAMMAR[\"<start>\"] = [\"<call>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_valid_grammar(URLPARSE_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPARSE_GRAMMAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this grammar for fuzzing and synthesizing calls to `urlparse)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlparse_fuzzer = GrammarFuzzer(URLPARSE_GRAMMAR)\n",
    "urlparse_fuzzer.fuzz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as above, we can immediately execute these calls.  To better see what is happening, we define a small helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function_name(arg[0], arg[1], ...) as a string\n",
    "def do_call(call_string):\n",
    "    print(call_string)\n",
    "    result = eval(call_string)\n",
    "    print(\"\\t= \" + repr(result))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call = urlparse_fuzzer.fuzz()\n",
    "do_call(call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `urlparse()` were a C function, for instance, we could embed its call into some (also generated) C function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPARSE_C_GRAMMAR = {\n",
    "    \"<cfile>\": [\"<cheader><cfunction>\"],\n",
    "    \"<cheader>\": ['#include \"urlparse.h\"\\n\\n'],\n",
    "    \"<cfunction>\": [\"void test() {\\n<calls>}\\n\"],\n",
    "    \"<calls>\": [\"<call>\", \"<calls><call>\"],\n",
    "    \"<call>\": ['    urlparse(\"<url>\");\\n']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPARSE_C_GRAMMAR.update(URL_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPARSE_C_GRAMMAR[\"<start>\"] = [\"<cfile>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_valid_grammar(URLPARSE_C_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlparse_fuzzer = GrammarFuzzer(URLPARSE_C_GRAMMAR)\n",
    "print(urlparse_fuzzer.fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that both the Python as well as the C variant only check for _generic_ errors in `urlparse()`; that is, they only detect fatal errors and exceptions.  To also check the _result_ of `urlparse()`, see the [exercise on synthesizing oracles](#Exercise-1:-Synthesizing-Oracles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthesizing Data\n",
    "\n",
    "For `urlparse()`, we have used a very specific grammar that would be useful for this function only.\n",
    "\\todo{Complete}\n",
    "\\todo{Introduce generators and constraints first?}\n",
    "\n",
    "#### Integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Grammars import convert_ebnf_grammar, crange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ProbabilisticGrammarFuzzer import ProbabilisticGrammarFuzzer, opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INT_EBNF_GRAMMAR = {\n",
    "    \"<start>\": [\"<int>\"],\n",
    "    \"<int>\": [\"<sign>?<leaddigit><digit>*\"],\n",
    "    \"<sign>\": [\"+\", \"-\"],\n",
    "    \"<leaddigit>\": crange('1', '9'),\n",
    "    \"<digit>\": crange('0', '9')\n",
    "}\n",
    "\n",
    "assert is_valid_grammar(INT_EBNF_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INT_GRAMMAR = convert_ebnf_grammar(INT_EBNF_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_fuzzer = GrammarFuzzer(INT_GRAMMAR)\n",
    "print([int_fuzzer.fuzz() for i in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOAT_EBNF_GRAMMAR = {\n",
    "    \"<start>\": [\"<float>\"],\n",
    "    \"<float>\": [\"<int>(.<digit>+)?<exp>?\", \"inf\", \"NaN\"],\n",
    "    \"<exp>\": [\"e<int>\"]\n",
    "}\n",
    "FLOAT_EBNF_GRAMMAR.update(INT_EBNF_GRAMMAR)\n",
    "FLOAT_EBNF_GRAMMAR[\"<start>\"] = [\"<float>\"]\n",
    "\n",
    "assert is_valid_grammar(FLOAT_EBNF_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOAT_GRAMMAR = convert_ebnf_grammar(FLOAT_EBNF_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_fuzzer = GrammarFuzzer(FLOAT_GRAMMAR)\n",
    "print([float_fuzzer.fuzz() for i in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASCII_STRING_EBNF_GRAMMAR = {\n",
    "    \"<start>\": [\"<ascii-string>\"],\n",
    "    \"<ascii-string>\": ['\"<ascii-chars>\"'],\n",
    "    \"<ascii-chars>\": [\n",
    "        (\"\", opts(prob=0.05)),\n",
    "        \"<ascii-chars><ascii-char>\"\n",
    "    ],\n",
    "    \"<ascii-char>\": crange(\" \", \"!\") + [r'\\\"'] + crange(\"#\", \"~\")\n",
    "}\n",
    "\n",
    "assert is_valid_grammar(ASCII_STRING_EBNF_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASCII_STRING_GRAMMAR = convert_ebnf_grammar(ASCII_STRING_EBNF_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_fuzzer = ProbabilisticGrammarFuzzer(ASCII_STRING_GRAMMAR)\n",
    "print([string_fuzzer.fuzz() for i in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_EBNF_GRAMMAR = {\n",
    "    \"<start>\": [\"<list>\"],\n",
    "    \"<list>\": [\n",
    "        (\"[]\", opts(prob=0.05)),\n",
    "        \"[<list-objects>]\"\n",
    "    ],\n",
    "    \"<list-objects>\": [\n",
    "        (\"<list-object>\", opts(prob=0.2)),\n",
    "        \"<list-object>, <list-objects>\"\n",
    "    ],\n",
    "    \"<list-object>\": [\"0\"],\n",
    "}\n",
    "\n",
    "assert is_valid_grammar(LIST_EBNF_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_GRAMMAR = convert_ebnf_grammar(LIST_EBNF_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_list_grammar = copy.deepcopy(LIST_GRAMMAR)\n",
    "int_list_grammar.update(INT_GRAMMAR)\n",
    "int_list_grammar[\"<start>\"] = [\"<list>\"]\n",
    "int_list_grammar[\"<list-object>\"] = [\"<int>\"]\n",
    "assert is_valid_grammar(int_list_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_list_fuzzer = ProbabilisticGrammarFuzzer(int_list_grammar)\n",
    "[int_list_fuzzer.fuzz() for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Mining API Grammars\n",
    "\n",
    "While it is relatively straightforward to write a grammar that produces a sequence of function calls, we can again try to automate this further by automatically _mining_ function calls from a given execution of a program.  To this end, we make use of [our _carving_ infrastructure introduced in the previous chapter](Carver.ipynb) to _record_ function calls and their arguments, from which we can create a grammar that can then combine arbitrary arguments into new calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general idea is as follows:\n",
    "\n",
    "1. First, we record all calls of a specific function from a given execution of the program.\n",
    "2. Second, we create a grammar that incorporates all these calls, with separate rules for each argument and alternatives for each value found; this allows us to produce calls that arbitrarily _recombine_ these arguments.\n",
    "\n",
    "Let us explore these steps in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Calls to Grammars\n",
    "\n",
    "Let us start with an example.  The `power(x, y)` function returns $x^y$; it is but a wrapper around the equivalent `math.pow()` function.  (Since `power()` is defined in Python, we can trace it – in contrast to `math.pow()`, which is implemented in C.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power(x, y):\n",
    "    return math.pow(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us invoke `power()` while recording its arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Carver import CallCarver, call_value, call_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with CallCarver() as power_carver:\n",
    "    z = power(1, 2)\n",
    "    z = power(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_carver.arguments(\"power\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this list of recorded arguments, we could now create a grammar for the `power()` call, with `x` and `y` expanding into the values seen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POWER_GRAMMAR = {\n",
    "    \"<start>\": [\"power(<x>, <y>)\"],\n",
    "    \"<x>\": [\"1\", \"3\"],\n",
    "    \"<y>\": [\"2\", \"4\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_valid_grammar(POWER_GRAMMAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When fuzzing with this grammar, we then get arbitrary combinations of `x` and `y`; aiming for coverage will ensure that all values are actually tested at least once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GrammarCoverageFuzzer import GrammarCoverageFuzzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_fuzzer = GrammarCoverageFuzzer(POWER_GRAMMAR)\n",
    "[power_fuzzer.fuzz() for i in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need is a method to automatically convert the arguments as seen in `power_carver` to the grammar as seen in `POWER_GRAMMAR`.  This is what we define in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Grammar Miner for Calls\n",
    "\n",
    "We introduce a class `CallGrammarMiner`, which, given a `Carver`, automatically produces a grammar from the calls seen.  To initialize, we pass the carver object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallGrammarMiner(object):\n",
    "    def __init__(self, carver, log=False):\n",
    "        self.carver = carver\n",
    "        self.log = log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Grammar\n",
    "\n",
    "The initial grammar produces a single call.  The possible `<call>` expansions are to be constructed later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallGrammarMiner(CallGrammarMiner):\n",
    "    CALL_SYMBOL = \"<call>\"\n",
    "\n",
    "    def initial_grammar(self):\n",
    "        return copy.deepcopy(\n",
    "            {START_SYMBOL: [self.CALL_SYMBOL],\n",
    "                self.CALL_SYMBOL: []\n",
    "             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CallGrammarMiner(power_carver)\n",
    "initial_grammar = m.initial_grammar()\n",
    "initial_grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Grammar from Arguments\n",
    "\n",
    "Let us start by creating a grammar from a list of arguments.  The method `mine_arguments_grammar()` creates a grammar for the arguments seen during carving, such as these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = power_carver.arguments(\"power\")\n",
    "arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mine_arguments_grammar()` method iterates through the variables seen and creates a mapping `variables` of variable names to a set of values seen (as strings, going through `call_value()`).  In a second step, it then creates a grammar with a rule for each variable name, expanding into the values seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallGrammarMiner(CallGrammarMiner):\n",
    "    def var_symbol(self, function_name, var, grammar):\n",
    "        return new_symbol(grammar, \"<\" + function_name + \"-\" + var + \">\")\n",
    "\n",
    "    def mine_arguments_grammar(self, function_name, arguments, grammar):\n",
    "        var_grammar = {}\n",
    "\n",
    "        variables = {}\n",
    "        for argument_list in arguments:\n",
    "            for (var, value) in argument_list:\n",
    "                value_string = call_value(value)\n",
    "                if self.log:\n",
    "                    print(var, \"=\", value_string)\n",
    "\n",
    "                if value_string.find(\"<\") >= 0:\n",
    "                    var_grammar[\"<langle>\"] = [\"<\"]\n",
    "                    value_string = value_string.replace(\"<\", \"<langle>\")\n",
    "\n",
    "                if var not in variables:\n",
    "                    variables[var] = set()\n",
    "                variables[var].add(value_string)\n",
    "\n",
    "        var_symbols = []\n",
    "        for var in variables:\n",
    "            var_symbol = self.var_symbol(function_name, var, grammar)\n",
    "            var_symbols.append(var_symbol)\n",
    "            var_grammar[var_symbol] = list(variables[var])\n",
    "\n",
    "        return var_grammar, var_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CallGrammarMiner(power_carver)\n",
    "var_grammar, var_symbols = m.mine_arguments_grammar(\n",
    "    \"power\", arguments, initial_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The additional return value `var_symbols` is a list of argument symbols in the call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Grammar from Calls\n",
    "\n",
    "To get the grammar for a single function (`mine_function_grammar()`), we add a call to the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallGrammarMiner(CallGrammarMiner):\n",
    "    def function_symbol(self, function_name, grammar):\n",
    "        return new_symbol(grammar, \"<\" + function_name + \">\")\n",
    "\n",
    "    def mine_function_grammar(self, function_name, grammar):\n",
    "        arguments = self.carver.arguments(function_name)\n",
    "\n",
    "        if self.log:\n",
    "            print(function_name, arguments)\n",
    "\n",
    "        var_grammar, var_symbols = self.mine_arguments_grammar(\n",
    "            function_name, arguments, grammar)\n",
    "\n",
    "        function_grammar = var_grammar\n",
    "        function_symbol = self.function_symbol(function_name, grammar)\n",
    "\n",
    "        if len(var_symbols) > 0 and var_symbols[0].find(\"-self\") >= 0:\n",
    "            # Method call\n",
    "            function_grammar[function_symbol] = [\n",
    "                var_symbols[0] + \".\" + function_name + \"(\" + \", \".join(var_symbols[1:]) + \")\"]\n",
    "        else:\n",
    "            function_grammar[function_symbol] = [\n",
    "                function_name + \"(\" + \", \".join(var_symbols) + \")\"]\n",
    "\n",
    "        if self.log:\n",
    "            print(function_symbol, \"::=\", function_grammar[function_symbol])\n",
    "\n",
    "        return function_grammar, function_symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CallGrammarMiner(power_carver)\n",
    "function_grammar, function_symbol = m.mine_function_grammar(\n",
    "    \"power\", initial_grammar)\n",
    "function_grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The additionally returned `function_symbol` holds the name of the function call just added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Grammar from all Calls\n",
    "\n",
    "Let us now repeat the above for all function calls seen during carving.  To this end, we simply iterate over all function calls seen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_carver.called_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallGrammarMiner(CallGrammarMiner):\n",
    "    def mine_call_grammar(self, function_list=None, qualified=False):\n",
    "        grammar = self.initial_grammar()\n",
    "        fn_list = function_list\n",
    "        if function_list is None:\n",
    "            fn_list = self.carver.called_functions(qualified=qualified)\n",
    "\n",
    "        for function_name in fn_list:\n",
    "            if function_list is None and (function_name.startswith(\"_\") or function_name.startswith(\"<\")):\n",
    "                continue  # Internal function\n",
    "\n",
    "            # Ignore errors with mined functions\n",
    "            try:\n",
    "                function_grammar, function_symbol = self.mine_function_grammar(\n",
    "                    function_name, grammar)\n",
    "            except:\n",
    "                if function_list is not None:\n",
    "                    raise\n",
    "\n",
    "            if function_symbol not in grammar[self.CALL_SYMBOL]:\n",
    "                grammar[self.CALL_SYMBOL].append(function_symbol)\n",
    "            grammar.update(function_grammar)\n",
    "\n",
    "        assert is_valid_grammar(grammar)\n",
    "        return grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `mine_call_grammar()` is the one that clients can and should use – first for mining..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CallGrammarMiner(power_carver)\n",
    "power_grammar = m.mine_call_grammar()\n",
    "power_grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and then for fuzzing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_fuzzer = GrammarCoverageFuzzer(power_grammar)\n",
    "[power_fuzzer.fuzz() for i in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we have successfully extracted a grammar from a recorded execution; in contrast to \"simple\" carving, our grammar allows us to _recombine_ arguments and thus to fuzz at the API level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzing Web Functions\n",
    "\n",
    "Let us now apply our grammar miner on a larger API – the `urlparse` API we already encountered during carving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Carver import webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with CallCarver() as webbrowser_carver:\n",
    "    webbrowser(\"https://www.fuzzingbook.org\")\n",
    "    webbrowser(\"http://www.example.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can mine a grammar from the calls encountered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CallGrammarMiner(webbrowser_carver)\n",
    "webbrowser_grammar = m.mine_call_grammar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a rather large grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(webbrowser_grammar['<call>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the rule for the `urlsplit()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser_grammar[\"<urlsplit>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the arguments.  Note that although we only passed `http://www.fuzzingbook.org` as a parameter, we also see the `https:` variant.  That is because opening the `http:` URL automatically redirects to the `https:` URL, which is then also processed by `urlsplit()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser_grammar[\"<urlsplit-url>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There also is some variation in the `scheme` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser_grammar[\"<urlsplit-scheme>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now apply a fuzzer on these rules, we systematically cover all variations of arguments seen, including, of course, combinations not seen during carving.  Again, we are fuzzing at the API level here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlsplit_fuzzer = GrammarCoverageFuzzer(\n",
    "    webbrowser_grammar, start_symbol=\"<urlsplit>\")\n",
    "for i in range(5):\n",
    "    print(urlsplit_fuzzer.fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just [as seen with carving](Carver.ipynb), running tests at the API level is orders of magnitude faster than executing system tests.  Hence, this calls for means to fuzz at the method level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlsplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Timer import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as urlsplit_timer:\n",
    "    urlsplit('http://www.fuzzingbook.org/', 'http', True)\n",
    "urlsplit_timer.elapsed_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as webbrowser_timer:\n",
    "    webbrowser(\"http://www.fuzzingbook.org\")\n",
    "webbrowser_timer.elapsed_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser_timer.elapsed_time() / urlsplit_timer.elapsed_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But then again, the caveats encountered during carving apply, notably the requirement to recreate the original function environment.  If we also alter or recombine arguments, we get the additional risk of _violating an implicit precondition_ – that is, invoking a function with arguments the function was never designed for.  Such _false alarms_, resulting from incorrect invocations rather than incorrect implementations, must then be identified (typically manually) and wed out (for instance, by altering or constraining the grammar).  The huge speed gains at the API level, however, may well justify this additional investment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Lessons Learned\n",
    "\n",
    "* To fuzz individual functions, one can easily set up grammars that produce function calls.\n",
    "* Such grammars can also be mined (carved) from given executions.\n",
    "* Fuzzing at the API level can be much faster than fuzzing at the system level, but brings the risk of false alarms by violating implicit preconditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "To extend the techniques just introduced, you can\n",
    "\n",
    "* [use _search-based testing_ to guide test generation towards specific goals](SearchBasedFuzzer.ipynb)\n",
    "* [use _constraints_ (i.e., a specification of the input format) to get even more valid inputs](ConstraintGrammarFuzzer.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "The combination of carving and fuzzing at the API level was first conducted by Alexander Kampmann in his PhD work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercises\n",
    "\n",
    "The exercises for this chapter combine the above techniques with fuzzing techniques introduced earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Exercise 1: Covering Argument Combinations\n",
    "\n",
    "In the chapter on [configuration testing](ConfigurationFuzzer.ipynb), we also discussed _combinatorial testing_ – that is, systematic coverage of _sets_ of configuration elements.  Implement a scheme that by changing the grammar, allows all _pairs_ of argument values to be covered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** Left to the reader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Exercise 2: Mutating Arguments\n",
    "\n",
    "To widen the range of arguments to be used during testing, apply the _mutation schemes_ introduced in [mutation fuzzing](MutationFuzzer.ipynb) – for instance, flip individual bytes or delete characters from strings.  Apply this either during grammar inference or as a separate step when invoking functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** Left to the reader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Exercise 3: Abstracting Arguments\n",
    "\n",
    "Set up an abstraction scheme to widen the range of arguments to be used during testing.  If the values for an argument, all conform to some type `T`. abstract it into `<T>`.  For instance, if calls to `foo(1)`, `foo(2)`, `foo(3)` have been seen, the grammar should abstract its calls into `foo(<int>)`, with `<int>` being appropriately defined.\n",
    "\n",
    "Do this for a number of common types: integers, positive numbers, floating-point numbers, host names, URLs, mail addresses, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** Left to the reader."
   ]
  }
 ],
 "metadata": {
  "ipub": {
   "bibliography": "fuzzingbook.bib",
   "toc": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
