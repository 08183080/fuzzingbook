{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Fuzzing APIs\n",
    "\n",
    "So far, we have always generated _system input_, i.e. data that the program as a whole obtains via its input channels.  However, we can also generate input that goes directly into individual functions, gaining flexibility and speed in the process.  In this chapter, we explore the use of grammars to synthesize code for function calls, which allows you to generate _program code that very efficiently invokes functions directly._  On top, we also explore how such API grammars can be synthesized from existing executions; this means that we can _synthesize API tests without having to write a grammar at all._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzingbook_utils import YouTubeVideo\n",
    "YouTubeVideo(\"w4u5gCgPlmg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Prerequisites**\n",
    "\n",
    "* You have to know how grammar fuzzing work, e.g. from the [chapter on grammars](Grammars.ipynb).\n",
    "* To synthesize API grammars, we make use of [recorded (\"carved\") function calls](Carver.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Fuzzing a Function\n",
    "\n",
    "Let us start with our first problem: How do we fuzz a given function?  For an interpreted language like Python, this pretty straight-forward.  All we need to do is to generate _calls_ to the function(s) we want to test.  This is something we can easily do with a grammar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Testing a URL Parser\n",
    "\n",
    "As an example, consider the `urlparse()` function from the Python library.  `urlparse()` takes a URL and decomposes it into its individual components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import fuzzingbook_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlparse('https://www.fuzzingbook.com/html/APIFuzzer.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see how the individual elements of the URL – the _scheme_ (`\"http\"`), the _network location_ (`\"www.fuzzingbook.com\"`), or the path (`\"//html/APIFuzzer.html\"`) are all properly identified.  Other elements (like `params`, `query`, or `fragment`) are empty, because they were not part of our input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test `urlparse()`, we'd want to feed it a large set of different URLs.  We can obtain these from the URL grammar we had defined in the [\"Grammars\"](Grammars.ipynb) chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Grammars import URL_GRAMMAR, is_valid_grammar\n",
    "from GrammarFuzzer import GrammarFuzzer, display_tree, all_terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_fuzzer = GrammarFuzzer(URL_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    url = url_fuzzer.fuzz()\n",
    "    print(urlparse(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, we can easily test any Python function – by setting up a scaffold that runs it.  How would we proceed, though, if we wanted to have a test that can be re-run again and again, without having to generate new calls every time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthesizing Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"scaffolding\" method, as sketched above, has an important downside: It couples test generation and test execution into a single unit, disallowing running both at different times, or for different languages.  To decouple the two, we take another approach: Rather than generating inputs and immediately feeding this input into a function, we _synthesize code_ instead that invokes functions with a given input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, if we generate the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call = \"urlparse('http://www.example.com/')\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can execute this string as a whole (and thus run the test) at any time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To systematically generate such calls, we can again use a grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPARSE_GRAMMAR = {\n",
    "    \"<call>\":\n",
    "        ['urlparse(\"<url>\")']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This grammar creates calls in the form `urlparse(<url>)`, where `<url>` is yet to be defined; the idea is to create many of these calls and to feed them into the Python interpreter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us add definitions for `<url>` from the previously defined URL grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPARSE_GRAMMAR.update(URL_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPARSE_GRAMMAR[\"<start>\"] = [\"<call>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_valid_grammar(URLPARSE_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPARSE_GRAMMAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this grammar for fuzzing and synthesizing calls to `urlparse)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlparse_fuzzer = GrammarFuzzer(URLPARSE_GRAMMAR)\n",
    "urlparse_fuzzer.fuzz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as above, we can immediately execute these calls.  To better see what is happening, we define a small helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function_name(arg[0], arg[1], ...) as a string\n",
    "def do_call(call_string):\n",
    "    print(call_string)\n",
    "    result = eval(call_string)\n",
    "    print(\"\\t= \" + repr(result))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call = urlparse_fuzzer.fuzz()\n",
    "do_call(call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `urlparse()` were a C function, for instance, we could embed its call into some (also generated) C function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPARSE_C_GRAMMAR = {\n",
    "    \"<cfile>\": [\"<cheader><cfunction>\"],\n",
    "    \"<cheader>\": ['#include \"urlparse.h\"\\n\\n'],\n",
    "    \"<cfunction>\": [\"void test() {\\n<calls>}\\n\"],\n",
    "    \"<calls>\": [\"<call>\", \"<calls><call>\"],\n",
    "    \"<call>\": ['    urlparse(\"<url>\");\\n']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPARSE_C_GRAMMAR.update(URL_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPARSE_C_GRAMMAR[\"<start>\"] = [\"<cfile>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert is_valid_grammar(URLPARSE_C_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlparse_fuzzer = GrammarFuzzer(URLPARSE_C_GRAMMAR)\n",
    "print(urlparse_fuzzer.fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that both the Python as well as the C variant only check for _generic_ errors in `urlparse()`; that is, they only detect fatal errors and exceptions.  To also check the _result_ of `urlparse()`, see the [exercise on synthesizing oracles](#Exercise-1:-Synthesizing-Oracles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Carving Function Calls\n",
    "\n",
    "Let us now try to _record_ and _replay_ calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return function_name(arg[0], arg[1], ...) as a string\n",
    "def call_with_args(function_name, args):\n",
    "    return function_name + \"(\" + \\\n",
    "        \", \".join([var + \"=\" + repr(value) for (var, value) in args]) + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_with_args(\"urlparse\", [(\"url\", \"http://example.com\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a tracer to capture all calls and arguments.  \\todo{Make this a `Carver` class.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where we store all calls and arguments\n",
    "the_args = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracking function: Record all calls and all args\n",
    "def traceit(frame, event, arg):\n",
    "    if event == \"call\":\n",
    "        code = frame.f_code\n",
    "        function_name = code.co_name\n",
    "\n",
    "        if function_name.startswith('_'):\n",
    "            return None  # Internal function\n",
    "\n",
    "        # When called, all arguments are local variables\n",
    "        variables = frame.f_locals.keys()\n",
    "        args = [(var, frame.f_locals[var]) for var in variables]\n",
    "\n",
    "        if function_name not in the_args:\n",
    "            the_args[function_name] = []\n",
    "        if args not in the_args[function_name]:\n",
    "            the_args[function_name].append(args)\n",
    "\n",
    "        # Some tracking\n",
    "        # print(call_with_args(function_name, args))\n",
    "\n",
    "    # If we return None, this will only be called for functions (more\n",
    "    # efficient)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record all function calls during an execution\n",
    "def power(x, y):\n",
    "    return math.pow(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerpair(pair):\n",
    "    return power(pair[0], pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_calls():\n",
    "    global the_args\n",
    "    the_args = {}\n",
    "\n",
    "    urls = [\n",
    "        \"https://andreas:zeller@cispa.saarland:8080/faculty/q?=zeller\",\n",
    "        \"http://fuzzingbook.com/fuzzing\",\n",
    "        \"http://google.com/query\",\n",
    "        \"http://microsoft.com/windows\",\n",
    "        \"https://mark:zuckerberg@facebook.com:666/friends\"\n",
    "    ]\n",
    "\n",
    "    sys.settrace(traceit)\n",
    "\n",
    "    for n in range(0, 10):\n",
    "        x = power(n, n)\n",
    "        x = powerpair((n, n))\n",
    "\n",
    "    for url in urls:\n",
    "        parts = urlparse(url)\n",
    "        url = urlunparse(parts)\n",
    "\n",
    "    sys.settrace(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_calls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run all calls seen, invoking functions directly\n",
    "def run_calls():\n",
    "    for function_name in the_args.keys():\n",
    "        if function_name.startswith(\"_\") or function_name.startswith(\"<\"):\n",
    "            continue        # Internal call\n",
    "\n",
    "        for args in the_args[function_name]:\n",
    "            call_string = call_with_args(function_name, args)\n",
    "            do_call(call_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_calls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can also first fuzz a program with a grammar, record the API calls and replay them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Mining a Grammar\n",
    "\n",
    "Let us bring together the fuzzing and carving techniques and mine a function call grammar from API invocations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a variable name into a grammar nonterminal\n",
    "def nonterminal(var):\n",
    "    return \"<\" + var.lower() + \">\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def mine_grammar_from_calls():\n",
    "    all_calls = \"<call>\"\n",
    "    grammar = {\n",
    "        \"<start>\": [all_calls],\n",
    "    }\n",
    "\n",
    "    function_nonterminals = []\n",
    "    for function_name in the_args.keys():\n",
    "        if function_name.startswith(\"_\") or function_name.startswith(\"<\"):\n",
    "            # Internal function\n",
    "            continue\n",
    "\n",
    "        nonterminal_name = nonterminal(function_name)\n",
    "        function_nonterminals.append(nonterminal_name)\n",
    "\n",
    "        # Add a rule for the function\n",
    "        expansion = function_name + \"(\"\n",
    "        first_arg = True\n",
    "        for (var, _) in the_args[function_name][0]:\n",
    "            arg_name = nonterminal(function_name + \"_\" + var)\n",
    "            if not first_arg:\n",
    "                expansion += \", \"\n",
    "            first_arg = False\n",
    "            expansion += var + \"=\" + arg_name\n",
    "        expansion += \")\"\n",
    "        # TODO: Handle polymorphic functions\n",
    "        grammar[nonterminal_name] = [expansion]\n",
    "\n",
    "        # Add rules for the arguments\n",
    "        values = {}\n",
    "        for args in the_args[function_name]:\n",
    "            for (var, value) in args:\n",
    "                if var not in values:\n",
    "                    values[var] = []\n",
    "                if value not in values[var]:\n",
    "                    values[var].append(value)\n",
    "        g = value_rules(values, function_name)\n",
    "        grammrs = merge_grammars(grammar, g)\n",
    "\n",
    "    # Add a rule for all calls\n",
    "    grammar[all_calls] = function_nonterminals\n",
    "\n",
    "    return grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge two grammars G1 and G2\n",
    "def merge_grammars(g1, g2):\n",
    "    merged_grammar = g1\n",
    "    for key2 in g2.keys():\n",
    "        repl2 = g2[key2]\n",
    "        key_found = False\n",
    "        for key1 in g1.keys():\n",
    "            repl1 = g1[key1]\n",
    "            for repl in repl2:\n",
    "                if key1 == key2:\n",
    "                    key_found = True\n",
    "                    if repl not in repl1:\n",
    "                        # Extend existing rule\n",
    "                        merged_grammar[key1] = repl1 + [repl]\n",
    "\n",
    "        if not key_found:\n",
    "            # Add new rule\n",
    "            merged_grammar[key2] = repl2\n",
    "    return merged_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEEP_VALUES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a grammar only for the values in VALUES\n",
    "def value_rules(values, prefix):\n",
    "    grammar = {}\n",
    "    for var in values.keys():\n",
    "        arg_name = nonterminal(prefix + \"_\" + var)\n",
    "        if DEEP_VALUES:\n",
    "            for value in values[var]:\n",
    "                g = deep_value_expansions(arg_name, value)\n",
    "                grammar = merge_grammars(grammar, g)\n",
    "        else:\n",
    "            expansions = [repr(value) for value in values[var]]\n",
    "            grammar[arg_name] = expansions\n",
    "\n",
    "    return grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_grammar = mine_grammar_from_calls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlunsplit_fuzzer = GrammarFuzzer(api_grammar, start_symbol='<urlunsplit>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    do_call(urlunsplit_fuzzer.fuzz())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlunparse_fuzzer = GrammarFuzzer(api_grammar, start_symbol='<urlunparse>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    do_call(urlunparse_fuzzer.fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can thus extract a grammar from a module simply by tracking its calls.\n",
    "\n",
    "\\todo{Combine this with grammars at the system level!}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-primitive values need special handling in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand a structured value into individual grammar rules\n",
    "def deep_value_expansions(prefix, value):\n",
    "    # print(\"Expanding\", prefix, \"=\", repr(value))\n",
    "\n",
    "    grammar = {}\n",
    "\n",
    "    attributes = value_attributes(value)\n",
    "    if attributes is not None:\n",
    "        # A class or named tuple\n",
    "        attr_names = []\n",
    "        for attribute in attributes:\n",
    "            if attribute.startswith(\"_\"):\n",
    "                # Internal attribute\n",
    "                continue\n",
    "            attr_name = prefix + \"_\" + attribute.upper()\n",
    "            attr_names.append((attribute, attr_name))\n",
    "            g = deep_value_expansions(attr_name, getattr(value, attribute))\n",
    "            grammar = merge_grammars(grammar, g)\n",
    "\n",
    "        expansion = value.__class__.__name__ + \"(\"\n",
    "        first_attribute = True\n",
    "        for (attribute, attr_name) in attr_names:\n",
    "            if not first_attribute:\n",
    "                expansion += \", \"\n",
    "            first_attribute = False\n",
    "            expansion += attribute + \" = \" + attr_name\n",
    "        expansion += \")\"\n",
    "        grammar[prefix] = [expansion]\n",
    "\n",
    "    elif isinstance(value, type(())):\n",
    "        # A tuple\n",
    "        field_names = []\n",
    "        for index in range(0, len(value)):\n",
    "            field_name = prefix + \"_\" + repr(index)\n",
    "            field_names.append(field_name)\n",
    "            g = deep_value_expansions(field_name, value[index])\n",
    "            grammar = merge_grammars(grammar, g)\n",
    "\n",
    "        grammar[prefix] = [\"(\" + \", \".join(field_names) + \")\"]\n",
    "\n",
    "    else:\n",
    "        # Can only expand to value\n",
    "        grammar[prefix] = [repr(value)]\n",
    "\n",
    "    # print(\"Expanded:\", grammar_to_string(grammar))\n",
    "    return grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Lessons Learned\n",
    "\n",
    "* _Lesson one_\n",
    "* _Lesson two_\n",
    "* _Lesson three_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "_Link to subsequent chapters (notebooks) here, as in:_\n",
    "\n",
    "* [use _mutations_ on existing inputs to get more valid inputs](MutationFuzzer.ipynb)\n",
    "* [use _grammars_ (i.e., a specification of the input format) to get even more valid inputs](Grammars.ipynb)\n",
    "* [reduce _failing inputs_ for efficient debugging](Reducer.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "_Cite relevant works in the literature and put them into context, as in:_\n",
    "\n",
    "The idea of ensuring that each expansion in the grammar is used at least once goes back to Burkhardt \\cite{Burkhardt1967}, to be later rediscovered by Paul Purdom \\cite{Purdom1972}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercises\n",
    "\n",
    "_Close the chapter with a few exercises such that people have things to do.  To make the solutions hidden (to be revealed by the user), have them start with_\n",
    "\n",
    "```markdown\n",
    "**Solution.**\n",
    "```\n",
    "\n",
    "_Your solution can then extend up to the next title (i.e., any markdown cell starting with `#`)._\n",
    "\n",
    "_Running `make metadata` will automatically add metadata to the cells such that the cells will be hidden by default, and can be uncovered by the user.  The button will be introduced above the solution._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Exercise 1: Synthesizing Oracles\n",
    "\n",
    "The tests we generate for `urlparse()` only check if `urlparse()` fails as a whole (i.e. crashes or raises an exception).  Set up a testing framework that ensures that the elements originally created (i.e., `scheme`, `path`, etc.) also occur in the result.  Here's an example of a test that you could synthesize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "result = urlparse(\"https://www.fuzzingbook.org\")\n",
    "assert result.scheme == \"https\"\n",
    "assert result.netloc == \"www.fuzzingbook.org\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, you cannot generate such tests via grammars alone (at least not via a context-free grammar, as we use them).  However, you can make use of the [derivation tree](GrammarFuzzer.ipynb) from which the input is created.  As a first step, after creating the input, access its derivation tree via the `derivation_tree` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlparse_fuzzer = GrammarFuzzer(URLPARSE_GRAMMAR)\n",
    "call = urlparse_fuzzer.fuzz()\n",
    "call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_tree = urlparse_fuzzer.derivation_tree\n",
    "display_tree(call_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a second step, write a function `get_element()` that extracts individual elements from that tree (by symbol name):\n",
    "\n",
    "```python\n",
    "assert get_element(call_tree, \"<scheme>\") == \"http\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use both the generated input as well as extracted elements to create assertions for `urlparse()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** This is pretty straightforward if you have read the [chapter on efficient grammar fuzzing](GrammarFuzzer.ipynb).  First, we define a function that extracts a symbol expansion from the derivation tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_element(tree, name):\n",
    "    \"\"\"Return definition of `name` in `tree` as a string\"\"\"\n",
    "    (symbol, children) = tree\n",
    "    if symbol == name:\n",
    "        return all_terminals(tree)\n",
    "    for c in children:\n",
    "        result = get_element(c, name)\n",
    "        if result is not None:\n",
    "            return result\n",
    "    return None  # Not Found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_element(call_tree, \"<scheme>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_element(call_tree, \"<host>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can easily extract the elements to be referenced in the oracle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "test = \"\"\n",
    "for i in range(10):\n",
    "    call = urlparse_fuzzer.fuzz()\n",
    "    tree = urlparse_fuzzer.derivation_tree\n",
    "    test += \"result = \" + call + \"\\n\"\n",
    "    test += \"assert result.scheme == \" + \\\n",
    "        repr(get_element(tree, \"<scheme>\")) + \"\\n\"\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we execute (i.e. run) these tests, it turns out they all pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "You can do similar things for other attributes (e.g. `netloc`, `query`, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution": "hidden",
    "solution2": "hidden",
    "solution2_first": true,
    "solution_first": true
   },
   "source": [
    "### Exercise 2: _Title_\n",
    "\n",
    "_Text of the exercise_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "solution": "hidden",
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** _Solution for the exercise_"
   ]
  }
 ],
 "metadata": {
  "ipub": {
   "bibliography": "fuzzingbook.bib",
   "toc": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
