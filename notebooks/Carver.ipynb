{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Carving Unit Tests\n",
    "\n",
    "So far, we have always generated _system input_, i.e. data that the program as a whole obtains via its input channels.  If we are interested in testing only a small set of functions, having to go through the system can be very inefficient.  This chapter introduces a technique known as _carving_, which, given a system test, automatically extracts a set of _unit tests_ that replicate the calls seen during the unit test.  The key idea is to _record_ such calls such that we can _replay_ them later – as a whole or selectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzingbook_utils import YouTubeVideo\n",
    "YouTubeVideo(\"Ty0ktPXJ23c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Prerequisites**\n",
    "\n",
    "* Carving makes use of dynamic traces of function calls and variables, as introduced in the [chapter on configuration fuzzing](ConfigurationFuzzer.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## System Tests vs Unit Tests\n",
    "\n",
    "Remember the URL grammar introduced for [grammar fuzzing](Grammars.ipynb)?  With such a grammar, we can happily test a Web browser again and again, checking how it reacts to arbitrary page requests.\n",
    "\n",
    "Let us define a very simple \"web browser\" that goes and downloads the content given by the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse, urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webbrowser(url):\n",
    "    \"\"\"Download the http/https resource given by the URL\"\"\"\n",
    "    response = urllib.request.urlopen(url)\n",
    "    if response.getcode() == 200:\n",
    "        contents = response.read()\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us apply this on [fuzzingboook.org](https://www.fuzzingbook.org/) and measure the time, using the [Timer class](Timer.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Timer import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as webbrowser_timer:\n",
    "    fuzzingbook_contents = webbrowser(\"http://www.fuzzingbook.org/html/Fuzzer.html\")\n",
    "\n",
    "print(\"Downloaded %d bytes in %.2f seconds\" % (len(fuzzingbook_contents), webbrowser_timer.elapsed_time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzingbook_contents[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having to start a whole browser (or having it render a Web page) again and again means lots of overhead, though – in particular if we want to test only a subset of its functionality.  In particular, after a change in the code, we would prefer to test only the subset of functions that is affected by the change, rather than running the well-tested functions again and again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let us assume we change the function that takes care of parsing the given URL and decomposing it into the individual elements – the scheme (\"http\"), the network location (`\"www.fuzzingbook.com\"`), or the path (`\"/html/Fuzzer.html\"`).  This function is named `urlparse()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlparse('https://www.fuzzingbook.com/html/APIFuzzer.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see how the individual elements of the URL – the _scheme_ (`\"http\"`), the _network location_ (`\"www.fuzzingbook.com\"`), or the path (`\"//html/APIFuzzer.html\"`) are all properly identified.  Other elements (like `params`, `query`, or `fragment`) are empty, because they were not part of our input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interesting thing is that executing only `urlparse()` is orders of magnitude faster than running all of `webbrowser()`.  Let us measure the factor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 1000\n",
    "with Timer() as urlparse_timer:\n",
    "    for i in range(runs):\n",
    "        urlparse('https://www.fuzzingbook.com/html/APIFuzzer.html')\n",
    "\n",
    "avg_urlparse_time = urlparse_timer.elapsed_time() / 1000\n",
    "avg_urlparse_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to the time required by the webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser_timer.elapsed_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in time is huge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser_timer.elapsed_time() / avg_urlparse_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, in the time it takes to run `webbrowser()` once, we can have _hundreds of thousands_ of executions of `urlparse()` – and this does not even take into account the time it takes the browser to render the downloaded HTML, to run the included scripts, and whatever else happens when a Web page is loaded.  Hence, strategies that allow us to test at the _unit_ level are very promising as they can save lots of overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carving Unit Tests\n",
    "\n",
    "Testing methods and functions at the unit level requires a very good understanding of the individual units to be tested as well as their interplay with other units.  Setting up an appropriate infrastructure and writing unit tests by hand thus is demanding, yet rewarding.  There is, however, an interesting alternative to writing unit tests by hand.  The technique of _carving_ automatically _converts system tests into unit tests_ by means of recording and replaying function calls:\n",
    "\n",
    "1. During a system test (given or generated), we _record_ all calls into a function, including all arguments and other variables the function reads.\n",
    "2. From these, we synthesize a self-contained _unit test_ that reconstructs the function call with all arguments.\n",
    "3. This unit test can be executed (replayed) at any time with high efficiency.\n",
    "\n",
    "Let us explore these three steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Recording Calls\n",
    "\n",
    "Our first challenge is to record function calls together with their arguments.  (In the interest of simplicity, we restrict ourself to arguments, ignoring any global variables or other non-arguments that are read by the function.)  To record calls and arguments, we use the mechanism [we introduced for coverage](Coverage.ipynb): By setting up a tracer function, we track all calls into individual functions, also saving their arguments.  Just like `Coverage` objects, we want to use `Carver` objects to be able to be used in conjunction with the `with` statement, such that we can trace a particular code block:\n",
    "\n",
    "```python\n",
    "with Carver() as carver:\n",
    "    function_to_be_traced()\n",
    "c = carver.calls()\n",
    "```\n",
    "\n",
    "The initial definition supports this construct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Carver(object):\n",
    "    def __init__(self):\n",
    "        self._calls = {}\n",
    "\n",
    "    # Start of `with` block\n",
    "    def __enter__(self):\n",
    "        self.original_trace_function = sys.gettrace()\n",
    "        sys.settrace(self.traceit)\n",
    "        return self\n",
    "\n",
    "    # End of `with` block\n",
    "    def __exit__(self, exc_type, exc_value, tb):\n",
    "        sys.settrace(self.original_trace_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual work takes place in the `traceit()` method, which records all calls in the `_calls` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qualified_name(code):\n",
    "    name = code.co_name\n",
    "    module = inspect.getmodule(code)\n",
    "    if module is not None:\n",
    "        name = module.__name__ + \".\" + name\n",
    "    return name\n",
    "\n",
    "class Carver(Carver):\n",
    "    # Tracking function: Record all calls and all args\n",
    "    def traceit(self, frame, event, arg):\n",
    "        if event != \"call\":\n",
    "            return None\n",
    "        \n",
    "        code = frame.f_code\n",
    "        function_name = qualified_name(code)\n",
    "\n",
    "        # When called, all arguments are local variables\n",
    "        arguments = [(var, frame.f_locals[var]) for var in frame.f_locals]\n",
    "        arguments.reverse()  # Want same order as call\n",
    "\n",
    "        if function_name not in self._calls:\n",
    "            self._calls[function_name] = []\n",
    "        if arguments not in self._calls[function_name]:\n",
    "            self._calls[function_name].append(arguments)\n",
    "\n",
    "        # Some tracking\n",
    "        # print(call_with_args(function_name, args))\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need some convenience functions to access the calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Carver(Carver):\n",
    "    def calls(self):\n",
    "        \"\"\"Return a dictionary of all calls traced.\"\"\"  \n",
    "        return self._calls\n",
    "    \n",
    "    def arguments(self, function_name):\n",
    "        \"\"\"Return a list of all arguments of the given function\n",
    "        as (VAR, VALUE) pairs.\n",
    "        Raises an exception if the function was not traced.\"\"\"\n",
    "        return self._calls[function_name]\n",
    "    \n",
    "    def called_functions(self):\n",
    "        \"\"\"Return all functions called.\"\"\"\n",
    "        return self._calls.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how these work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recording my_sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out our new `Carver` class – first on a very simple function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Intro_Testing import my_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Carver() as sqrt_carver:\n",
    "    my_sqrt(2)\n",
    "    my_sqrt(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve all calls seen..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_carver.calls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... as well as the arguments of a particular function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_carver.arguments(\"my_sqrt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a convenience function for nicer printing of these lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return function_name(arg[0], arg[1], ...) as a string\n",
    "def call_with_args(function_name, argument_list):\n",
    "    return function_name + \"(\" + \\\n",
    "        \", \".join([var + \"=\" + repr(value) for (var, value) in argument_list]) + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for function_name in sqrt_carver.called_functions():\n",
    "    for argument_list in sqrt_carver.arguments(function_name):\n",
    "        print(call_with_args(function_name, argument_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a syntax we can directly use to invoke `my_sqrt()` again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(\"my_sqrt(x=2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carving urlparse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we apply this to `webbrowser()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Carver() as webbrowser_carver:\n",
    "    webbrowser(\"http://www.example.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that retrieving a URL from the Web requires quite some functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser_carver.called_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among several other functions, we also have a call to `urlparse()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlparse_argument_list = webbrowser_carver.arguments(\"urllib.parse.urlparse\")\n",
    "urlparse_argument_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can convert this into a well-formatted call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlparse_call = call_with_args(\"urlparse\", urlparse_argument_list[0])\n",
    "urlparse_call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can re-execute this call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(urlparse_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have successfully carved the call to `urlparse()` out of the `webbrowser()` execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replaying Calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replaying calls in their entirety and in all generality is tricky, as there are several challenges to be addressed.  These include:\n",
    "\n",
    "1. We need to be able to _access_ individual functions.  If we access a function by name, the name must be in scope.  If the name is not visible (for instance, because it is a name internal to the module), we must make it visible.\n",
    "\n",
    "2. Any resources accessed outside of arguments must be recorded and reconstructed for replay as well.  This can be difficult if variables refer to external resources such as files or network resources.\n",
    "\n",
    "3. Complex objects must be reconstructed as well.  This can be difficult if they provide no means to do so.\n",
    "\n",
    "These constraints make carving hard if the function to be tested interacts heavily with its environment.  In this section, we provide some mechanisms to make carving possible even under difficult circumstances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate these issues, consider the `email.parser.parse()` method that is invoked in `webbrowser()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_parse_argument_list = webbrowser_carver.arguments(\"email.parser.parse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calls to this method look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_parse_call = call_with_args(\"email.parser.parse\", email_parse_argument_list[0])\n",
    "email_parse_call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `email.parser.parse()` is part of a `email.parser.Parser` object and it gets a `StringIO` object.  Both are non-primitive values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser_object = email_parse_argument_list[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled = pickle.dumps(parser_object)\n",
    "pickled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_with_pickled_args(function_name, argument_list):\n",
    "    return function_name + \"(\" + \\\n",
    "        \", \".join([var + \"=pickle.loads(\" + repr(pickle.dumps(value)) + \")\" for (var, value) in argument_list]) + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call = call_with_pickled_args(\"email.parser.parse\", email_parse_argument_list[0])\n",
    "print(call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pickle.loads(b'\\x80\\x03cemail.parser\\nParser\\nq\\x00)\\x81q\\x01}q\\x02(X\\x06\\x00\\x00\\x00_classq\\x03chttp.client\\nHTTPMessage\\nq\\x04X\\x06\\x00\\x00\\x00policyq\\x05cemail._policybase\\nCompat32\\nq\\x06)\\x81q\\x07ub.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "obj.parse(io.StringIO(\"foo\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Lessons Learned\n",
    "\n",
    "* _Lesson one_\n",
    "* _Lesson two_\n",
    "* _Lesson three_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "Traditionally, tests at the unit level are written by humans just as production code is.  Since this book is about generating software tests, we also [cover techniques that generate unit tests](APIFuzzer.ipynb).\n",
    "\n",
    "_Link to subsequent chapters (notebooks) here, as in:_\n",
    "\n",
    "* [use _mutations_ on existing inputs to get more valid inputs](MutationFuzzer.ipynb)\n",
    "* [use _grammars_ (i.e., a specification of the input format) to get even more valid inputs](Grammars.ipynb)\n",
    "* [reduce _failing inputs_ for efficient debugging](Reducer.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "_Cite relevant works in the literature and put them into context, as in:_\n",
    "\n",
    "The idea of ensuring that each expansion in the grammar is used at least once goes back to Burkhardt \\cite{Burkhardt1967}, to be later rediscovered by Paul Purdom \\cite{Purdom1972}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercises\n",
    "\n",
    "_Close the chapter with a few exercises such that people have things to do.  To make the solutions hidden (to be revealed by the user), have them start with_\n",
    "\n",
    "```markdown\n",
    "**Solution.**\n",
    "```\n",
    "\n",
    "_Your solution can then extend up to the next title (i.e., any markdown cell starting with `#`)._\n",
    "\n",
    "_Running `make metadata` will automatically add metadata to the cells such that the cells will be hidden by default, and can be uncovered by the user.  The button will be introduced above the solution._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution": "hidden",
    "solution2": "hidden",
    "solution2_first": true,
    "solution_first": true
   },
   "source": [
    "### Exercise 2: _Title_\n",
    "\n",
    "_Text of the exercise_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "solution": "hidden",
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** _Solution for the exercise_"
   ]
  }
 ],
 "metadata": {
  "ipub": {
   "bibliography": "fuzzingbook.bib",
   "toc": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
