{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Carving Unit Tests\n",
    "\n",
    "So far, we have always generated _system input_, i.e. data that the program as a whole obtains via its input channels.  If we are interested in testing only a small set of functions, having to go through the system can be very inefficient.  This chapter introduces a technique known as _carving_, which, given a system test, automatically extracts a set of _unit tests_ that replicate the calls seen during the unit test.  The key idea is to _record_ such calls such that we can _replay_ them later – as a whole or selectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzingbook_utils import YouTubeVideo\n",
    "YouTubeVideo(\"w4u5gCgPlmg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Prerequisites**\n",
    "\n",
    "* Carving makes use of dynamic traces of function calls and variables, as introduced in the [chapter on configuration fuzzing](ConfigurationFuzzer.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## System Tests vs Unit Tests\n",
    "\n",
    "Remember the URL grammar introduced for [grammar fuzzing](Grammars.ipynb)?  With such a grammar, we can happily test a Web browser again and again, checking how it reacts to arbitrary page requests.\n",
    "\n",
    "Let us define a very simple \"web browser\" that goes and downloads the content given by the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse, urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webbrowser(url):\n",
    "    \"\"\"Download the http/https resource given by the URL\"\"\"\n",
    "    response = urllib.request.urlopen(url)\n",
    "    if response.getcode() == 200:\n",
    "        contents = response.read()\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us apply this on [fuzzingboook.org](https://www.fuzzingbook.org/) and measure the time, using the [Timer class](Timer.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Timer import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as webbrowser_timer:\n",
    "    fuzzingbook_contents = webbrowser(\"http://www.fuzzingbook.org/html/Fuzzer.html\")\n",
    "\n",
    "print(\"Downloaded %d bytes in %.2f seconds\" % (len(fuzzingbook_contents), webbrowser_timer.elapsed_time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzingbook_contents[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having to start a whole browser (or having it render a Web page) again and again means lots of overhead, though – in particular if we want to test only a subset of its functionality.  In particular, after a change in the code, we would prefer to test only the subset of functions that is affected by the change, rather than running the well-tested functions again and again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let us assume we change the function that takes care of parsing the given URL and decomposing it into the individual elements – the scheme (\"http\"), the network location (`\"www.fuzzingbook.com\"`), or the path (`\"/html/Fuzzer.html\"`).  This function is named `urlparse()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlparse('https://www.fuzzingbook.com/html/APIFuzzer.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see how the individual elements of the URL – the _scheme_ (`\"http\"`), the _network location_ (`\"www.fuzzingbook.com\"`), or the path (`\"//html/APIFuzzer.html\"`) are all properly identified.  Other elements (like `params`, `query`, or `fragment`) are empty, because they were not part of our input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interesting thing is that executing only `urlparse()` is orders of magnitude faster than running all of `webbrowser()`.  Let us measure the factor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 1000\n",
    "with Timer() as urlparse_timer:\n",
    "    for i in range(runs):\n",
    "        urlparse('https://www.fuzzingbook.com/html/APIFuzzer.html')\n",
    "\n",
    "avg_urlparse_time = urlparse_timer.elapsed_time() / 1000\n",
    "avg_urlparse_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to the time required by the webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser_timer.elapsed_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in time is huge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser_timer.elapsed_time() / avg_urlparse_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, in the time it takes to run `webbrowser()` once, we can have _hundreds of thousands_ of executions of `urlparse()` – and this does not even take into account the time it takes the browser to render the downloaded HTML, to run the included scripts, and whatever else happens when a Web page is loaded.  Hence, strategies that allow us to test at the _unit_ level are very promising as they can save lots of overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carving Unit Tests\n",
    "\n",
    "Testing methods and functions at the unit level requires a very good understanding of the individual units to be tested as well as their interplay with other units.  Setting up an appropriate infrastructure and writing unit tests by hand thus is demanding, yet rewarding.  There is, however, an interesting alternative to writing unit tests by hand.  The technique of _carving_ automatically _converts system tests into unit tests_ by means of recording and replaying function calls:\n",
    "\n",
    "1. During a system test (given or generated), we _record_ all calls into a function, including all arguments and other variables the function reads.\n",
    "2. From these, we synthesize a self-contained _unit test_ that reconstructs the function call with all arguments.\n",
    "3. This unit test can be executed (replayed) at any time with high efficiency.\n",
    "\n",
    "In the remainder of this chapter, let us explore these steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Recording Calls\n",
    "\n",
    "Our first challenge is to record function calls together with their arguments.  (In the interest of simplicity, we restrict ourself to arguments, ignoring any global variables or other non-arguments that are read by the function.)  To record calls and arguments, we use the mechanism [we introduced for coverage](Coverage.ipynb): By setting up a tracer function, we track all calls into individual functions, also saving their arguments.  Just like `Coverage` objects, we want to use `Carver` objects to be able to be used in conjunction with the `with` statement, such that we can trace a particular code block:\n",
    "\n",
    "```python\n",
    "with Carver() as carver:\n",
    "    function_to_be_traced()\n",
    "c = carver.calls()\n",
    "```\n",
    "\n",
    "The initial definition supports this construct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Carver(object):\n",
    "    def __init__(self):\n",
    "        self._calls = {}\n",
    "\n",
    "    # Start of `with` block\n",
    "    def __enter__(self):\n",
    "        self.original_trace_function = sys.gettrace()\n",
    "        sys.settrace(self.traceit)\n",
    "        return self\n",
    "\n",
    "    # End of `with` block\n",
    "    def __exit__(self, exc_type, exc_value, tb):\n",
    "        sys.settrace(self.original_trace_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual work takes place in the `traceit()` method, which records all calls in the `_calls` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qualified_name(code):\n",
    "    name = code.co_name\n",
    "    module = inspect.getmodule(code)\n",
    "    if module is not None:\n",
    "        name = module.__name__ + \".\" + name\n",
    "    return name\n",
    "\n",
    "class Carver(Carver):\n",
    "    # Tracking function: Record all calls and all args\n",
    "    def traceit(self, frame, event, arg):\n",
    "        if event != \"call\":\n",
    "            return None\n",
    "        \n",
    "        code = frame.f_code\n",
    "        function_name = qualified_name(code)\n",
    "\n",
    "        # When called, all arguments are local variables\n",
    "        arguments = [(var, frame.f_locals[var]) for var in frame.f_locals]\n",
    "        arguments.reverse()  # Want same order as call\n",
    "\n",
    "        if function_name not in self._calls:\n",
    "            self._calls[function_name] = []\n",
    "        if arguments not in self._calls[function_name]:\n",
    "            self._calls[function_name].append(arguments)\n",
    "\n",
    "        # Some tracking\n",
    "        # print(simple_call_string(function_name, args))\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need some convenience functions to access the calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Carver(Carver):\n",
    "    def calls(self):\n",
    "        \"\"\"Return a dictionary of all calls traced.\"\"\"  \n",
    "        return self._calls\n",
    "    \n",
    "    def arguments(self, function_name):\n",
    "        \"\"\"Return a list of all arguments of the given function\n",
    "        as (VAR, VALUE) pairs.\n",
    "        Raises an exception if the function was not traced.\"\"\"\n",
    "        return self._calls[function_name]\n",
    "    \n",
    "    def called_functions(self):\n",
    "        \"\"\"Return all functions called.\"\"\"\n",
    "        return self._calls.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how these work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recording my_sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out our new `Carver` class – first on a very simple function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Intro_Testing import my_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Carver() as sqrt_carver:\n",
    "    my_sqrt(2)\n",
    "    my_sqrt(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve all calls seen..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_carver.calls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... as well as the arguments of a particular function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_carver.arguments(\"my_sqrt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a convenience function for nicer printing of these lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_call_string(function_name, argument_list):\n",
    "    \"\"\"Return function_name(arg[0], arg[1], ...) as a string\"\"\"\n",
    "    return function_name + \"(\" + \\\n",
    "        \", \".join([var + \"=\" + repr(value) for (var, value) in argument_list]) + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for function_name in sqrt_carver.called_functions():\n",
    "    for argument_list in sqrt_carver.arguments(function_name):\n",
    "        print(simple_call_string(function_name, argument_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a syntax we can directly use to invoke `my_sqrt()` again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(\"my_sqrt(x=2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carving urlparse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we apply this to `webbrowser()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Carver() as webbrowser_carver:\n",
    "    webbrowser(\"http://www.example.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that retrieving a URL from the Web requires quite some functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser_carver.called_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among several other functions, we also have a call to `urlparse()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlparse_argument_list = webbrowser_carver.arguments(\"urllib.parse.urlparse\")\n",
    "urlparse_argument_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can convert this into a well-formatted call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlparse_call = simple_call_string(\"urlparse\", urlparse_argument_list[0])\n",
    "urlparse_call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can re-execute this call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(urlparse_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have successfully carved the call to `urlparse()` out of the `webbrowser()` execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replaying Calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replaying calls in their entirety and in all generality is tricky, as there are several challenges to be addressed.  These include:\n",
    "\n",
    "1. We need to be able to _access_ individual functions.  If we access a function by name, the name must be in scope.  If the name is not visible (for instance, because it is a name internal to the module), we must make it visible.\n",
    "\n",
    "2. Any resources accessed outside of arguments must be recorded and reconstructed for replay as well.  This can be difficult if variables refer to external resources such as files or network resources.\n",
    "\n",
    "3. Complex objects must be reconstructed as well.\n",
    "\n",
    "These constraints make carving hard if the function to be tested interacts heavily with its environment.  To illustrate these issues, consider the `email.parser.parse()` method that is invoked in `webbrowser()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_parse_argument_list = webbrowser_carver.arguments(\"email.parser.parse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calls to this method look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_parse_call = simple_call_string(\"email.parser.parse\", email_parse_argument_list[0])\n",
    "email_parse_call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `email.parser.parse()` is part of a `email.parser.Parser` object and it gets a `StringIO` object.  Both are non-primitive values.  How could we possibly reconstruct them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serializing Objects\n",
    "\n",
    "The answer to the problem of complex objects lies in creating a _persistent_ representation that can be _reconstructed_ at later points in time.  This process is known as _serialization_; in Python, it is also known as _pickling_.  The `pickle` module provides means to create a serialized representation of an object.  Let us apply this on the `email.parser.Parser` object we just found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser_object = email_parse_argument_list[0][0][1]\n",
    "parser_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled = pickle.dumps(parser_object)\n",
    "pickled"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "From this string, we can recreate the Parser object at any time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpickled_parser_object = pickle.loads(pickled)\n",
    "unpickled_parser_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The serialization mechanism allows us to produce a representation for all objects passed as parameters (assuming they can be pickled, that is).  We can now extend the `simple_call_string()` function such that it automatically pickles objects.  Additionally, we set it up such that if the first parameter is named `self` (i.e., it is a class method), we make it a method of the `self` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_string(function_name, argument_list):\n",
    "    \"\"\"Return function_name(arg[0], arg[1], ...) as a string, pickling complex objects\"\"\"\n",
    "    def call_value(value):\n",
    "        value_as_string = repr(value)\n",
    "        if value_as_string.find('<') >= 0:\n",
    "            # Complex object\n",
    "            value_as_string = \"pickle.loads(\" + repr(pickle.dumps(value)) + \")\"\n",
    "        return value_as_string\n",
    "    \n",
    "    if len(argument_list) > 0:\n",
    "        (first_var, first_value) = argument_list[0]\n",
    "        if first_var == \"self\":\n",
    "            # Make this a method call\n",
    "            method_name = function_name.split(\".\")[-1]\n",
    "            function_name = call_value(first_value) + \".\" + method_name\n",
    "            argument_list = argument_list[1:]\n",
    "    \n",
    "    return function_name + \"(\" + \\\n",
    "        \", \".join([var + \"=\" + call_value(value) for (var, value) in argument_list]) + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call = call_string(\"email.parser.parse\", email_parse_argument_list[0])\n",
    "print(call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Calls\n",
    "\n",
    "So far, we have seen only one call of `webbrowser()`.  How many of the calls within `webbrowser()` can we actually carve and replay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum, socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_functions = set(webbrowser_carver.called_functions())\n",
    "call_success = set()\n",
    "run_success = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for function_name in webbrowser_carver.called_functions():\n",
    "    for argument_list in webbrowser_carver.arguments(function_name):\n",
    "        try:\n",
    "            call = call_string(function_name, argument_list)\n",
    "            call_success.add(function_name)\n",
    "\n",
    "            result = eval(call)\n",
    "            run_success.add(function_name)\n",
    "\n",
    "        except:\n",
    "            # print(\"->\", call, file=sys.stderr)\n",
    "            # traceback.print_exc()\n",
    "            # print(\"\", file=sys.stderr)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%d/%d calls (%.2f%%) successfully created and %d/%d calls (%.2f%%) successfully ran\" % (\n",
    "    len(call_success), len(all_functions), len(call_success) * 100 / len(all_functions),\n",
    "    len(run_success), len(all_functions), len(run_success) * 100 / len(all_functions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that:\n",
    "\n",
    "* **A large majority of calls could be converted into call strings.**  If this is not the case, this is mostly due to having unserialized objects being passed.\n",
    "* **The majority of calls could be executed.**  The error messages for these are varied (try uncommenting the above diagnostic lines); the most frequent being that some internal name is invoked that is not in scope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our carving mechanism should be taken with a grain of salt: We still do not cover the situation where external variables and values (such as global variables) are being accessed, and the serialization mechanism cannot recreate external resources.  Still, if the function of interest falls among those that _can_ be carved and replayed, we can very effectively re-run its calls with their original arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Lessons Learned\n",
    "\n",
    "* _Carving_ allows for effective replay of function calls recorded during a system test.\n",
    "* A function call can be _orders of magnitude faster_ than a system invocation.\n",
    "* _Serialization_ allows to create persistent representations of complex objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "The following chapters make use of the concepts defined here:\n",
    "\n",
    "* In the chapter on [fuzzing APIs](APIFuzzer.ipynb), we discuss how to use carving to _fuzz functions with combinations of carved and newly generated values_.  This effectively joins the strengths of carving and fuzzing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Carving was invented by Elbaum et al. \\cite{Elbaum2006} and originally implemented for Java.  In this chapter, we follow several of their design choices (including recording and serializing method arguments only).  We do not know how long it took to implement carving for Java, but the above implementation was crafted in one afternoon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercises\n",
    "\n",
    "\\todo{Add.}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution": "hidden",
    "solution2": "hidden",
    "solution2_first": true,
    "solution_first": true
   },
   "source": [
    "### Exercise 1: Carving Return Values\n",
    "\n",
    "Record not only calls, but also their return values.  Use this for _regression testing_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "solution": "hidden",
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** _Solution for the exercise_"
   ]
  }
 ],
 "metadata": {
  "ipub": {
   "bibliography": "fuzzingbook.bib",
   "toc": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
