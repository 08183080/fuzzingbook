{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Grammar Coverage\n",
    "\n",
    "In this chapter, we explore how to systematically cover elements of a grammar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Prerequisites**\n",
    "\n",
    "* You should have read the [chapter on grammars](Grammars.ipynb).\n",
    "* You should have read the [chapter on efficient grammar fuzzing](GrammarFuzzer.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Covering Grammar Elements\n",
    "\n",
    "[Producing inputs from grammars](GrammarFuzzer.ipynb) gives all possible expansions of a rule the same likelihood.  For producing a comprehensive test suite, however, it makes more sense to maximize _variety_ – for instance, by avoiding repeating the same expansions over and over again.  To achieve this, we can track the _coverage_ of individual expansions: If we have seen some expansion already, we can prefer other possible expansions in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "As an example, consider the grammar\n",
    "\n",
    "```grammar\n",
    "<start> ::= <digit><digit>\n",
    "<digit> ::= 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let us assume we have already produced a `0` in the first expansion of `<digit>`.  As it comes to expand the next digit, we would mark the `0` expansion as already covered, and choose one of the yet uncovered alternatives.  Only when we have covered all alternatives would we go back and consider expansions covered before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking Grammar Coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "This concept of coverage is very easy to implement.  We introduce a class `GrammarCoverageFuzzer` that keeps track of the current grammar coverage achieved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import fuzzingbook_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Grammars import DIGIT_GRAMMAR, EXPR_GRAMMAR, CGI_GRAMMAR, URL_GRAMMAR, START_SYMBOL, is_valid_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GrammarFuzzer import GrammarFuzzer, all_terminals, nonterminals, display_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "class TrackingGrammarCoverageFuzzer(GrammarFuzzer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # invoke superclass __init__(), passing all arguments\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.reset_coverage()\n",
    "\n",
    "    def reset_coverage(self):\n",
    "        self.covered_expansions = set()\n",
    "\n",
    "    def expansion_coverage(self):\n",
    "        return self.covered_expansions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this set `covered_expansions`, we store individual expansions seen as pairs of (_symbol_, _expansion_), using the method `expansion_key()` to generate a string representation for the pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackingGrammarCoverageFuzzer(TrackingGrammarCoverageFuzzer):\n",
    "    def expansion_key(self, symbol, expansion):\n",
    "        \"\"\"Convert (symbol, children) into a key.  `children` can be an expansion string or a derivation tree.\"\"\"\n",
    "        if isinstance(expansion, tuple):\n",
    "            expansion = expansion[0]\n",
    "        if not isinstance(expansion, str):\n",
    "            children = expansion\n",
    "            expansion = all_terminals((symbol, children))\n",
    "        return symbol + \" -> \" + expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = TrackingGrammarCoverageFuzzer(EXPR_GRAMMAR)\n",
    "f.expansion_key(START_SYMBOL, EXPR_GRAMMAR[START_SYMBOL][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of _expansion_, we can also pass a list of children as argument, which will then automatically be converted into a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "children = [(\"<expr>\", None), (\" + \", []), (\"<term>\", None)]\n",
    "f.expansion_key(\"<expr>\", children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the set of possible expansions in a grammar by enumerating all expansions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackingGrammarCoverageFuzzer(TrackingGrammarCoverageFuzzer):\n",
    "    def max_expansion_coverage(self):\n",
    "        \"\"\"Return set of all expansions in a grammar\"\"\"\n",
    "        expansions = set()\n",
    "        for nonterminal in self.grammar:\n",
    "            for expansion in self.grammar[nonterminal]:\n",
    "                expansions.add(self.expansion_key(nonterminal, expansion))\n",
    "        return expansions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = TrackingGrammarCoverageFuzzer(DIGIT_GRAMMAR)\n",
    "f.max_expansion_coverage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During expansion, we can keep track of expansions seen.  To do so, we hook into the method `choose_node_expansion()`, expanding a single node in our [Grammar fuzzer](GrammarFuzzer.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackingGrammarCoverageFuzzer(TrackingGrammarCoverageFuzzer):\n",
    "    def add_coverage(self, symbol, new_children):\n",
    "        key = self.expansion_key(symbol, new_children)\n",
    "\n",
    "        if self.log and key not in self.covered_expansions:\n",
    "            print(\"Now covered:\", key)\n",
    "        self.covered_expansions.add(key)\n",
    "\n",
    "    def choose_node_expansion(self, node, possible_children):\n",
    "        (symbol, children) = node\n",
    "        index = super().choose_node_expansion(node, possible_children)\n",
    "        self.add_coverage(symbol, possible_children[index])\n",
    "        return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can now systematically check which expansions already have been covered – and which ones still have to be covered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "f = TrackingGrammarCoverageFuzzer(DIGIT_GRAMMAR, log=True)\n",
    "f.fuzz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.fuzz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.fuzz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the set of covered expansions so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.expansion_coverage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, how many characters do we have to produce until all expansions are covered?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_length_until_full_coverage(fuzzer):\n",
    "    trials = 50\n",
    "\n",
    "    sum = 0\n",
    "    for trial in range(trials):\n",
    "        fuzzer.reset_coverage()\n",
    "        while len(fuzzer.max_expansion_coverage() \n",
    "                  - fuzzer.expansion_coverage()) > 0:\n",
    "            s = fuzzer.fuzz()\n",
    "            sum += len(s)\n",
    "\n",
    "    return sum / trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_length_until_full_coverage(TrackingGrammarCoverageFuzzer(EXPR_GRAMMAR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covering Grammar Expansions\n",
    "\n",
    "Let us now not only track coverage, but actually _produce_ coverage.  The idea is as follows:\n",
    "\n",
    "1. We determine children yet uncovered (in `uncovered_children`)\n",
    "2. If all children are covered, we fall back to the original method (i.e., choosing one expansion randomly)\n",
    "3. Otherwise, we select a child from the uncovered children and mark it as covered.\n",
    "\n",
    "To this end, we introduce a new fuzzer `SimpleGrammarCoverageFuzzer` that implements this strategy in the `choose_node_expansion()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGrammarCoverageFuzzer(TrackingGrammarCoverageFuzzer):\n",
    "    def choose_node_expansion(self, node, possible_children):\n",
    "        # Prefer uncovered expansions\n",
    "        (symbol, children) = node\n",
    "        uncovered_children = [c for (i, c) in enumerate(possible_children)\n",
    "                              if self.expansion_key(symbol, c) not in self.covered_expansions]\n",
    "        index_map = [i for (i, c) in enumerate(possible_children)\n",
    "                     if self.expansion_key(symbol, c) not in self.covered_expansions]\n",
    "\n",
    "        if len(uncovered_children) == 0:\n",
    "            # All expansions covered - use superclass method\n",
    "            return self.choose_covered_node_expansion(node, possible_children)\n",
    "\n",
    "        # select a random expansion\n",
    "        index = self.choose_uncovered_node_expansion(node, uncovered_children)\n",
    "\n",
    "        return index_map[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two methods `choose_covered_node_expansion()` and `choose_uncovered_node_expansion()` are provided for subclasses to hook in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGrammarCoverageFuzzer(SimpleGrammarCoverageFuzzer):\n",
    "    def choose_uncovered_node_expansion(self, node, possible_children):\n",
    "        return TrackingGrammarCoverageFuzzer.choose_node_expansion(self, node, possible_children)\n",
    "\n",
    "    def choose_covered_node_expansion(self, node, possible_children):\n",
    "        return TrackingGrammarCoverageFuzzer.choose_node_expansion(self, node, possible_children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "By returning the set of expansions covered so far, we can invoke the fuzzer multiple times, each time adding to the grammar coverage.  With the `DIGIT_GRAMMAR` grammar, for instance, this lets the grammar produce one digit after the other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "f = SimpleGrammarCoverageFuzzer(DIGIT_GRAMMAR, log=True)\n",
    "f.fuzz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.fuzz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.fuzz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the set of covered expansions so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.expansion_coverage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us fuzz some more. We see that with each iteration, we cover another expansion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    f.fuzz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "At the end, all expansions are covered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.max_expansion_coverage() - f.expansion_coverage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let us apply this on a more complex grammar – e.g., the expression grammar.  We see that after a few iterations, we cover each and every digit, operator, and expansion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "f = SimpleGrammarCoverageFuzzer(EXPR_GRAMMAR)\n",
    "for i in range(10):\n",
    "    print(f.fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Again, all expansions are covered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "f.max_expansion_coverage() - f.expansion_coverage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our strategy is much more effective than random in achieving coverage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_length_until_full_coverage(SimpleGrammarCoverageFuzzer(EXPR_GRAMMAR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Foresight\n",
    "\n",
    "Selecting expansions for individual rules is a good start; however, it is not sufficient, as the following example shows.  We apply our coverage fuzzer on the CGI grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = SimpleGrammarCoverageFuzzer(CGI_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(f.fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 10 iterations, we still have a number of expansions uncovered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.max_expansion_coverage() - f.expansion_coverage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is that so?  The problem is that in the CGI grammar, the largest number of variations to be covered occurs in the `hexdigit` rule.  However, we first need to _reach_ this expansion.  When expanding a `<letter>` symbol, we have the choice between three possible expansions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CGI_GRAMMAR[\"<letter>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all three expansions are covered already, then `choose_node_expansion()` above will choose one randomly – even if there may be more expansions to cover when choosing `<percent>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need is a better strategy that will pick `<percent>` if there are more uncovered expansions following – even if `<percent>` is covered.  Such a strategy was first discussed by W. Burkhardt \\cite{Burkhardt1967} under the name of \"Shortest Path Selection\":\n",
    "\n",
    "> This version selects, from several alternatives for development, that syntactic unit under which there is still an unused unit available, starting with the shortest path.\n",
    "    \n",
    "This is what we will implement in the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining Maximum per-Symbol Coverage\n",
    "\n",
    "To address this problem, we introduce a new class `GrammarCoverageFuzzer` that builds on `SimpleGrammarCoverageFuzzer`, but with a better strategy.  First, we need to compute the _maximum set of expansions_ that can be reached from a particular symbol. The idea is to later compute the _intersection_ of this set and the expansions already covered, such that we can favor those expansions with a non-empty intersection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our method `max_symbol_expansion_coverage()` computes this maximum set of expansions.  The helper method `_max_symbol_expansion_coverage()` does the heavy lifting, iterating through the grammar up to a given depth and tracking which symbols (`symbols_seen`) and which coverage (`cov`) has already been seen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarCoverageFuzzer(SimpleGrammarCoverageFuzzer):\n",
    "    def _max_symbol_expansion_coverage(\n",
    "            self, symbol, max_depth, cov, symbols_seen):\n",
    "        \"\"\"Return set of all expansions in a grammar starting with `symbol`\"\"\"\n",
    "        if max_depth <= 0:\n",
    "            return (cov, symbols_seen)\n",
    "\n",
    "        symbols_seen.add(symbol)\n",
    "        for expansion in self.grammar[symbol]:\n",
    "            key = self.expansion_key(symbol, expansion)\n",
    "            if key in cov:\n",
    "                continue\n",
    "\n",
    "            cov.add(key)\n",
    "            for s in nonterminals(expansion):\n",
    "                if s in symbols_seen:\n",
    "                    continue\n",
    "                new_cov, new_symbols_seen = (\n",
    "                    self._max_symbol_expansion_coverage(s, max_depth - 1, cov, symbols_seen))\n",
    "                cov |= new_cov\n",
    "                symbols_seen |= new_symbols_seen\n",
    "\n",
    "        return (cov, symbols_seen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main method `max_symbol_expansion_coverage()` simply returns the coverage that can be achieved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarCoverageFuzzer(GrammarCoverageFuzzer):\n",
    "    def max_symbol_expansion_coverage(self, symbol, max_depth=float('inf')):\n",
    "        cov, symbols_seen = self._max_symbol_expansion_coverage(\n",
    "            symbol, max_depth, set(), set())\n",
    "        return cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can compute the possible expansions for every symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = GrammarCoverageFuzzer(EXPR_GRAMMAR)\n",
    "f.max_symbol_expansion_coverage('<integer>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.max_symbol_expansion_coverage('<digit>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum coverage achievable in a grammar is the same as starting with the start symbol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert f.max_expansion_coverage() == f.max_symbol_expansion_coverage(START_SYMBOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining Children with new Coverage\n",
    "\n",
    "The definition of `max_symbol_expansion_coverage()` allows us to determine the _new_ coverage for each child.  To this end, we _subtract_ the coverage already seen (`expansion_coverage()`) from the coverage that could be obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarCoverageFuzzer(GrammarCoverageFuzzer):\n",
    "    def _new_child_coverage(self, children, max_depth):\n",
    "        new_cov = set()\n",
    "        for (c_symbol, _) in children:\n",
    "            if c_symbol in self.grammar:\n",
    "                new_cov |= self.max_symbol_expansion_coverage(\n",
    "                    c_symbol, max_depth)\n",
    "        return new_cov\n",
    "\n",
    "    def new_child_coverage(self, symbol, children, max_depth=float('inf')):\n",
    "        \"\"\"Return new coverage that would be obtained by expanding (symbol, children)\"\"\"\n",
    "        new_cov = self._new_child_coverage(children, max_depth)\n",
    "        for c in children:\n",
    "            new_cov.add(self.expansion_key(symbol, children))\n",
    "        new_cov -= self.expansion_coverage()   # set subtraction\n",
    "        return new_cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us illustrate `new_child_coverage()`.  We again start fuzzing, choosing expansions randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = GrammarCoverageFuzzer(DIGIT_GRAMMAR, log=True)\n",
    "f.fuzz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our current coverage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.expansion_coverage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we go through the individual expansion possibilities for `START_SYMBOL`, we see that all expansions offer additional coverage, _except_ for the one we have just seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for expansion in DIGIT_GRAMMAR[START_SYMBOL]:\n",
    "    children = f.expansion_to_children(expansion)\n",
    "    print(expansion, f.new_child_coverage(START_SYMBOL, children))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that whenever choosing an expansion, we can make use of `new_child_coverage()` and choose among the expansions that offer the greatest new (unseen) coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Lookahead\n",
    "\n",
    "When choosing a child, we do not look out for the maximum overall coverage to be obtained, as this would result in expansions with many uncovered possibilities totally dominate other expansions.  Instead, we aim for a _breadth-first_ strategy, first covering all expansions up to a given depth, and only then looking for a greater depth.  The method `new_coverages()` is at the heart of this strategy: Starting with a maximum depth (`max_depth`) of zero, it increases the depth until it finds at least one uncovered expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarCoverageFuzzer(GrammarCoverageFuzzer):\n",
    "    def new_coverages(self, node, possible_children):\n",
    "        \"\"\"Return coverage to be obtained for each child at minimum depth\"\"\"\n",
    "        (symbol, children) = node\n",
    "        for max_depth in range(len(self.grammar)):\n",
    "            new_coverages = [\n",
    "                self.new_child_coverage(\n",
    "                    symbol, c, max_depth) for c in possible_children]\n",
    "            max_new_coverage = max(len(new_coverage)\n",
    "                                   for new_coverage in new_coverages)\n",
    "            if max_new_coverage > 0:\n",
    "                # Uncovered node found\n",
    "                return new_coverages\n",
    "\n",
    "        # All covered\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Together\n",
    "\n",
    "We can now define `choose_node_expansion()` to make use of this strategy: First, we determine the possible coverages to be obtained (using `new_coverages()`); then we (randomly) select among the children which sport the maximum coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarCoverageFuzzer(GrammarCoverageFuzzer):\n",
    "    def choose_node_expansion(self, node, possible_children):\n",
    "        (symbol, children) = node\n",
    "        new_coverages = self.new_coverages(node, possible_children)\n",
    "\n",
    "        if new_coverages is None:\n",
    "            # All expansions covered - use superclass method\n",
    "            return self.choose_covered_node_expansion(node, possible_children)\n",
    "\n",
    "        max_new_coverage = max(len(cov) for cov in new_coverages)\n",
    "        \n",
    "        children_with_max_new_coverage = [c for (i, c) in enumerate(possible_children)\n",
    "                                            if len(new_coverages[i]) == max_new_coverage]\n",
    "        index_map = [i for (i, c) in enumerate(possible_children)\n",
    "                     if len(new_coverages[i]) == max_new_coverage]\n",
    "        \n",
    "        # Select a random expansion\n",
    "        new_children_index = self.choose_uncovered_node_expansion(node, children_with_max_new_coverage)\n",
    "        new_children = children_with_max_new_coverage[new_children_index]\n",
    "\n",
    "        # Save the expansion as covered\n",
    "        key = self.expansion_key(symbol, new_children)\n",
    "\n",
    "        if self.log:\n",
    "            print(\"Now covered:\", key)\n",
    "        self.covered_expansions.add(key)\n",
    "\n",
    "        return index_map[new_children_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our fuzzer is now complete.  Let us apply it on a series of examples.  On expressions, it quickly covers all digits and operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = GrammarCoverageFuzzer(EXPR_GRAMMAR, min_nonterminals=3)\n",
    "f.fuzz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.max_expansion_coverage() - f.expansion_coverage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, it is again faster than the simple strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_length_until_full_coverage(GrammarCoverageFuzzer(EXPR_GRAMMAR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the CGI grammar, it takes but a few iterations to cover all letters and digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = GrammarCoverageFuzzer(CGI_GRAMMAR, min_nonterminals=5)\n",
    "while len(f.max_expansion_coverage() - f.expansion_coverage()) > 0:\n",
    "    print(f.fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This improvement can also be seen in comparing the random, expansion-only, and deep foresight strategies on the CGI grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_length_until_full_coverage(TrackingGrammarCoverageFuzzer(CGI_GRAMMAR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_length_until_full_coverage(SimpleGrammarCoverageFuzzer(CGI_GRAMMAR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_length_until_full_coverage(GrammarCoverageFuzzer(CGI_GRAMMAR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Coverage via Grammar Coverage\n",
    "\n",
    "By systematically covering all input elements, we get a larger variety in inputs – but does this translate into a wider variety of program behaviors?  After all, these behaviors are what we want to cover, including the unexpected behaviors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a grammar, there are elements that directly correspond to program features.  A program handling arithmetic expressions will have functionality that is directly triggered by individual elements - say, an addition feature triggered by the presence of `+`, subtraction triggered by the presence of `-`, and floating-point arithmetic triggered by the presence of floating-point numbers in the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a connection between input structure and functionality leads to a strong _correlation between grammar coverage and code coverage_.  In other words: If we can achieve a high grammar coverage, this also leads to a high code coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CGI Grammars\n",
    "\n",
    "Let us explore this relationship on one of our grammars – say, the CGI decoder.  We compute a mapping `coverages` where in `coverages[x]` = `{y_1, y_2, ...}`, `x` is the grammar coverage obtained, and `y_n` is the code coverage obtained for the `n`-th run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Coverage import Coverage, cgi_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = GrammarCoverageFuzzer(CGI_GRAMMAR, max_nonterminals=2)\n",
    "coverages = {}\n",
    "\n",
    "trials = 100\n",
    "for trial in range(trials):\n",
    "    f.reset_coverage()\n",
    "    overall_cov = set()\n",
    "\n",
    "    for i in range(10):\n",
    "        s = f.fuzz()\n",
    "        with Coverage() as cov:\n",
    "            cgi_decode(s)\n",
    "        overall_cov |= cov.coverage()\n",
    "\n",
    "        x = len(f.expansion_coverage())\n",
    "        y = len(overall_cov)\n",
    "        if x not in coverages:\n",
    "            coverages[x] = []\n",
    "        coverages[x].append(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the averages for the `y`-values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = list(coverages.keys())\n",
    "ys = [sum(coverages[x]) / len(coverages[x]) for x in coverages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and create a scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xs, ys)\n",
    "plt.title('Coverage of cgi_decode() vs. grammar coverage')\n",
    "plt.xlabel('grammar coverage (expansions)')\n",
    "plt.ylabel('code coverage (lines)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the higher the grammar coverage, the higher the code coverage.  This also translates into a correlation coefficient of about 0.8, indicating a strong correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL Grammars\n",
    "\n",
    "Let us repeat this experiment on URL grammars.  We use the same code as above, except for exchanging the grammars and the function in place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from urlparse import urlparse      # Python 2\n",
    "except ImportError:\n",
    "    from urllib.parse import urlparse  # Python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = GrammarCoverageFuzzer(URL_GRAMMAR, max_nonterminals=2)\n",
    "coverages = {}\n",
    "\n",
    "trials = 100\n",
    "for trial in range(trials):\n",
    "    f.reset_coverage()\n",
    "    overall_cov = set()\n",
    "\n",
    "    for i in range(20):\n",
    "        s = f.fuzz()\n",
    "        with Coverage() as cov:\n",
    "            urlparse(s)\n",
    "        overall_cov |= cov.coverage()\n",
    "\n",
    "        x = len(f.expansion_coverage())\n",
    "        y = len(overall_cov)\n",
    "        if x not in coverages:\n",
    "            coverages[x] = []\n",
    "        coverages[x].append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = list(coverages.keys())\n",
    "ys = [sum(coverages[x]) / len(coverages[x]) for x in coverages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xs, ys)\n",
    "plt.title('Coverage of cgi_decode() vs. grammar coverage')\n",
    "plt.xlabel('grammar coverage (expansions)')\n",
    "plt.ylabel('code coverage (lines)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have an even stronger correlation of almost .95:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude: If one wants to obtain high code coverage, it is a good idea to strive for high grammar coverage first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Will this always work?\n",
    "\n",
    "The correlation observed for the CGI and URL examples will not hold for every program and every structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equivalent Elements\n",
    "\n",
    "First, some grammar elements are treated uniformly by a program even though the grammar sees them as different symbols.  In the host name of a URL, for instance, we can have many different characters, although a URL-handling program treats them all the same.  Likewise, individual digits, once composed into a number, make less of a difference than the value of the number itself.  Hence, achieving variety in digits or characters will not yield a large difference in functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Data Processing\n",
    "\n",
    "Second, the way the data is processed can make a large difference.  Consider the input to a _media player_, consisting of compressed media data.  While processing the media data, the media player will show differences in behavior (notably in its output), but these differences cannot be directly triggered through individual elements of the media data.  Likewise, a _machine learner_ that is trained on a large set of inputs typically will not have its behavior controlled by a single syntactic element of the input.  (Well, it could, but then, we would not need a machine learner.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these cases of \"deep\" data processing, achieving coverage in the grammar will not necessarily induce code coverage.  We still can make use of the grammar to produce _valid_ inputs, but will have to rely on chance and patience to cover functionality and trigger bugs.  _Some_ parts of the input, though, can still be covered: _Metadata_ (such as author name or composer for the media player) or _configuration data_ (such as settings for the machine learner) can and should be covered systematically; we will see how this is done [in the chapter on \"Configuration fuzzing\"](ConfigurationFuzzer.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Lessons Learned\n",
    "\n",
    "* Achieving _grammar coverage_ quickly results in a large variety of inputs.\n",
    "* Achieving grammar coverage can help in obtaining _code coverage_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "From here, you can learn how to\n",
    "\n",
    "* [use grammar coverage to systematically test cpnfigurations](ConfigurationFuzzer.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "The idea of ensuring that each expansion in the grammar is used at least once goes back to Burkhardt \\cite{Burkhardt1967}, to be later rediscovered by Paul Purdom \\cite{Purdom1972}. \\todo{Add more.}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Exercise 1: Testing ls\n",
    "\n",
    "Consider the Unix `ls` program, used to list the contents of a directory.  Create a grammar for invoking `ls`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "LS_EBNF_GRAMMAR = {\n",
    "    '<start>': ['-<options>'],\n",
    "    '<options>': ['<option>*'],\n",
    "    '<option>': ['1', 'A', '@',\n",
    "                 # many more\n",
    "                 ]\n",
    "}\n",
    "\n",
    "assert is_valid_grammar(LS_EBNF_GRAMMAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "Use `GrammarCoverageFuzzer` to test all options.  Be sure to invoke `ls` with each option set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "**Solution.**  We can copy the set of option characters right from the manual page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from Grammars import convert_ebnf_grammar, srange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "LS_EBNF_GRAMMAR = {\n",
    "    '<start>': ['-<options>'],\n",
    "    '<options>': ['<option>*'],\n",
    "    '<option>': srange(\"ABCFGHLOPRSTUW@abcdefghiklmnopqrstuwx1\")\n",
    "}\n",
    "assert is_valid_grammar(LS_EBNF_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "LS_GRAMMAR = convert_ebnf_grammar(LS_EBNF_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from Fuzzer import ProgramRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "f = GrammarCoverageFuzzer(LS_GRAMMAR, max_nonterminals=3)\n",
    "while len(f.max_expansion_coverage() - f.expansion_coverage()) > 0:\n",
    "    invocation = f.fuzz()\n",
    "    print(\"ls\", invocation, end=\"; \")\n",
    "    args = invocation.split()\n",
    "    ls = ProgramRunner([\"ls\"] + args)\n",
    "    ls.run()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "By setting `max_nonterminals` to other values, you can control how many options `ls` should be invoked with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution": "hidden",
    "solution2": "hidden",
    "solution2_first": true,
    "solution_first": true
   },
   "source": [
    "### Exercise 2: Caching\n",
    "\n",
    "The value of `max_symbol_expansion_coverage()` depends on the grammar only.  Change the implementation such that the values are precomputed for each symbol upon initialization (`__init__()`); this way, `max_symbol_expansion_coverage()` can simply lookup the value in the table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** This is like exercise 1 and 2 [in the chapter on efficient grammar fuzzing](GrammarFuzzer.ipynb); you can implement a similar solution here."
   ]
  }
 ],
 "metadata": {
  "ipub": {
   "bibliography": "fuzzingbook.bib",
   "toc": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
