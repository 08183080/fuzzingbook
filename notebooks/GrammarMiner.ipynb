{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Mining Input Grammars\n",
    "\n",
    "So far, the grammars we have seen have been mostly specified manually – that is, you (or the person knowing the input format) had to design and write a grammar in the first place.  While the grammars we have seen so far have been rather simple, creating a grammar for complex inoputs can involve quite some effort.  In this chapter, we therefore introduce techniques that automatically _mine_ grammars from programs – by executing the programs and observing how they process which parts of the input.  In conjunction with a grammar fuzzer, this allows us to (1) take a program, (2) extract its input grammar, and (3) fuzz it with high efficiency and effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Prerequisites**\n",
    "\n",
    "* You should have read the [chapter on grammars](Grammars.ipynb).\n",
    "* The [chapter on configuration fuzzing](ConfigurationFuzzer.ipynb) introduces grammar mining for configuration options, as well as observing variables and values during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fuzzingbook_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## A Simple Grammar Miner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we want to obtain the grammar for the function `urlparse` from the *Python* distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Under Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, clear_cache\n",
    "FUNCTION = urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recording Occurrence of Input Values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a few inputs that can be used, as listed below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use two *global* variables -- `the_values` is used to keep track of variable assignments and `the_input` to keep track of the current input string. We will show later how to avoid these globals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS = [\n",
    "    'http://user:pass@www.google.com:80/?q=path#ref',\n",
    "    'https://www.cispa.saarland:80/',\n",
    "    'http://www.fuzzingbook.org/#News',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get qualified name of a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Context:\n",
    "    def __init__(self, frame, track_caller=True):\n",
    "        self.method = self._method(frame)\n",
    "        self.parameter_names = self._get_parameters(frame)\n",
    "        self.file_name = self._file_name(frame)\n",
    "        self.parent = Context(frame.f_back,\n",
    "                              False) if track_caller and frame.f_back else None\n",
    "\n",
    "    def _get_parameters(self, frame):\n",
    "        return [\n",
    "            frame.f_code.co_varnames[i]\n",
    "            for i in range(frame.f_code.co_argcount)\n",
    "        ]\n",
    "\n",
    "    def _file_name(self, frame):\n",
    "        return frame.f_code.co_filename\n",
    "    \n",
    "    def _method(self, frame):\n",
    "        return frame.f_code.co_name\n",
    "\n",
    "    def all_vars(self, frame):\n",
    "        return frame.f_locals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `traceit()` is used to record all *non trivial* string variables (with length more than 2 characters) and values occurring during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracer:\n",
    "    def __init__(self, inputstr):\n",
    "        self.inputstr, self.trace = inputstr, []\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.oldtrace = sys.gettrace()\n",
    "        sys.settrace(self.traceit)\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        sys.settrace(self.oldtrace)\n",
    "\n",
    "    def include(self, k, v):\n",
    "        return isinstance(v, str)\n",
    "\n",
    "    def traceit(self, frame, event, arg):\n",
    "        cxt = Context(frame)\n",
    "        my_vars = [(k, v) for k, v in cxt.all_vars(frame).items()\n",
    "                   if self.include(k, v)]\n",
    "        self.trace.append((event, arg, cxt, my_vars))\n",
    "        return self.traceit\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.inputstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker:\n",
    "    def __init__(self, inputstr, trace, **kwargs):\n",
    "        self.the_vars = {}\n",
    "        self.trace = trace\n",
    "        self.inputstr = inputstr\n",
    "        self.options(kwargs)\n",
    "        self.process()\n",
    "        \n",
    "    def options(self, kwargs):\n",
    "        pass\n",
    "\n",
    "    def include(self, var, value):\n",
    "        return len(value) > 2 and value in self.inputstr\n",
    "\n",
    "    def trace_event(self, event, arg, ctx, my_vars):\n",
    "        self.the_vars.update({k: v for k, v in my_vars if self.include(k, v)})\n",
    "\n",
    "    def process(self):\n",
    "        for event, arg, cxt, my_vars in self.trace:\n",
    "            self.trace_event(event, arg, cxt, my_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace\n",
    "\n",
    "The `trace_function()` hooks into the Python trace functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "with Tracer(INPUTS[0]) as tracer:\n",
    "    FUNCTION(tracer())\n",
    "\n",
    "tracker = Tracker(tracer.inputstr, tracer.trace)\n",
    "for k,v in tracker.the_vars.items():\n",
    "    print(k, '=', repr(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting a Derivation Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Grammars import START_SYMBOL, syntax_diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GrammarFuzzer import GrammarFuzzer, FasterGrammarFuzzer, display_tree, tree_to_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert a variable name into a grammar nonterminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each pair _VAR_, _VALUE_ found:\n",
    "\n",
    "1. We search for occurrences of _VALUE_ in the grammar\n",
    "2. We replace them by <_VAR_>\n",
    "3. We add a new rule <_VAR_> $\\rightarrow$ <_VALUE_> to the grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Miner:\n",
    "    def __init__(self, my_input, my_assignments, **kwargs):\n",
    "        self.my_input = my_input\n",
    "        self.my_assignments = my_assignments\n",
    "        self.log = kwargs.get('log') or False\n",
    "        self.tree = self.get_derivation_tree()\n",
    "\n",
    "    def logger(self, indent, var):\n",
    "        if self.log:\n",
    "            print('\\t' * indent, var)\n",
    "\n",
    "    def nonterminal(self, var):\n",
    "        return \"<\" + var.lower() + \">\"\n",
    "\n",
    "    def to_tree(self, key=START_SYMBOL):\n",
    "        if key not in self.tree:\n",
    "            return (key, [])\n",
    "        children = [self.to_tree(c) for c in self.tree[key]]\n",
    "        return (key, children)\n",
    "\n",
    "    def get_derivation_tree(self):\n",
    "        tree = {START_SYMBOL: (self.my_input, )}\n",
    "        my_assignments = self.my_assignments.copy()\n",
    "\n",
    "        while True:\n",
    "            new_rules = []\n",
    "            for var, value in my_assignments.items():\n",
    "                self.logger(0, \"%s = %s\" % (var, value))\n",
    "                for key, repl in tree.items():\n",
    "                    self.logger(1, \"%s : %s\" % (key, repl))\n",
    "                    if not any(value in t for t in repl):\n",
    "                        continue\n",
    "                    alt_key = self.nonterminal(var)\n",
    "                    new_arr = []\n",
    "                    for k, token in enumerate(repl):\n",
    "                        if not value in token:\n",
    "                            new_arr.append(token)\n",
    "                        else:\n",
    "                            arr = token.split(value)\n",
    "                            new_arr.extend(\n",
    "                                list(sum(zip(arr,\n",
    "                                             len(arr) * [alt_key]), ()))[:-1])\n",
    "                    tree[key] = tuple(i for i in new_arr if i)\n",
    "                    new_rules.append((var, alt_key, value))\n",
    "\n",
    "            if not new_rules:\n",
    "                break  # Nothing to expand anymore\n",
    "\n",
    "            for (var, alt_key, value) in new_rules:\n",
    "                tree[alt_key] = (value, )\n",
    "                self.logger(0, \"+%s = %s\" % (alt_key, value))\n",
    "\n",
    "                # Do not expand this again\n",
    "                del my_assignments[var]\n",
    "\n",
    "        return {key: values for key, values in tree.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, trace the execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "with Tracer(INPUTS[0]) as tracer:\n",
    "    FUNCTION(tracer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments = Tracker(tracer.inputstr, tracer.trace).the_vars\n",
    "for var, val in tracker.the_vars.items():\n",
    "    print(var + \" = \" + repr(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt0 = Miner(tracer.inputstr, assignments)\n",
    "display_tree(dt0.to_tree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "with Tracer(INPUTS[1]) as tracer:\n",
    "    FUNCTION(tracer())\n",
    "dt1 = Miner(tracer.inputstr,\n",
    "                          Tracker(tracer.inputstr, tracer.trace).the_vars)\n",
    "display_tree(dt1.to_tree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "with Tracer(INPUTS[2]) as tracer:\n",
    "    FUNCTION(tracer())\n",
    "dt2 = Miner(tracer.inputstr,\n",
    "                          Tracker(tracer.inputstr, tracer.trace).the_vars)\n",
    "display_tree(dt2.to_tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Recovering Grammar from Derivation Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Infer:\n",
    "    def __init__(self):\n",
    "        self.grammar = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Infer(Infer):\n",
    "    def add_tree(self, t):\n",
    "        merged_grammar = {}\n",
    "        for key in list(self.grammar.keys()) + list(t.tree.keys()):\n",
    "            alternates = set(self.grammar.get(key, []))\n",
    "            if key in t.tree:\n",
    "                alternates.add(''.join(t.tree[key]))\n",
    "            merged_grammar[key] = list(alternates)\n",
    "        self.grammar = merged_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Infer()\n",
    "i.add_tree(dt0)\n",
    "i.add_tree(dt1)\n",
    "i.add_tree(dt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax_diagram(i.grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_grammar(traces):\n",
    "    m = Infer()\n",
    "    for inputstr, trace in traces:\n",
    "        dt = Miner(inputstr, Tracker(inputstr, trace).the_vars)\n",
    "        m.add_tree(dt)\n",
    "    return m.grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "for inputstr in INPUTS:\n",
    "    clear_cache()\n",
    "    with Tracer(inputstr) as tracer:\n",
    "        FUNCTION(tracer())\n",
    "    traces.append((tracer.inputstr, tracer.trace))\n",
    "grammar = recover_grammar(traces)\n",
    "syntax_diagram(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax_diagram(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = GrammarFuzzer(grammar)\n",
    "for i in range(10):\n",
    "    print(f.fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar Miner with Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep Track of The Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputStack(object):\n",
    "    def __init__(self, i):\n",
    "        self.original = i\n",
    "        self.inputs = []\n",
    "        \n",
    "    def height(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def has(self, val):\n",
    "        return any(val in var for var in self.inputs[-1].values())\n",
    "\n",
    "    def ignored(self, val):\n",
    "        return not (isinstance(val, str) and len(val) > 2)\n",
    "\n",
    "    def include(self, k, val):\n",
    "        if self.ignored(val):\n",
    "            return False\n",
    "        return self.has(val) if self.inputs else val in self.original\n",
    "\n",
    "    def push(self, inputs):\n",
    "        my_inputs = {k: v for k, v in inputs.items() if self.include(k, v)}\n",
    "        self.inputs.append(my_inputs)\n",
    "\n",
    "    def pop(self):\n",
    "        return self.inputs.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Restrict The Input Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proxy the dictionary so that it will only update if it does not already contain a value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vars(object):\n",
    "    def __init__(self, stack):\n",
    "        self.defs = {START_SYMBOL: stack.original}\n",
    "        self.istack = stack\n",
    "        \n",
    "    def set_kv(self, k, v):\n",
    "        if k not in self.defs:\n",
    "            self.defs[k] = v\n",
    "\n",
    "    def update(self, v):\n",
    "        for k,v in v.items():\n",
    "            self.set_kv(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackTracker(Tracker):\n",
    "    def __init__(self, inputstr, trace, **kwargs):\n",
    "        self.istack = InputStack(inputstr)\n",
    "        self.the_vars = Vars(self.istack)\n",
    "        self.trace = trace\n",
    "        self.options(kwargs)\n",
    "        self.process()\n",
    "\n",
    "    def options(self, kwargs):\n",
    "        self.files = kwargs.get('files') or []\n",
    "        self.track_params = kwargs.get('track_params') or True\n",
    "        self.track_vars = kwargs.get('track_vars') or True\n",
    "        self.track_return = kwargs.get('track_return') or False\n",
    "\n",
    "    def include(self, var, value):\n",
    "        if self.istack.ignored(value):\n",
    "            return False\n",
    "        return self.istack.include(var, value)\n",
    "\n",
    "    def get_params(self, cxt, all_vars):\n",
    "        return {\n",
    "            \"%s:%s\" % (cxt.method, k): v\n",
    "            for k, v in all_vars if k in cxt.parameter_names\n",
    "        }\n",
    "\n",
    "    def on_call(self, arg, cxt, my_vars):\n",
    "        my_parameters = {\n",
    "            k: v\n",
    "            for k, v in self.get_params(cxt, my_vars).items()\n",
    "            if not self.istack.ignored(v)\n",
    "        }\n",
    "        self.istack.push(my_parameters)\n",
    "        if self.track_params:\n",
    "            self.the_vars.update(my_parameters)\n",
    "\n",
    "    def on_line(self, arg, cxt, my_vars):\n",
    "        if self.track_vars:\n",
    "            qvars = {\"%s:%s\" % (cxt.method, k): v for k, v in my_vars}\n",
    "            my_vars = {\n",
    "                var: value\n",
    "                for var, value in qvars.items() if self.include(var, value)\n",
    "            }\n",
    "            if not self.track_params:\n",
    "                my_vars = {\n",
    "                    var: value\n",
    "                    for var, value in my_vas.items() if var not in param_names\n",
    "                }\n",
    "            self.the_vars.update(my_vars)\n",
    "\n",
    "    def on_return(self, arg, cxt, my_vars):\n",
    "        self.istack.pop()\n",
    "        self.on_line(arg, cxt, my_vars)\n",
    "        if self.track_return:\n",
    "            var = '(<-%s)' % cxt.method\n",
    "            self.the_vars.update_vars({var: arg})\n",
    "\n",
    "    def trace_event(self, event, arg, cxt, my_vars):\n",
    "        if not any(cxt.file_name.endswith(f) for f in self.files):\n",
    "            return\n",
    "        if event == 'call':\n",
    "            return self.on_call(arg, cxt, my_vars)\n",
    "\n",
    "        if event == 'return':\n",
    "            return self.on_return(arg, cxt, my_vars)\n",
    "\n",
    "        if event == 'exception':\n",
    "            return\n",
    "\n",
    "        self.on_line(arg, cxt, my_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to modify `traceit()` to be aware of events now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "for inputstr in INPUTS:\n",
    "    clear_cache()\n",
    "    with Tracer(inputstr) as tracer:\n",
    "        FUNCTION(tracer())\n",
    "    sm = StackTracker(tracer.inputstr, tracer.trace, files=['urllib/parse.py'])\n",
    "    traces.append((tracer.inputstr, sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the following we do not account for parameters getting reassigned values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each (VAR, VALUE) found:\n",
    "* We search for occurrences of VALUE in the grammar\n",
    "* We replace them by VAR\n",
    "* We add a new rule VAR -> VALUE to the grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Miner(Miner):\n",
    "    def get_derivation_tree(self):\n",
    "        my_assignments = self.my_assignments.copy()\n",
    "        tree = {}\n",
    "        for var, value in my_assignments.items():\n",
    "            nt_var = var if var == START_SYMBOL else self.nonterminal(var)\n",
    "            self.logger(0, \"%s = %s\" % (nt_var, value))\n",
    "            if tree:\n",
    "                append = False\n",
    "                for key, repl in tree.items():\n",
    "                    self.logger(1, \"%s : %s\" % (key, repl))\n",
    "                    if not any(value in t for t in repl):\n",
    "                        continue\n",
    "                    new_arr = []\n",
    "                    for k, token in enumerate(repl):\n",
    "                        if not value in token:\n",
    "                            new_arr.append(token)\n",
    "                        else:\n",
    "                            append = True\n",
    "                            arr = token.split(value)\n",
    "                            new_arr.extend(\n",
    "                                list(sum(zip(arr,\n",
    "                                             len(arr) * [nt_var]), ()))[:-1])\n",
    "                    tree[key] = tuple(i for i in new_arr if i)\n",
    "                if append:\n",
    "                    self.logger(0, \"+%s = %s\" % (nt_var, value))\n",
    "                    tree[nt_var] = set([value])\n",
    "            else:\n",
    "                tree[nt_var] = (value, )\n",
    "        return  {key: values for key, values in tree.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "with Tracer(INPUTS[2]) as tracer:\n",
    "    FUNCTION(tracer())\n",
    "sm = StackTracker(tracer.inputstr, tracer.trace, files=['urllib/parse.py'])\n",
    "dt = Miner(tracer.inputstr, sm.the_vars.defs)\n",
    "display_tree(dt.to_tree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_grammar(traces):\n",
    "    m = Infer()\n",
    "    for inputstr, trace in traces:\n",
    "        st = StackTracker(inputstr, trace, files=['urllib/parse.py'])\n",
    "        dt = Miner(inputstr, st.the_vars.defs)\n",
    "        m.add_tree(dt)\n",
    "    return m.grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "for inputstr in INPUTS:\n",
    "    clear_cache()\n",
    "    with Tracer(inputstr) as tracer:\n",
    "        FUNCTION(tracer())\n",
    "    traces.append((tracer.inputstr, tracer.trace))\n",
    "grammar = recover_grammar(traces)\n",
    "syntax_diagram(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tainted Grammar Miner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from InformationFlow import tstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaintedTracer(Tracer):\n",
    "    def __init__(self, inputstr):\n",
    "        self.inputstr = tstr(inputstr, parent=None)\n",
    "        self.trace = []\n",
    "        self.istack = TaintedInputStack(inputstr)\n",
    "        self.vars = TaintedVars(self.istack)\n",
    "  \n",
    "    def include(self, k, v):\n",
    "        return isinstance(repr(v), tstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaintedInputStack(InputStack):\n",
    "    def has(self, val):\n",
    "        return any(val.taint_in(var) for var in self.inputs[-1].values())\n",
    "    \n",
    "    def ignored(self, val):\n",
    "        return not (isinstance(repr(val), tstr) and len(repr(val).taint) > 2)\n",
    "    \n",
    "    def include(self, k, val):\n",
    "        if self.ignored(val):\n",
    "            return False\n",
    "        return self.has(val) if self.inputs else val.taint_in(self.original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaintedVars(Vars):\n",
    "    def set_kv(self, k, v):\n",
    "        def trep(v):\n",
    "            return v if isinstance(v, tstr) else repr(v)\n",
    "\n",
    "        self.defs[k] = trep(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaintedTracker(StackTracker):\n",
    "    def __init__(self, inputstr, trace, **kwargs):\n",
    "        self.istack = TaintedInputStack(inputstr)\n",
    "        self.the_vars = TaintedVars(self.istack)\n",
    "        self.trace = trace\n",
    "        self.options(kwargs)\n",
    "        self.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can only replace a value if the taints match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Miner(Miner):\n",
    "    def get_derivation_tree(self):\n",
    "        my_assignments = self.my_assignments.copy()\n",
    "        tree = {}\n",
    "        for var, value in my_assignments.items():\n",
    "            nt_var = var if var == START_SYMBOL else self.nonterminal(var)\n",
    "            self.logger(0, \"%s = %s\" % (nt_var, value))\n",
    "            if tree:\n",
    "                append = False\n",
    "                for key, repl in tree.items():\n",
    "                    self.logger(1, \"%s : %s\" % (key, repl))\n",
    "                    if not any(value.taint_in(t) for t in repl if isinstance(t, tstr)):\n",
    "                        continue\n",
    "                    new_arr = []\n",
    "                    for k, token in enumerate(repl):\n",
    "                        if not isinstance(token, tstr) or not value.taint_in(token):\n",
    "                            new_arr.append(token)\n",
    "                        else:\n",
    "                            append = True\n",
    "                            arr = token.split(value)\n",
    "                            new_arr.extend(\n",
    "                                list(sum(zip(arr,\n",
    "                                             len(arr) * [nt_var]), ()))[:-1])\n",
    "                    tree[key] = tuple(i for i in new_arr if i)\n",
    "                if append:\n",
    "                    self.logger(0, \"+%s = %s\" % (nt_var, value))\n",
    "                    tree[nt_var] = set([value])\n",
    "            else:\n",
    "                tree[nt_var] = (value, )\n",
    "        return  {key: values for key, values in tree.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_grammar(traces):\n",
    "    m = Infer()\n",
    "    for inputstr, trace in traces:\n",
    "        st = TaintedTracker(inputstr, trace, files=['urllib/parse.py'])\n",
    "        dt = Miner(inputstr, st.the_vars.defs)\n",
    "        m.add_tree(dt)\n",
    "    return m.grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "for inputstr in INPUTS:\n",
    "    clear_cache()\n",
    "    with TaintedTracer(inputstr) as tracer:\n",
    "        FUNCTION(tracer())\n",
    "    traces.append((tracer.inputstr, tracer.trace))\n",
    "grammar = recover_grammar(traces)\n",
    "syntax_diagram(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tainted Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the functions we have seen so far uses string parameters to pass fragments of input around, real world parses often pass around data structures that represent the input fragments. For the standard data containers in Python, one can rely on rely on simple recursive filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(key, val):\n",
    "    tv = type(val)\n",
    "    if tv in {int, float, complex, str, bytes, bytearray}:\n",
    "        return [(key, val)]\n",
    "    elif tv in {set, frozenset, list, tuple, range}:\n",
    "        values = [e for i, elt in enumerate(val) for e in flatten(i, elt)]\n",
    "        return [(\"%s.%d\" % (key, i), v) for i, v in values]\n",
    "    elif tv is dict:\n",
    "        values = [e for k, elt in val.items() for e in flatten(k, elt)]\n",
    "        return [(\"%s.%s\" % (key, k), v) for k, v in values]\n",
    "    elif tv is tstr:\n",
    "        return [(key, val)]\n",
    "    elif hasattr(val,'__dict__'):\n",
    "        values = [e for k, elt in val.__dict__.items() for e in flatten(k, elt)]\n",
    "        return [(\"%s.%s\" % (key, k), v) for k, v in values]\n",
    "    else:\n",
    "        return [(key, repr(v))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to account for custom data structures other than containers is to rely on its `repr()`. That is, both `str()` and `repr()` relies on string methods that we have overridden in the tainted string. Hence if any of the string fragments are tainted, their return will also tainted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaintedVars(TaintedVars):\n",
    "    def update(self, values):\n",
    "        vals = [(k1, v1) for k, v in values.items() for k1, v1 in flatten(k, v)]\n",
    "        for k, v in vals:\n",
    "            self.set_kv(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the choices here is whether to track the input parameters as variables (not just as input parameters) or only the local variable values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accounting for reassignments in loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaintedVars(TaintedVars):\n",
    "    def __init__(self, stack):\n",
    "        self.accessed_scop_var = {}\n",
    "        self.taint_register = {}\n",
    "        super().__init__(stack)\n",
    "\n",
    "    def var_init(self, var):\n",
    "        if var not in self.accessed_scop_var:\n",
    "            self.accessed_scop_var[var] = 0\n",
    "\n",
    "    def var_assign(self, var):\n",
    "        self.accessed_scop_var[var] += 1\n",
    "\n",
    "    def var_name(self, var):\n",
    "        t = self.accessed_scop_var[var]\n",
    "        return \"%s[%d:%d]\" % (var, self.istack.height(), t)\n",
    "\n",
    "    def set_kv(self, var, val):\n",
    "        self.var_init(var)\n",
    "        sa_var = self.var_name(var)\n",
    "        if sa_var not in self.defs:\n",
    "            self.defs[sa_var] = val\n",
    "            self.taint_register[str(val.taint)] = sa_var\n",
    "        else:  # possible reassignment\n",
    "            if self.taint_register.get(str(val.taint)) is None:  # a change in taint\n",
    "                self.var_assign(var)\n",
    "                sa_var = self.var_name(var)\n",
    "                self.defs[sa_var] = val\n",
    "                self.taint_register[str(val.taint)] = sa_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "for inputstr in INPUTS:\n",
    "    clear_cache()\n",
    "    with TaintedTracer(inputstr) as tracer:\n",
    "        FUNCTION(tracer())\n",
    "    traces.append((tracer.inputstr, tracer.trace))\n",
    "grammar = recover_grammar(traces)\n",
    "syntax_diagram(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is essentially that, with greater detail, we can no longer match the keys across different inputs. That is, the variable at each particular loop iteration has a different name, and it is no longer clear how to join them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Lessons Learned\n",
    "\n",
    "* Given a set of inputs, we can learn an input grammar by examining variable values during execution.\n",
    "* The resulting grammars can be used right during fuzzing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "_Link to subsequent chapters (notebooks) here, as in:_\n",
    "\n",
    "* [use _mutations_ on existing inputs to get more valid inputs](MutationFuzzer.ipynb)\n",
    "* [use _grammars_ (i.e., a specification of the input format) to get even more valid inputs](Grammars.ipynb)\n",
    "* [reduce _failing inputs_ for efficient debugging](Reducer.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "\\cite{Lin2008}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercises\n",
    "\n",
    "_Close the chapter with a few exercises such that people have things to do.  To make the solutions hidden (to be revealed by the user), have them start with_\n",
    "\n",
    "```markdown\n",
    "**Solution.**\n",
    "```\n",
    "\n",
    "_Your solution can then extend up to the next title (i.e., any markdown cell starting with `#`)._\n",
    "\n",
    "_Running `make metadata` will automatically add metadata to the cells such that the cells will be hidden by default, and can be uncovered by the user.  The button will be introduced above the solution._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Exercise 1: _Title_\n",
    "\n",
    "_Text of the exercise_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "# Some code that is part of the exercise\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "_Some more text for the exercise_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** _Some text for the solution_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# Some code for the solution\n",
    "2 + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "_Some more text for the solution_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution": "hidden",
    "solution2": "hidden",
    "solution2_first": true,
    "solution_first": true
   },
   "source": [
    "### Exercise 2: _Title_\n",
    "\n",
    "_Text of the exercise_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "solution": "hidden",
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** _Solution for the exercise_"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.2",
    "jupytext_version": "0.8.6"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
