{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Mining Input Grammars\n",
    "\n",
    "So far, the grammars we have seen have been mostly specified manually – that is, you (or the person knowing the input format) had to design and write a grammar in the first place.  While the grammars we have seen so far have been rather simple, creating a grammar for complex inoputs can involve quite some effort.  In this chapter, we therefore introduce techniques that automatically _mine_ grammars from programs – by executing the programs and observing how they process which parts of the input.  In conjunction with a grammar fuzzer, this allows us to (1) take a program, (2) extract its input grammar, and (3) fuzz it with high efficiency and effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Prerequisites**\n",
    "\n",
    "* You should have read the [chapter on grammars](Grammars.ipynb).\n",
    "* The [chapter on configuration fuzzing](ConfigurationFuzzer.ipynb) introduces grammar mining for configuration options, as well as observing variables and values during execution.\n",
    "* The concept of parsing from [chapter on parsers](Parser.ipynb) is also useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fuzzingbook_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the `parse_vehicle()` and `process_inventory()`  methods from the [chapter on parsers](Parser.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_van(year, company, model):\n",
    "    desc = \"We have a %s %s van from %s vintage.\" % (company, model, year)\n",
    "    iyear = int(year)\n",
    "    if iyear > 2010:\n",
    "        return \"%s\\nIt is a recent model!\" % desc\n",
    "    else:\n",
    "        return \"%s\\nIt is an old but reliable model!\" % desc\n",
    "\n",
    "def process_car(year, company, model):\n",
    "    desc = \"We have a %s %s car from %s vintage.\" % (company, model, year)\n",
    "    iyear = int(year)\n",
    "    if iyear > 2016:\n",
    "        return \"%s\\nIt is a recent model!\" % desc\n",
    "    else:\n",
    "        return \"%s\\nIt is an old but reliable model!\" % desc\n",
    "\n",
    "def process_vehicle(vehicle):\n",
    "    year, kind, company, model, *_ = vehicle.split(',')\n",
    "    if kind == 'van':\n",
    "        return process_van(year, company, model)\n",
    "    elif kind == 'car':\n",
    "        return process_car(year, company, model)\n",
    "    else:\n",
    "        raise Exception('Invalid entry')\n",
    "\n",
    "\n",
    "def process_inventory(inventory):\n",
    "    result = []\n",
    "    for vehicle in inventory.split('\\n'):\n",
    "        r = process_vehicle(vehicle)\n",
    "        result.append(r)\n",
    "    return \"\\n\".join(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few sample inputs to `process_inventory()` are given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory = \"\"\"\\\n",
    "1997,van,Ford,E350\n",
    "2000,car,Mercury,Cougar\n",
    "1999,car,Chevy,Venture\\\n",
    "\"\"\"\n",
    "print(process_inventory(inventory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found from the [chapter on parsers](Parser.ipynb) that coarse grammars do not work well for fuzzing when the input format includes details expressed only in code. That is, even though we have the formal specification of CSV files ([RFC 4180](https://tools.ietf.org/html/rfc4180)), the inventory system includes further rules as to what is expected at each index of the CSV file. The solution of simply recombining existing inputs, while practical, is incomplete. In particular, it relies on a formal input specification being available in the first place. However, we have no assurance that the program obeys the input specification given.\n",
    "\n",
    "One of the ways out of this predicament is to interrogate the program under test as to what its input specification is. That is, if the program under test is written in a recursive descent style, with specific methods responsible for handling specific parts of the input, one can recover the parse tree, by observing the process of parsing. Further, one can recover a reasonable approximation of the grammar by abstraction from multiple input trees.\n",
    "\n",
    "The idea is as follows\n",
    "* The assumption (1) is that the program is written in such a fashion that specific methods are responsible for parsing specific fragments of the program. This includes almost all ad hoc parsers.\n",
    "* We hook into the Python execution and observe values of variables as they get generated in different methods.\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## A Simple Grammar Miner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we want to obtain the grammar for the function `process_inventory()` which is our function under test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Under Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEHICLES = inventory.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple miners can be defeated by lookaheads which uses part of the input fragment to decide if we should process the fragment. It is in our interest to avoid those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOKAHEAD=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recording Occurrence of Input Values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a few inputs that can be used, as listed below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get qualified name of a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Context:\n",
    "    def __init__(self, frame, track_caller=True):\n",
    "        self.method = self._method(frame)\n",
    "        self.parameter_names = self._get_parameters(frame)\n",
    "        self.file_name = self._file_name(frame)\n",
    "        self.parent = Context(frame.f_back,\n",
    "                              False) if track_caller and frame.f_back else None\n",
    "\n",
    "    def _get_parameters(self, frame):\n",
    "        return [\n",
    "            frame.f_code.co_varnames[i]\n",
    "            for i in range(frame.f_code.co_argcount)\n",
    "        ]\n",
    "\n",
    "    def _file_name(self, frame):\n",
    "        return frame.f_code.co_filename\n",
    "    \n",
    "    def _method(self, frame):\n",
    "        return frame.f_code.co_name\n",
    "\n",
    "    def all_vars(self, frame):\n",
    "        return frame.f_locals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `traceit()` is used to record all *non trivial* string variables (with length more than 2 characters) and values occurring during execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracer:\n",
    "    def __init__(self, inputstr, files=[]):\n",
    "        self.inputstr, self.files, self.trace = inputstr, files, []\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.oldtrace = sys.gettrace()\n",
    "        sys.settrace(self.trace_event)\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        sys.settrace(self.oldtrace)\n",
    "\n",
    "    def tracing_var(self, k, v):\n",
    "        return isinstance(v, str)\n",
    "\n",
    "    def tracing_context(self, cxt, event, arg):\n",
    "        if not self.files:\n",
    "            return True\n",
    "        return any(cxt.file_name.endswith(f) for f in self.files)\n",
    "\n",
    "    def trace_event(self, frame, event, arg):\n",
    "        cxt = Context(frame)\n",
    "        if not self.tracing_context(cxt, event, arg):\n",
    "            return self.trace_event\n",
    "\n",
    "        my_vars = [(k, v) for k, v in cxt.all_vars(frame).items()\n",
    "                   if self.tracing_var(k, v)]\n",
    "        self.trace.append((event, arg, cxt, my_vars))\n",
    "        return self.trace_event\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.inputstr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker:\n",
    "    def __init__(self, inputstr, trace, **kwargs):\n",
    "        self.the_vars = {}\n",
    "        self.trace = trace\n",
    "        self.inputstr = inputstr\n",
    "        self.options(kwargs)\n",
    "        self.process()\n",
    "        \n",
    "    def options(self, kwargs):\n",
    "        pass\n",
    "\n",
    "    def include(self, var, value):\n",
    "        return len(value) > LOOKAHEAD and value in self.inputstr\n",
    "\n",
    "    def track_event(self, event, arg, cxt, my_vars):\n",
    "        self.the_vars.update({k: v for k, v in my_vars if self.include(k, v)})\n",
    "\n",
    "    def process(self):\n",
    "        for event, arg, cxt, my_vars in self.trace:\n",
    "            self.track_event(event, arg, cxt, my_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace\n",
    "\n",
    "The `trace_function()` hooks into the Python trace functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with Tracer(VEHICLES[0]) as tracer:\n",
    "    process_vehicle(tracer())\n",
    "\n",
    "tracker = Tracker(tracer.inputstr, tracer.trace)\n",
    "for k,v in tracker.the_vars.items():\n",
    "    print(k, '=', repr(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting a Derivation Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from Grammars import START_SYMBOL, syntax_diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GrammarFuzzer import GrammarFuzzer, FasterGrammarFuzzer, display_tree, tree_to_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert a variable name into a grammar nonterminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each pair _VAR_, _VALUE_ found:\n",
    "\n",
    "1. We search for occurrences of _VALUE_ in the grammar\n",
    "2. We replace them by <_VAR_>\n",
    "3. We add a new rule <_VAR_> $\\rightarrow$ <_VALUE_> to the grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Miner:\n",
    "    def __init__(self, my_input, my_assignments, **kwargs):\n",
    "        self.my_input = my_input\n",
    "        self.my_assignments = my_assignments\n",
    "        self.log = kwargs.get('log') or False\n",
    "        self.tree = self.get_derivation_tree()\n",
    "\n",
    "    def logger(self, indent, var):\n",
    "        if self.log:\n",
    "            print('\\t' * indent, var)\n",
    "\n",
    "    def nonterminal(self, var):\n",
    "        return \"<\" + var.lower() + \">\"\n",
    "\n",
    "    def to_tree(self, key=START_SYMBOL):\n",
    "        if key not in self.tree:\n",
    "            return (key, [])\n",
    "        children = [self.to_tree(c) for c in self.tree[key]]\n",
    "        return (key, children)\n",
    "\n",
    "    def get_derivation_tree(self):\n",
    "        tree = {START_SYMBOL: (self.my_input, )}\n",
    "        my_assignments = self.my_assignments.copy()\n",
    "\n",
    "        while True:\n",
    "            new_rules = []\n",
    "            for var, value in my_assignments.items():\n",
    "                self.logger(0, \"%s = %s\" % (var, value))\n",
    "                for key, repl in tree.items():\n",
    "                    self.logger(1, \"%s : %s\" % (key, repl))\n",
    "                    if not any(value in t for t in repl):\n",
    "                        continue\n",
    "                    alt_key = self.nonterminal(var)\n",
    "                    new_arr = []\n",
    "                    for k, token in enumerate(repl):\n",
    "                        if not value in token:\n",
    "                            new_arr.append(token)\n",
    "                        else:\n",
    "                            arr = token.split(value)\n",
    "                            new_arr.extend(\n",
    "                                list(sum(zip(arr,\n",
    "                                             len(arr) * [alt_key]), ()))[:-1])\n",
    "                    tree[key] = tuple(i for i in new_arr if i)\n",
    "                    new_rules.append((var, alt_key, value))\n",
    "\n",
    "            if not new_rules:\n",
    "                break  # Nothing to expand anymore\n",
    "\n",
    "            for (var, alt_key, value) in new_rules:\n",
    "                tree[alt_key] = (value, )\n",
    "                self.logger(0, \"+%s = %s\" % (alt_key, value))\n",
    "\n",
    "                # Do not expand this again\n",
    "                del my_assignments[var]\n",
    "\n",
    "        return {key: values for key, values in tree.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, trace the execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = []\n",
    "for VEHICLE in VEHICLES:\n",
    "    print(VEHICLE)\n",
    "    with Tracer(VEHICLE) as tracer:\n",
    "        process_inventory(tracer())\n",
    "    assignments = Tracker(tracer.inputstr, tracer.trace).the_vars\n",
    "    trees.append((tracer.inputstr, assignments))\n",
    "    for var, val in assignments.items():\n",
    "        print(var + \" = \" + repr(val))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "csv_dt = []\n",
    "for inputstr, assignments in trees:\n",
    "    print(inputstr)\n",
    "    dt = Miner(inputstr, assignments)\n",
    "    csv_dt.append(dt)\n",
    "    display_tree(dt.to_tree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLS = [\n",
    "    'http://user:pass@www.google.com:80/?q=path#ref',\n",
    "    'https://www.cispa.saarland:80/',\n",
    "    'http://www.fuzzingbook.org/#News',\n",
    "    'ftp://freebsd.org/releases/5.8'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, clear_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_dt = []\n",
    "for URL in URLS:\n",
    "    clear_cache()\n",
    "    print(URL)\n",
    "    with Tracer(URL, ['urllib/parse.py']) as tracer:\n",
    "        urlparse(tracer())\n",
    "    dt = Miner(tracer.inputstr, Tracker(tracer.inputstr, tracer.trace).the_vars)\n",
    "    url_dt.append(dt)\n",
    "    display_tree(dt.to_tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Recovering Grammar from Derivation Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Infer:\n",
    "    def __init__(self):\n",
    "        self.grammar = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Infer(Infer):\n",
    "    def add_tree(self, t):\n",
    "        merged_grammar = {}\n",
    "        for key in list(self.grammar.keys()) + list(t.tree.keys()):\n",
    "            alternates = set(self.grammar.get(key, []))\n",
    "            if key in t.tree:\n",
    "                alternates.add(''.join(t.tree[key]))\n",
    "            merged_grammar[key] = list(alternates)\n",
    "        self.grammar = merged_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Infer()\n",
    "for dt in csv_dt:\n",
    "    i.add_tree(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax_diagram(i.grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_grammar(traces):\n",
    "    m = Infer()\n",
    "    for inputstr, trace in traces:\n",
    "        dt = Miner(inputstr, Tracker(inputstr, trace).the_vars)\n",
    "        m.add_tree(dt)\n",
    "    return m.grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "for inputstr in URLS:\n",
    "    clear_cache()\n",
    "    with Tracer(inputstr, ['urllib/parse.py']) as tracer:\n",
    "        urlparse(tracer())\n",
    "    traces.append((tracer.inputstr, tracer.trace))\n",
    "grammar = recover_grammar(traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax_diagram(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = GrammarFuzzer(grammar)\n",
    "for i in range(10):\n",
    "    print(f.fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar Miner with Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputStack(object):\n",
    "    def __init__(self, i):\n",
    "        self.original = i\n",
    "        self.inputs = []\n",
    "        \n",
    "    def height(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def has(self, val):\n",
    "        return any(val in var for var in self.inputs[-1].values())\n",
    "\n",
    "    def ignored(self, val):\n",
    "        return not (isinstance(val, str) and len(val) > LOOKAHEAD)\n",
    "\n",
    "    def include(self, k, val):\n",
    "        if self.ignored(val):\n",
    "            return False\n",
    "        return self.has(val) if self.inputs else val in self.original\n",
    "\n",
    "    def push(self, inputs):\n",
    "        my_inputs = {k: v for k, v in inputs.items() if self.include(k, v)}\n",
    "        self.inputs.append(my_inputs)\n",
    "\n",
    "    def pop(self):\n",
    "        return self.inputs.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proxy the dictionary so that it will only update if it does not already contain a value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vars(object):\n",
    "    def __init__(self, stack):\n",
    "        self.defs = {START_SYMBOL: stack.original}\n",
    "        self.istack = stack\n",
    "        \n",
    "    def set_kv(self, k, v):\n",
    "        if k not in self.defs:\n",
    "            self.defs[k] = v\n",
    "\n",
    "    def update(self, v):\n",
    "        for k,v in v.items():\n",
    "            self.set_kv(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackTracker(Tracker):\n",
    "    def __init__(self, inputstr, trace, **kwargs):\n",
    "        self.istack = InputStack(inputstr)\n",
    "        self.the_vars = Vars(self.istack)\n",
    "        self.trace = trace\n",
    "        self.options(kwargs)\n",
    "        self.process()\n",
    "\n",
    "    def options(self, kwargs):\n",
    "        self.track_params = kwargs.get('track_params') or True\n",
    "        self.track_vars = kwargs.get('track_vars') or True\n",
    "        self.track_return = kwargs.get('track_return') or False\n",
    "\n",
    "    def include(self, var, value):\n",
    "        return self.istack.include(var, value)\n",
    "\n",
    "    def get_params(self, cxt, all_vars):\n",
    "        return {\n",
    "            \"%s:%s\" % (cxt.method, k): v\n",
    "            for k, v in all_vars if k in cxt.parameter_names\n",
    "        }\n",
    "\n",
    "    def on_call(self, arg, cxt, my_vars):\n",
    "        my_parameters = {\n",
    "            k: v\n",
    "            for k, v in self.get_params(cxt, my_vars).items()\n",
    "            if not self.istack.ignored(v)\n",
    "        }\n",
    "        self.istack.push(my_parameters)\n",
    "        if self.track_params:\n",
    "            self.the_vars.update(my_parameters)\n",
    "\n",
    "    def on_line(self, arg, cxt, my_vars):\n",
    "        if self.track_vars:\n",
    "            qvars = {\"%s:%s\" % (cxt.method, k): v for k, v in my_vars}\n",
    "            my_vars = {\n",
    "                var: value\n",
    "                for var, value in qvars.items() if self.include(var, value)\n",
    "            }\n",
    "            if not self.track_params:\n",
    "                my_vars = {\n",
    "                    var: value\n",
    "                    for var, value in my_vas.items() if var not in param_names\n",
    "                }\n",
    "            self.the_vars.update(my_vars)\n",
    "\n",
    "    def on_return(self, arg, cxt, my_vars):\n",
    "        self.istack.pop()\n",
    "        self.on_line(arg, cxt, my_vars)\n",
    "        if self.track_return:\n",
    "            var = '(<-%s)' % cxt.method\n",
    "            self.the_vars.update_vars({var: arg})\n",
    "\n",
    "    def track_event(self, event, arg, cxt, my_vars):\n",
    "        if event == 'call':\n",
    "            return self.on_call(arg, cxt, my_vars)\n",
    "\n",
    "        if event == 'return':\n",
    "            return self.on_return(arg, cxt, my_vars)\n",
    "\n",
    "        if event == 'exception':\n",
    "            return\n",
    "\n",
    "        self.on_line(arg, cxt, my_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to modify `traceit()` to be aware of events now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url_traces = []\n",
    "for inputstr in URLS:\n",
    "    clear_cache()\n",
    "    with Tracer(inputstr, ['urllib/parse.py']) as tracer:\n",
    "        urlparse(tracer())\n",
    "    sm = StackTracker(tracer.inputstr, tracer.trace)\n",
    "    url_traces.append((tracer.inputstr, sm))\n",
    "    for k,v in sm.the_vars.defs.items():\n",
    "        print(k, v)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the following we do not account for parameters getting reassigned values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each (VAR, VALUE) found:\n",
    "* We search for occurrences of VALUE in the grammar\n",
    "* We replace them by VAR\n",
    "* We add a new rule VAR -> VALUE to the grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Miner(Miner):\n",
    "    def get_derivation_tree(self):\n",
    "        my_assignments = self.my_assignments.copy()\n",
    "        tree = {}\n",
    "        for var, value in my_assignments.items():\n",
    "            nt_var = var if var == START_SYMBOL else self.nonterminal(var)\n",
    "            self.logger(0, \"%s = %s\" % (nt_var, value))\n",
    "            if tree:\n",
    "                append = False\n",
    "                for key, repl in tree.items():\n",
    "                    self.logger(1, \"%s : %s\" % (key, repl))\n",
    "                    if not any(value in t for t in repl):\n",
    "                        continue\n",
    "                    new_arr = []\n",
    "                    for k, token in enumerate(repl):\n",
    "                        if not value in token:\n",
    "                            new_arr.append(token)\n",
    "                        else:\n",
    "                            append = True\n",
    "                            arr = token.split(value)\n",
    "                            new_arr.extend(\n",
    "                                list(sum(zip(arr,\n",
    "                                             len(arr) * [nt_var]), ()))[:-1])\n",
    "                    tree[key] = tuple(i for i in new_arr if i)\n",
    "                if append:\n",
    "                    self.logger(0, \"+%s = %s\" % (nt_var, value))\n",
    "                    tree[nt_var] = set([value])\n",
    "            else:\n",
    "                tree[nt_var] = (value, )\n",
    "        return  {key: values for key, values in tree.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "with Tracer(URLS[2], ['urllib/parse.py']) as tracer:\n",
    "    urlparse(tracer())\n",
    "sm = StackTracker(tracer.inputstr, tracer.trace)\n",
    "dt = Miner(tracer.inputstr, sm.the_vars.defs)\n",
    "display_tree(dt.to_tree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_grammar(traces):\n",
    "    m = Infer()\n",
    "    for inputstr, trace in traces:\n",
    "        st = StackTracker(inputstr, trace)\n",
    "        dt = Miner(inputstr, st.the_vars.defs)\n",
    "        m.add_tree(dt)\n",
    "    return m.grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "traces = []\n",
    "for inputstr in URLS:\n",
    "    clear_cache()\n",
    "    with Tracer(inputstr, ['urllib/parse.py']) as tracer:\n",
    "        urlparse(tracer())\n",
    "    traces.append((tracer.inputstr, tracer.trace))\n",
    "grammar = recover_grammar(traces)\n",
    "syntax_diagram(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tainted Miner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from InformationFlow import tstr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we expand any object to a list of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(key, val):\n",
    "    # Should we limit flatened objects to repr ~ tstr here or during call?\n",
    "    tv = type(val)\n",
    "    if tv in {int, float, complex, str, bytes, bytearray}:\n",
    "        return [(key, val)]\n",
    "    elif tv in {set, frozenset, list, tuple, range}:\n",
    "        values = [e for i, elt in enumerate(val) for e in flatten(i, elt)]\n",
    "        return [(\"%s.%d\" % (key, i), v) for i, v in values]\n",
    "    elif tv is dict:\n",
    "        values = [e for k, elt in val.items() for e in flatten(k, elt)]\n",
    "        return [(\"%s.%s\" % (key, k), v) for k, v in values]\n",
    "    elif tv is tstr:\n",
    "        return [(key, val)]\n",
    "    elif hasattr(val,'__dict__'):\n",
    "        values = [e for k, elt in val.__dict__.items() for e in flatten(k, elt)]\n",
    "        return [(\"%s.%s\" % (key, k), v) for k, v in values]\n",
    "    else:\n",
    "        return [(key, repr(v))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tainted Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a simple miner, we do not need the input stack. All that we need is the ability to identify reassignments in variables. However, it makes life a little simpler if we can annotate variables with the stack depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaintedStack(InputStack):\n",
    "    # height has ignored include push pop\n",
    "    def __init__(self, i):  # same as original\n",
    "        self.original = i\n",
    "        self.inputs = []\n",
    "\n",
    "    # has is used only with include\n",
    "    def has(self, val):\n",
    "        assert False\n",
    "\n",
    "    def ignored(self, val):\n",
    "        return not (isinstance(repr(val), tstr))\n",
    "\n",
    "    # used from push (and Tracker)\n",
    "    def include(self, k, val):\n",
    "        if self.ignored(val):\n",
    "            return False\n",
    "        return val.taint_in(self.original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to account for custom data structures other than containers is to rely on its `repr()`. That is, both `str()` and `repr()` relies on string methods that we have overridden in the tainted string. Hence if any of the string fragments are tainted, their return will also tainted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tainted Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaintedVars(Vars):\n",
    "    def __init__(self, stack):\n",
    "        self.accessed_scop_var = {}\n",
    "        self.taint_register = {}\n",
    "        super().__init__(stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaintedVars(TaintedVars):\n",
    "    def update(self, values):\n",
    "        vals = [(k1, v1) for k, v in values.items() for k1, v1 in flatten(k, v)]\n",
    "        for k, v in vals:\n",
    "            self.set_kv(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaintedVars(TaintedVars):\n",
    "    def var_init(self, var):\n",
    "        if var not in self.accessed_scop_var:\n",
    "            self.accessed_scop_var[var] = 0\n",
    "\n",
    "    def var_assign(self, var):\n",
    "        self.accessed_scop_var[var] += 1\n",
    "\n",
    "    def var_name(self, var):\n",
    "        t = self.accessed_scop_var[var]\n",
    "        return \"%s[%d]\" % (var, t) # TODO: figure out how to deal with stack/vars stack height\n",
    "\n",
    "    def set_kv(self, var, val):\n",
    "        self.var_init(var)\n",
    "        sa_var = self.var_name(var)\n",
    "        if sa_var not in self.defs:\n",
    "            self.defs[sa_var] = val\n",
    "            self.taint_register[str(val.taint)] = sa_var\n",
    "        else:  # possible reassignment\n",
    "            if self.taint_register.get(str(val.taint)) is None:  # a change in taint\n",
    "                self.var_assign(var)\n",
    "                sa_var = self.var_name(var)\n",
    "                self.defs[sa_var] = val\n",
    "                self.taint_register[str(val.taint)] = sa_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tainted Tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaintedTracer(Tracer):\n",
    "    def __init__(self, inputstr, files=[]):\n",
    "        self.inputstr = tstr(inputstr, parent=None)\n",
    "        self.trace = []\n",
    "        self.files = files\n",
    "  \n",
    "    def tracing_var(self, k, v):\n",
    "        return isinstance(repr(v), tstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tainted Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaintedTracker(StackTracker):\n",
    "    def __init__(self, inputstr, trace, **kwargs):\n",
    "        self.istack = TaintedStack(inputstr)\n",
    "        self.the_vars = TaintedVars(self.istack)\n",
    "        self.trace = trace\n",
    "        self.options(kwargs)\n",
    "        self.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_grammar(traces):\n",
    "    m = Infer()\n",
    "    for inputstr, trace in traces:\n",
    "        st = TaintedTracker(inputstr, trace)\n",
    "        dt = Miner(inputstr, st.the_vars.defs)\n",
    "        m.add_tree(dt)\n",
    "    return m.grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "with TaintedTracer(URLS[0], ['urllib/parse.py']) as tracer:\n",
    "    urlparse(tracer())\n",
    "sm = TaintedTracker(tracer.inputstr, tracer.trace)\n",
    "#grammar = recover_grammar(traces)\n",
    "for k, v in sm.the_vars.defs.items():\n",
    "    print(\"%s = <%s> \\t %s\" % (k,v, len(v.taint)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tainted Miner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaintedMiner(Miner):\n",
    "    def get_derivation_tree(self):\n",
    "        my_assignments = self.my_assignments.copy()\n",
    "        root = (START_SYMBOL[1:-1], my_assignments[START_SYMBOL], [])\n",
    "        del my_assignments[START_SYMBOL]\n",
    "        for k,v in my_assignments.items():\n",
    "            self.insert_into_tree(root, (k,v, []))\n",
    "        return self.once_over(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaintedMiner(TaintedMiner):\n",
    "    def insert_into_tree(self, root, elt):\n",
    "        # for each children of root, see if we are a\n",
    "        # subset of taints. If none, add ourself as a first level childA\n",
    "        \n",
    "        ek, ev, eitems = elt\n",
    "        first_level = True\n",
    "        for child in root[2]:\n",
    "            if ev.taint_in(child[1]):\n",
    "                first_level = False\n",
    "                # do not break. There may be overlaps\n",
    "                self.insert_into_tree(child, elt)\n",
    "        if first_level:\n",
    "            root[2].append(elt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that all children are in the right positions. In particular, assert that there are no overlaps. (If there are overlaps, we might have to choose between one of the overlapped elements based on the height of the tree of that element. -- Remember that each element is inserted as a child to *all* matching elements, and not just the first matching one. Hence, we can afford to choose between the trees and not worry about transferring elements across."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaintedMiner(TaintedMiner):\n",
    "    def once_over(self, elt):\n",
    "        k, v, children = elt\n",
    "        new_children = []\n",
    "        old_children = children\n",
    "        while old_children:\n",
    "            ochild, *old_children = old_children\n",
    "            # look for possible overlap also here TODO\n",
    "            possible_parents = [\n",
    "                child for child in children\n",
    "                if ochild[1].taint_in(child[1]) and ochild[0:1] != child[0:1]\n",
    "            ]\n",
    "            assert len(possible_parents) <= 1\n",
    "            if possible_parents:\n",
    "                for child in possible_parents:\n",
    "                    self.insert_into_tree(child, ochild)\n",
    "            else:\n",
    "                new_children.append(ochild)\n",
    "        return (k, v, [self.once_over(c) for c in new_children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tree(tree):\n",
    "    children = [to_tree(c) for c in tree[2]]\n",
    "    if not children:\n",
    "        return (\"<%s>\" % tree[0], [(tree[1], [])])\n",
    "    return (\"<%s>\" % tree[0], children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dt = TaintedMiner(tracer.inputstr, sm.the_vars.defs)\n",
    "display_tree(to_tree(dt.tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Lessons Learned\n",
    "\n",
    "* Given a set of inputs, we can learn an input grammar by examining variable values during execution.\n",
    "* The resulting grammars can be used right during fuzzing.\n",
    "* TODO: make the point that our initial implementation is about learning regular grammar not CFG because we do not know how to handle mutually recursive and looping procedures\n",
    "* TODO: Use process_vehicle as a pervading example.\n",
    "* TODO: Mention that control flow dependencies is not tracked in dynamic taints. But it is tracked in simple miner with string inclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "_Link to subsequent chapters (notebooks) here, as in:_\n",
    "\n",
    "* [use _mutations_ on existing inputs to get more valid inputs](MutationFuzzer.ipynb)\n",
    "* [use _grammars_ (i.e., a specification of the input format) to get even more valid inputs](Grammars.ipynb)\n",
    "* [reduce _failing inputs_ for efficient debugging](Reducer.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "\\cite{Lin2008}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercises\n",
    "\n",
    "_Close the chapter with a few exercises such that people have things to do.  To make the solutions hidden (to be revealed by the user), have them start with_\n",
    "\n",
    "```markdown\n",
    "**Solution.**\n",
    "```\n",
    "\n",
    "_Your solution can then extend up to the next title (i.e., any markdown cell starting with `#`)._\n",
    "\n",
    "_Running `make metadata` will automatically add metadata to the cells such that the cells will be hidden by default, and can be uncovered by the user.  The button will be introduced above the solution._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Exercise 1: _Title_\n",
    "\n",
    "_Text of the exercise_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "# Some code that is part of the exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "_Some more text for the exercise_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** _Some text for the solution_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# Some code for the solution\n",
    "2 + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "_Some more text for the solution_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution": "hidden",
    "solution2": "hidden",
    "solution2_first": true,
    "solution_first": true
   },
   "source": [
    "### Exercise 2: _Title_\n",
    "\n",
    "_Text of the exercise_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "solution": "hidden",
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** _Solution for the exercise_"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.2",
    "jupytext_version": "0.8.6"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
