{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Mining Input Grammars\n",
    "\n",
    "So far, the grammars we have seen have been mostly specified manually – that is, you (or the person knowing the input format) had to design and write a grammar in the first place.  While the grammars we have seen so far have been rather simple, creating a grammar for complex inoputs can involve quite some effort.  In this chapter, we therefore introduce techniques that automatically _mine_ grammars from programs – by executing the programs and observing how they process which parts of the input.  In conjunction with a grammar fuzzer, this allows us to (1) take a program, (2) extract its input grammar, and (3) fuzz it with high efficiency and effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Prerequisites**\n",
    "\n",
    "* You should have read the [chapter on grammars](Grammars.ipynb).\n",
    "* The [chapter on configuration fuzzing](ConfigurationFuzzer.ipynb) introduces grammar mining for configuration options, as well as observing variables and values during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fuzzingbook_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logger(indent, var, log):\n",
    "    if log:\n",
    "        print('\\t' * indent, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## A Simple Grammar Miner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we want to obtain the grammar for the function `urlparse` from the *Python* distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Under Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, clear_cache\n",
    "FUNCTION = urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recording Occurrence of Input Values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a few inputs that can be used, as listed below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use two *global* variables -- `the_values` is used to keep track of variable assignments and `the_input` to keep track of the current input string. We will show later how to avoid these globals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS = [\n",
    "    'http://user:pass@www.google.com:80/?q=path#ref',\n",
    "    'https://www.cispa.saarland:80/',\n",
    "    'http://www.fuzzingbook.org/#News',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get qualified name of a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Context:\n",
    "    def __init__(self, frame, track_caller=True):\n",
    "        self.method = self._method(frame)\n",
    "        #self.class_name = self._class_name(frame)\n",
    "        self.parameter_names = self._get_parameters(frame)\n",
    "        self.file_name = self._file_name(frame)\n",
    "        self.parent = Context(frame.f_back,\n",
    "                              False) if track_caller and frame.f_back else None\n",
    "\n",
    "    def _class_name(self, frame):\n",
    "        class_name = frame.f_code.co_name\n",
    "        if frame.f_code.co_name == '__new__':\n",
    "            class_name = frame.f_locals[frame.f_code.co_varnames[0]].__name__\n",
    "        return class_name\n",
    "\n",
    "    def _get_parameters(self, frame):\n",
    "        return [\n",
    "            frame.f_code.co_varnames[i]\n",
    "            for i in range(frame.f_code.co_argcount)\n",
    "        ]\n",
    "\n",
    "    def _file_name(self, frame):\n",
    "        return frame.f_code.co_filename\n",
    "    \n",
    "    def _method(self, frame):\n",
    "        return frame.f_code.co_name\n",
    "\n",
    "    def all_vars(self, frame):\n",
    "        return frame.f_locals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `traceit()` is used to record all *non trivial* string variables (with length more than 2 characters) and values occurring during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracer:\n",
    "    def __init__(self, inputstr):\n",
    "        self.inputstr, self.trace = inputstr, []\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.oldtrace = sys.gettrace()\n",
    "        sys.settrace(self.traceit)\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        sys.settrace(self.oldtrace)\n",
    "\n",
    "    def include(self, k, v):\n",
    "        return isinstance(v, str)\n",
    "\n",
    "    def traceit(self, frame, event, arg):\n",
    "        cxt = Context(frame)\n",
    "        my_vars = [(k, v) for k, v in cxt.all_vars(frame).items()\n",
    "                   if self.include(k, v)]\n",
    "        self.trace.append((event, arg, cxt, my_vars))\n",
    "        return self.traceit\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.inputstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker:\n",
    "    def __init__(self, inputstr, trace, **kwargs):\n",
    "        self.the_vars = {}\n",
    "        self.trace = trace\n",
    "        self.inputstr = inputstr\n",
    "        self.options(kwargs)\n",
    "        self.process()\n",
    "        \n",
    "    def options(self, kwargs):\n",
    "        pass\n",
    "\n",
    "    def include(self, var, value):\n",
    "        return len(value) > 2 and value in self.inputstr\n",
    "\n",
    "    def trace_event(self, event, arg, ctx, my_vars):\n",
    "        self.the_vars.update({k: v for k, v in my_vars if self.include(k, v)})\n",
    "\n",
    "    def process(self):\n",
    "        for event, arg, cxt, my_vars in self.trace:\n",
    "            self.trace_event(event, arg, cxt, my_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace\n",
    "\n",
    "The `trace_function()` hooks into the Python trace functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "with Tracer(INPUTS[0]) as tracer:\n",
    "    FUNCTION(tracer())\n",
    "\n",
    "tracker = Tracker(tracer.inputstr, tracer.trace)\n",
    "for k,v in tracker.the_vars.items():\n",
    "    print(k, '=', repr(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting a Derivation Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from Grammars import START_SYMBOL, syntax_diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert a variable name into a grammar nonterminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonterminal(var):\n",
    "    return \"<\" + var.lower() + \">\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each pair _VAR_, _VALUE_ found:\n",
    "\n",
    "1. We search for occurrences of _VALUE_ in the grammar\n",
    "2. We replace them by <_VAR_>\n",
    "3. We add a new rule <_VAR_> $\\rightarrow$ <_VALUE_> to the grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_derivation_tree(my_input, my_assignments, log=False):\n",
    "    # Here's our initial tree\n",
    "    tree = {START_SYMBOL: (my_input, )}\n",
    "    my_assignments = my_assignments.copy()\n",
    "\n",
    "    # Replace as listed above\n",
    "    while True:\n",
    "        new_rules = []\n",
    "        for var, value in my_assignments.items():\n",
    "            logger(0, \"%s = %s\" % (var, value), log)\n",
    "            for key, repl in tree.items():\n",
    "                logger(1, \"%s : %s\" % (key, repl), log)\n",
    "                if not any(value in t for t in repl):\n",
    "                    continue\n",
    "                alt_key = nonterminal(var)\n",
    "                new_arr = []\n",
    "                for k, token in enumerate(repl):\n",
    "                    if not value in token:\n",
    "                        new_arr.append(token)\n",
    "                    else:\n",
    "                        # Replace value by nonterminal name\n",
    "                        arr = token.split(value)\n",
    "                        new_arr.extend(\n",
    "                            list(sum(zip(arr,\n",
    "                                         len(arr) * [alt_key]), ()))[:-1])\n",
    "                tree[key] = tuple(i for i in new_arr if i)\n",
    "                new_rules.append((var, alt_key, value))\n",
    "\n",
    "        if not new_rules:\n",
    "            break  # Nothing to expand anymore\n",
    "\n",
    "        for (var, alt_key, value) in new_rules:\n",
    "            # Add new rule to tree\n",
    "            tree[alt_key] = (value, )\n",
    "            logger(0, \"+%s = %s\" % (alt_key, value), log)\n",
    "\n",
    "            # Do not expand this again\n",
    "            del my_assignments[var]\n",
    "\n",
    "    return {key: values for key, values in tree.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, trace the execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "with Tracer(INPUTS[0]) as tracer:\n",
    "    FUNCTION(tracer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments = Tracker(tracer.inputstr, tracer.trace).the_vars\n",
    "for var, val in tracker.the_vars.items():\n",
    "    print(var + \" = \" + repr(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt0 = get_derivation_tree(tracer.inputstr, assignments)\n",
    "for k, v in dt0.items():\n",
    "    print(k, ' = ', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "with Tracer(INPUTS[1]) as tracer:\n",
    "    FUNCTION(tracer())\n",
    "dt1 = get_derivation_tree(tracer.inputstr,\n",
    "                          Tracker(tracer.inputstr, tracer.trace).the_vars)\n",
    "for k, v in dt1.items():\n",
    "    print(k, ' = ', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "with Tracer(INPUTS[2]) as tracer:\n",
    "    FUNCTION(tracer())\n",
    "dt2 = get_derivation_tree(tracer.inputstr,\n",
    "                          Tracker(tracer.inputstr, tracer.trace).the_vars)\n",
    "for k, v in dt2.items():\n",
    "    print(k, ' = ', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Recovering Grammar from Derivation Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_grammar(t):\n",
    "    return {k:[''.join(v)] for k,v in t.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tree(g, t):\n",
    "    merged_grammar = {}\n",
    "    for key in list(g.keys()) + list(t.keys()):\n",
    "        alternates = set(g.get(key, []))\n",
    "        if key in t:\n",
    "            alternates.add(''.join(t[key]))\n",
    "        merged_grammar[key] = list(alternates)\n",
    "    return merged_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_tree(to_grammar(dt1), dt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_grammar(traces):\n",
    "    merged_grammar = {}\n",
    "    for inputstr, trace in traces:\n",
    "        tree = get_derivation_tree(inputstr, Tracker(inputstr, trace).the_vars)\n",
    "        merged_grammar = add_tree(merged_grammar, tree)\n",
    "    return merged_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "for inputstr in INPUTS:\n",
    "    clear_cache()\n",
    "    with Tracer(inputstr) as tracer:\n",
    "        FUNCTION(tracer())\n",
    "    traces.append((tracer.inputstr, tracer.trace))\n",
    "\n",
    "grammar = recover_grammar(traces)\n",
    "for k,v in grammar.items():\n",
    "    print(k, ':= ', \"\\n\\t|\".join([str(s) for s in v]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax_diagram(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GrammarFuzzer import GrammarFuzzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = GrammarFuzzer(grammar)\n",
    "for i in range(10):\n",
    "    print(f.fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar Miner with Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep Track of The Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputStack(object):\n",
    "    def __init__(self, i):\n",
    "        self.original = i\n",
    "        self.inputs = []\n",
    "\n",
    "    def has(self, val):\n",
    "        return any(val in var for var in self.inputs[-1].values())\n",
    "\n",
    "    def ignored(self, val):\n",
    "        return not (isinstance(val, str) and len(val) > 2)\n",
    "\n",
    "    def include(self, k, val):\n",
    "        if self.ignored(val):\n",
    "            return False\n",
    "        return self.has(val) if self.inputs else val in self.original\n",
    "\n",
    "    def push(self, inputs):\n",
    "        my_inputs = {k: v for k, v in inputs.items() if self.include(k, v)}\n",
    "        self.inputs.append(my_inputs)\n",
    "\n",
    "    def pop(self):\n",
    "        return self.inputs.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Restrict The Input Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proxy the dictionary so that it will only update if it does not already contain a value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vars(object):\n",
    "    def __init__(self, i):\n",
    "        self.defs = {START_SYMBOL: i}\n",
    "\n",
    "    def update(self, v):\n",
    "        self.defs.update({k: v for k, v in v.items() if k not in self.defs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackTracker(Tracker):\n",
    "    def __init__(self, inputstr, trace, **kwargs):\n",
    "        self.istack = InputStack(inputstr)\n",
    "        self.the_vars = Vars(inputstr)\n",
    "        self.trace = trace\n",
    "        self.options(kwargs)\n",
    "        self.process()\n",
    "        \n",
    "    def options(self, kwargs):\n",
    "        self.files = kwargs.get('files') or []\n",
    "        self.track_params = kwargs.get('track_params') or True\n",
    "        self.track_vars = kwargs.get('track_vars') or True\n",
    "        self.track_return = kwargs.get('track_return') or False\n",
    "\n",
    "    def include(self, var, value):\n",
    "        if self.istack.ignored(value):\n",
    "            return False\n",
    "        return self.istack.include(var, value)\n",
    "\n",
    "    def get_params(self, cxt, all_vars):\n",
    "        return {\n",
    "            \"%s:%s\" % (cxt.method, k): v\n",
    "            for k, v in all_vars if k in cxt.parameter_names\n",
    "        }\n",
    "\n",
    "    def trace_event(self, event, arg, cxt, my_vars):\n",
    "        if not any(cxt.file_name.endswith(f) for f in self.files):\n",
    "            return\n",
    "        if event == 'call':\n",
    "            my_parameters = {\n",
    "                k: v\n",
    "                for k, v in self.get_params(cxt, my_vars).items()\n",
    "                if not self.istack.ignored(v)\n",
    "            }\n",
    "            self.istack.push(my_parameters)\n",
    "            if self.track_params:\n",
    "                self.the_vars.update(my_parameters)\n",
    "            return\n",
    "\n",
    "        if event == 'return':\n",
    "            self.istack.pop()\n",
    "            if self.track_return:\n",
    "                var = '(<-%s)' % cxt.method\n",
    "                self.the_vars.update_vars({var: arg})\n",
    "            return\n",
    "\n",
    "        if event == 'exception':\n",
    "            return\n",
    "\n",
    "        if self.track_vars:\n",
    "            qvars = {\"%s:%s\" % (cxt.method, k): v for k, v in my_vars}\n",
    "            my_vars = {\n",
    "                var: value\n",
    "                for var, value in qvars.items() if self.include(var, value)\n",
    "            }\n",
    "            if not self.track_params:\n",
    "                my_vars = {\n",
    "                    var: value\n",
    "                    for var, value in my_vas.items() if var not in param_names\n",
    "                }\n",
    "            self.the_vars.update(my_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to modify `traceit()` to be aware of events now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "traces = []\n",
    "for inputstr in INPUTS:\n",
    "    clear_cache()\n",
    "    with Tracer(inputstr) as tracer:\n",
    "        FUNCTION(tracer())\n",
    "    sm = StackTracker(tracer.inputstr, tracer.trace, files=['urllib/parse.py'])\n",
    "    traces.append((tracer.inputstr, sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the following we do not account for parameters getting reassigned values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each (VAR, VALUE) found:\n",
    "* We search for occurrences of VALUE in the grammar\n",
    "* We replace them by VAR\n",
    "* We add a new rule VAR -> VALUE to the grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_derivation_tree(my_input, my_assignments, log=False):\n",
    "    my_assignments = my_assignments.copy()\n",
    "    tree = {}\n",
    "    for var, value in my_assignments.items():\n",
    "        nt_var = var if var == START_SYMBOL else nonterminal(var)\n",
    "        logger(0, \"%s = %s\" % (nt_var, value), log)\n",
    "        if tree:\n",
    "            append = False\n",
    "            for key, repl in tree.items():\n",
    "                logger(1, \"%s : %s\" % (key, repl), log)\n",
    "                if not any(value in t for t in repl):\n",
    "                    continue\n",
    "                new_arr = []\n",
    "                for k, token in enumerate(repl):\n",
    "                    if not value in token:\n",
    "                        new_arr.append(token)\n",
    "                    else:\n",
    "                        append = True\n",
    "                        arr = token.split(value)\n",
    "                        new_arr.extend(\n",
    "                            list(sum(zip(arr,\n",
    "                                         len(arr) * [nt_var]), ()))[:-1])\n",
    "                tree[key] = tuple(i for i in new_arr if i)\n",
    "            if append:\n",
    "                logger(0, \"+%s = %s\" % (nt_var, value), log)\n",
    "                tree[nt_var] = set([value])\n",
    "        else:\n",
    "            tree[nt_var] = (value, )\n",
    "    return  {key: values for key, values in tree.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_grammar(traces):\n",
    "    merged_grammar = {}\n",
    "    for inputstr, assignments in traces:\n",
    "        tree = get_derivation_tree(inputstr, assignments)\n",
    "        merged_grammar = add_tree(merged_grammar, tree)\n",
    "    return merged_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "with Tracer(INPUTS[2]) as tracer:\n",
    "    FUNCTION(tracer())\n",
    "sm = StackTracker(tracer.inputstr, tracer.trace, files=['urllib/parse.py'])\n",
    "tree = get_derivation_tree(tracer.inputstr, sm.the_vars.defs)\n",
    "for k, v in tree.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "traces = []\n",
    "for inputstr in INPUTS:\n",
    "    clear_cache()\n",
    "    with Tracer(inputstr) as tracer:\n",
    "        FUNCTION(tracer())\n",
    "    sm = StackTracker(tracer.inputstr, tracer.trace, files=['urllib/parse.py'])\n",
    "    traces.append((tracer.inputstr, sm.the_vars.defs))\n",
    "grammar = recover_grammar(traces)\n",
    "for k,v in grammar.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax_diagram(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tainted Grammar Miner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from InformationFlow import tstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaintedTracer(Tracer):\n",
    "    def __init__(self, inputstr):\n",
    "        self.inputstr = tstr(inputstr, parent=None)\n",
    "        self.trace = []\n",
    "        self.istack = TaintedInputStack(inputstr)\n",
    "        self.vars = TaintedVars(inputstr)\n",
    "  \n",
    "    def include(self, k, v):\n",
    "        return isinstance(repr(v), tstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaintedInputStack(InputStack):\n",
    "    def has(self, val):\n",
    "        return any(val.taint_in(var) for var in self.inputs[-1].values())\n",
    "    \n",
    "    def ignored(self, val):\n",
    "        return not isinstance(repr(val), tstr)\n",
    "    \n",
    "    def include(self, k, val):\n",
    "        if self.ignored(val):\n",
    "            return False\n",
    "        return self.has(val) if self.inputs else val.taint_in(self.original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaintedVars(Vars):\n",
    "    def trep(self, v):\n",
    "        return v if isinstance(v, tstr) else repr(v)\n",
    "\n",
    "    def update(self, v):\n",
    "        self.defs.update(\n",
    "            {k: self.trep(v)\n",
    "             for k, v in v.items() if k not in self.defs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaintedTracker(StackTracker):\n",
    "    def __init__(self, inputstr, trace, **kwargs):\n",
    "        self.istack = TaintedInputStack(inputstr)\n",
    "        self.the_vars = TaintedVars(inputstr)\n",
    "        self.trace = trace\n",
    "        self.options(kwargs)\n",
    "        self.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can only replace a value if the taints match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_derivation_tree(my_input, my_assignments, log=False):\n",
    "    my_assignments = my_assignments.copy()\n",
    "    tree = {}\n",
    "    for var, value in my_assignments.items():\n",
    "        nt_var = var if var == START_SYMBOL else nonterminal(var)\n",
    "        logger(0, \"%s = %s\" % (nt_var, value), log)\n",
    "        if tree:\n",
    "            append = False\n",
    "            for key, repl in tree.items():\n",
    "                logger(1, \"%s : %s\" % (key, repl), log)\n",
    "                if not any(value.taint_in(t) for t in repl if isinstance(t, tstr)):\n",
    "                    continue\n",
    "                new_arr = []\n",
    "                for k, token in enumerate(repl):\n",
    "                    if not isinstance(token, tstr) or not value.taint_in(token):\n",
    "                        new_arr.append(token)\n",
    "                    else:\n",
    "                        append = True\n",
    "                        arr = token.split(value)\n",
    "                        new_arr.extend(\n",
    "                            list(sum(zip(arr,\n",
    "                                         len(arr) * [nt_var]), ()))[:-1])\n",
    "                tree[key] = tuple(i for i in new_arr if i)\n",
    "            if append:\n",
    "                logger(0, \"+%s = %s\" % (nt_var, value), log)\n",
    "                tree[nt_var] = set([value])\n",
    "        else:\n",
    "            tree[nt_var] = (value, )\n",
    "    return  {key: values for key, values in tree.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_grammar(traces):\n",
    "    merged_grammar = {}\n",
    "    for inputstr, assignments in traces:\n",
    "        tree = get_derivation_tree(inputstr, assignments)\n",
    "        merged_grammar = add_tree(merged_grammar, tree)\n",
    "    return merged_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "for inputstr in INPUTS:\n",
    "    clear_cache()\n",
    "    with TaintedTracer(inputstr) as tracer:\n",
    "        FUNCTION(tracer())\n",
    "    sm = TaintedTracker(tracer.inputstr, tracer.trace, files=['urllib/parse.py'])\n",
    "    traces.append((tracer.inputstr, sm.the_vars.defs))\n",
    "grammar = recover_grammar(traces)\n",
    "syntax_diagram(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tainted Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the functions we have seen so far uses string parameters to pass fragments of input around, real world parses often pass around data structures that represent the input fragments. For the standard data containers in Python, one can rely on rely on simple recursive filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taint_process(v):\n",
    "    tv = type(v)\n",
    "    if tv in {int, float, complex, str, bytes, bytearray}:\n",
    "        return v\n",
    "    elif tv in {set, frozenset, list, tuple, range}:\n",
    "        return tv([taint_process(i) for i in v])\n",
    "    elif tv in {dict}:  # or hasattr(v, '__dict__')\n",
    "        return {i: taint_process(v[i]) for i in v}\n",
    "    else:\n",
    "        return repr(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to account for custom data structures other than containers is to rely on its `repr()`. That is, both `str()` and `repr()` relies on string methods that we have overridden in the tainted string. Hence if any of the string fragments are tainted, their return will also tainted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaintedInputStack(TaintedInputStack):\n",
    "    def has(self, val):\n",
    "        return any(val.taint_in(var) for var in self.inputs[-1].values())\n",
    "\n",
    "    def push(self, inputs):\n",
    "        tainted = {\n",
    "            k: repr(v)\n",
    "            for k, v in inputs.items() if isinstance(repr(v), tstr)\n",
    "        }\n",
    "        if not self.inputs:\n",
    "            my_inputs = tainted\n",
    "        else:\n",
    "            my_inputs = {k: v for k, v in tainted.items() if self.has(v)}\n",
    "        self.inputs.append(my_inputs)\n",
    "\n",
    "    def pop(self):\n",
    "        return self.inputs.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the choices here is whether to track the input parameters as variables (not just as input parameters) or only the local variable values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurableTracker(StackTracker):\n",
    "    def __init__(self, inputstr):\n",
    "        super().__init__(inputstr)\n",
    "        self.istack = InputStack()\n",
    "        self.vars = TaintedVars(inputstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accounting for reassignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Lessons Learned\n",
    "\n",
    "* Given a set of inputs, we can learn an input grammar by examining variable values during execution.\n",
    "* The resulting grammars can be used right during fuzzing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "_Link to subsequent chapters (notebooks) here, as in:_\n",
    "\n",
    "* [use _mutations_ on existing inputs to get more valid inputs](MutationFuzzer.ipynb)\n",
    "* [use _grammars_ (i.e., a specification of the input format) to get even more valid inputs](Grammars.ipynb)\n",
    "* [reduce _failing inputs_ for efficient debugging](Reducer.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "\\cite{Lin2008}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercises\n",
    "\n",
    "_Close the chapter with a few exercises such that people have things to do.  To make the solutions hidden (to be revealed by the user), have them start with_\n",
    "\n",
    "```markdown\n",
    "**Solution.**\n",
    "```\n",
    "\n",
    "_Your solution can then extend up to the next title (i.e., any markdown cell starting with `#`)._\n",
    "\n",
    "_Running `make metadata` will automatically add metadata to the cells such that the cells will be hidden by default, and can be uncovered by the user.  The button will be introduced above the solution._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Exercise 1: _Title_\n",
    "\n",
    "_Text of the exercise_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "# Some code that is part of the exercise\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "_Some more text for the exercise_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** _Some text for the solution_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# Some code for the solution\n",
    "2 + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "_Some more text for the solution_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution": "hidden",
    "solution2": "hidden",
    "solution2_first": true,
    "solution_first": true
   },
   "source": [
    "### Exercise 2: _Title_\n",
    "\n",
    "_Text of the exercise_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "solution": "hidden",
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** _Solution for the exercise_"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.2",
    "jupytext_version": "0.8.6"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
