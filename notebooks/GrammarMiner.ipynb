{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Mining Input Grammars\n",
    "\n",
    "So far, the grammars we have seen have been mostly specified manually – that is, you (or the person knowing the input format) had to design and write a grammar in the first place.  While the grammars we have seen so far have been rather simple, creating a grammar for complex inputs can involve quite some effort.  In this chapter, we therefore introduce techniques that automatically _mine_ grammars from programs – by executing the programs and observing how they process which parts of the input.  In conjunction with a grammar fuzzer, this allows us to (1) take a program, (2) extract its input grammar, and (3) fuzz it with high efficiency and effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Prerequisites**\n",
    "\n",
    "* You should have read the [chapter on grammars](Grammars.ipynb).\n",
    "* The [chapter on configuration fuzzing](ConfigurationFuzzer.ipynb) introduces grammar mining for configuration options, as well as observing variables and values during execution.\n",
    "* The concept of parsing from [chapter on parsers](Parser.ipynb) is also useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the `process_inventory()`  method from the [chapter on parsers](Parser.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fuzzingbook_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Parser import process_inventory, process_vehicle, process_car, process_van, lr_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes inputs of the following form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INVENTORY = \"\"\"\\\n",
    "1997,van,Ford,E350\n",
    "2000,car,Mercury,Cougar\n",
    "1999,car,Chevy,Venture\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(process_inventory(INVENTORY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found from the [chapter on parsers](Parser.ipynb) that coarse grammars do not work well for fuzzing when the input format includes details expressed only in code. That is, even though we have the formal specification of CSV files ([RFC 4180](https://tools.ietf.org/html/rfc4180)), the inventory system includes further rules as to what is expected at each index of the CSV file. The solution of simply recombining existing inputs, while practical, is incomplete. In particular, it relies on a formal input specification being available in the first place. However, we have no assurance that the program obeys the input specification given.\n",
    "\n",
    "One of the ways out of this predicament is to interrogate the program under test as to what its input specification is. That is, if the program under test is written in a recursive descent style, with specific methods responsible for handling specific parts of the input, one can recover the parse tree, by observing the process of parsing. Further, one can recover a reasonable approximation of the grammar by abstraction from multiple input trees.\n",
    "\n",
    " _We start with the assumption (1) that the program is written in such a fashion that specific methods are responsible for parsing specific fragments of the program -- This includes almost all ad hoc parsers._\n",
    "\n",
    "The idea is as follows\n",
    "\n",
    "* Hook into the Python execution and observe the fragments of input string as they are produced and named in different methods.\n",
    "* Stitch the input fragments together in a tree structure to retrieve the **Parse Tree**.\n",
    "* Abstract common elements from multiple parse trees to produce the **Context Free Grammar** of the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## A Simple Grammar Miner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we want to obtain the input grammar for the function `process_vehicle()`. We first collect the sample inputs for this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEHICLES = INVENTORY.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen from the chapter on [configuration fuzzing](ConfigurationFuzzer.ipynb) that one can hook into the Python runtime to observe the arguments to a function and any local variables created. We have also seen that one can obtain the context of execution by inspecting the `frame` argument. Here is a simple tracer that can return the local variables and other contextual information in a traced function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INVENTORY_METHODS = {\n",
    "    'process_inventory',\n",
    "    'process_vehicle',\n",
    "    'process_van',\n",
    "    'process_car'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traceit(frame, event, arg):\n",
    "    method_name = inspect.getframeinfo(frame).function\n",
    "    if method_name not in INVENTORY_METHODS:\n",
    "        return\n",
    "    file_name = inspect.getframeinfo(frame).filename\n",
    "\n",
    "    param_names = inspect.getargvalues(frame).args\n",
    "    lineno = inspect.getframeinfo(frame).lineno\n",
    "    print(event, file_name, lineno, method_name, param_names, frame.f_locals)\n",
    "    return traceit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first obtain and save the current trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldtrace = sys.gettrace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, set our trace function as the current one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.settrace(traceit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, run the code under this trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "process_vehicle(VEHICLES[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we reset the trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.settrace(oldtrace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the interests of modularity, we expand the `traceit()` function to a full fledged class `Tracer` that acts as a *context manager*. A context manager in Python requires two methods `__enter__()` to enter the context and `__exit__()` to leave the context. We *undo* the effect of `__enter__()` in `__exit__()`, in this instance, by switching the trace back to the old trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracer:\n",
    "    def __enter__(self):\n",
    "        self.oldtrace = sys.gettrace()\n",
    "        sys.settrace(self.trace_event)\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        sys.settrace(self.oldtrace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logic in the `traceit()` function is now moved to a method `trace_event()` which is set as the trace function by the `Tracer` context manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracer(Tracer):\n",
    "    def trace_event(self, frame, event, arg):\n",
    "        method_name = inspect.getframeinfo(frame).function\n",
    "        if method_name not in INVENTORY_METHODS:\n",
    "            return\n",
    "        param_names = inspect.getargvalues(frame).args\n",
    "        lineno = inspect.getframeinfo(frame).lineno\n",
    "        local_vars = inspect.getargvalues(frame).locals\n",
    "        print(event, method_name, lineno, param_names, local_vars)\n",
    "        return self.trace_event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " That is, any function executed under it gets a tracing hook installed, and after the execution, the hook is uninstalled automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Tracer() as tracer:\n",
    "    process_vehicle(VEHICLES[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `trace_event()` relies on information from the `frame` variable which exposes Python internals. We define a `context` class that encapsulates the information that we need from the `frame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Context` class provides easy access to the information such as the current module, and parameter names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Context:\n",
    "    def __init__(self, frame, track_caller=True):\n",
    "        self.method = self._method(frame)\n",
    "        self.parameter_names = self._get_parameter_names(frame)\n",
    "        self.file_name = self._file_name(frame)\n",
    "        self.line_no = self._line(frame)\n",
    "\n",
    "    def _get_parameter_names(self, frame):\n",
    "        return inspect.getargvalues(frame).args\n",
    "\n",
    "    def _line(self, frame):\n",
    "        return inspect.getframeinfo(frame).lineno\n",
    "\n",
    "    def _file_name(self, frame):\n",
    "        return inspect.getframeinfo(frame).filename\n",
    "\n",
    "    def _method(self, frame):\n",
    "        return inspect.getframeinfo(frame).function\n",
    "\n",
    "    def _t(self):\n",
    "        return (self.file_name, self.line_no, self.method,\n",
    "                ','.join(self.parameter_names))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"%s:%d:%s(%s)\" % self._t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few convenience method that operate on the `frame` to `Context`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Context(Context):\n",
    "    def extract_vars(self, frame):\n",
    "        return inspect.getargvalues(frame).locals\n",
    "\n",
    "    def parameters(self, all_vars):\n",
    "        return {k: v for k, v in all_vars.items() if k in self.parameter_names}\n",
    "\n",
    "    def qualified(self, all_vars):\n",
    "        return {\"%s:%s\" % (self.method, k): v for k, v in all_vars.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hook printing the context to our `trace_event()` to see it in action. First we define an `event_logger()` for displaying events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_logger(event, var):\n",
    "    print({'call': '->', 'return': '<-'}.get(event, '  '), var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And use the `event_logger()` in the `trace_event()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Tracer(Tracer):\n",
    "    def trace_event(self, frame, event, arg):\n",
    "        event_logger(event, Context(frame))\n",
    "        return self.trace_event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running `process_vehicle()` under trace prints the contexts encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with Tracer() as tracer:\n",
    "    process_vehicle(VEHICLES[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `<string>` is the placeholder name for those functions executed within our functions `process_vehicle()` and `process_van()`. The Jupyter specific functions have a special `<ipython-input...>` suffix in their filename. We will show how to remove the Jupyter specific functions from the trace, next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trace produced by executing any function can get overwhelmingly large. Hence, we need restrict our attention to specific modules. Further, we also restrict our attention exclusively to `str` variables since these variables are more likely to contain input fragments. (We will show how to deal with complex objects later in exercises.)\n",
    "\n",
    "The `Context` class we developed earlier is used to decide which modules to monitor, and which variables to trace.\n",
    "\n",
    "We store the current *input string* so that it can be used to determine if any particular string fragments came from the current input string. Any optional arguments are processed separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracer(Tracer):\n",
    "    def __init__(self, my_input, **kwargs):\n",
    "        self.options(kwargs)\n",
    "        self.my_input, self.trace = my_input, []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use an optional argument `files` to indicate the specific source files we are interested in, and `methods` to indicate which specific methods that are of interest. Further, we also use `log` to specify whether verbose logging should be enabled during trace. We use the `event_logger()` method we defined earlier for logging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The options processing is as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracer(Tracer):\n",
    "    def options(self, kwargs):\n",
    "        self.files = kwargs.get('files') or []\n",
    "        self.methods = kwargs.get('methods') or []\n",
    "        self.logger = event_logger if kwargs.get(\n",
    "            'log') else lambda _evt, _var: _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `files` and `methods` are checked to determine if a particular event should be traced or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracer(Tracer):\n",
    "    def tracing_context(self, cxt, event, arg):\n",
    "        fres = any(cxt.file_name.endswith(f)\n",
    "                   for f in self.files) if self.files else True\n",
    "        mres = any(\n",
    "            cxt.method == m for m in self.methods) if self.methods else True\n",
    "        return fres and mres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the context of events, we also want to restrict our attention to specific variables. For now, we want to focus only on strings. (See the Exercises at the end of the chapter on how to extend it to other kinds of objects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracer(Tracer):\n",
    "    def tracing_var(self, k, v):\n",
    "        return isinstance(v, str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We modify the `trace_event()` to call an `on_event()` function with the context information only on the specific events we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracer(Tracer):\n",
    "    def on_event(self, event, arg, cxt, my_vars):\n",
    "        self.trace.append((event, arg, cxt, my_vars))\n",
    "\n",
    "    def trace_event(self, frame, event, arg):\n",
    "        cxt = Context(frame)\n",
    "        if not self.tracing_context(cxt, event, arg):\n",
    "            return self.trace_event\n",
    "        self.logger(event, cxt)\n",
    "\n",
    "        my_vars = {\n",
    "            k: v\n",
    "            for k, v in cxt.extract_vars(frame).items()\n",
    "            if self.tracing_var(k, v)\n",
    "        }\n",
    "        self.on_event(event, arg, cxt, my_vars)\n",
    "        return self.trace_event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Tracer` class can now focus on specific kinds of events on specific files. Further, it provides a first level filter for variables that we find interesting. For example, we want to focus specifically on variables from `process_*` methods that contain input fragments. Here is how our updated `Tracer` can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Tracer(VEHICLES[0], methods=INVENTORY_METHODS, log=True) as tracer:\n",
    "    process_vehicle(VEHICLES[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The execution produced the following trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tracer.trace:\n",
    "    print(t[0], t[2].method, dict(t[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are saving the input already in Tracer, it is redundant to specify it separately again as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with Tracer(VEHICLES[0], methods=INVENTORY_METHODS, log=True) as tracer:\n",
    "    process_vehicle(tracer.my_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `settrace()` function hooks into the Python debugging facility. When it is in operation, no debugger can hook into the program. Hence, we limit the tracer to the simplest implementation possible as given above, and implement the core of grammar mining in later stages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a `Tracker` class that processes the trace from the `Tracer`.\n",
    "\n",
    "The tracker identifies string fragments that are part of the input string, and stores them in a dictionary `my_assignments`. It saves the trace, and the corresponding input for processing. Finally it calls `process()` to process the `trace` it was given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker:\n",
    "    def __init__(self, my_input, trace, **kwargs):\n",
    "        self.options(kwargs)\n",
    "        self.my_input = my_input\n",
    "        self.trace = trace\n",
    "        self.my_assignments = {}\n",
    "        self.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the problems of using substring search is that short string sequences tend to be included in other string sequences even though they may not have come from the original string. That is, say the input fragment is `v`. It could have equally come from either `van` or `chevy`. We rely on being able to predict the exact place input where a given fragment occurred. Hence, we define a constant `FRAGMENT_LEN` such that we ignore strings up to that length. We also incorporate a logging facility as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAGMENT_LEN = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker(Tracker):\n",
    "    def options(self, kwargs):\n",
    "        self.logger = event_logger if kwargs.get(\n",
    "            'log') else lambda _evt, _var: None\n",
    "        self.fragment_len = kwargs.get('fragment_len') or FRAGMENT_LEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our tracer simply records the variable values as they occur. We next need to check if the variables contain values from the **input string**. Common ways to do this is to rely on symbolic execution or at least dynamic tainting, which are powerful, but also complex. However, one can obtain a reasonable approximation by simply relying on substring search. That is, we consider any value produced that is a substring of the original input string to have come from the original input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define `is_input_fragment()` method that relies on string inclusion to detect if the string came from the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker(Tracker):\n",
    "    def is_input_fragment(self, var, value):\n",
    "        return len(value) > self.fragment_len and value in self.my_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `is_input_fragment()` to select only a subset of variables defined, as implemented below in `fragments()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker(Tracker):\n",
    "    def fragments(self, variables):\n",
    "        return {k: v for k, v in variables.items() if self.is_input_fragment(k, v)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tracker processes each event, and at each event, it updates the dictionary `my_assignments` with the current local variables that contain strings that are part of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker(Tracker):\n",
    "    def track_event(self, event, arg, cxt, my_vars):\n",
    "        self.logger(event, (cxt.method, my_vars))\n",
    "        self.my_assignments.update(self.fragments(my_vars))\n",
    "\n",
    "    def process(self):\n",
    "        for event, arg, cxt, my_vars in self.trace:\n",
    "            self.track_event(event, arg, cxt, my_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the tracker, we can obtain the input fragments. For example, say we are only interested in strings that are at least `5` characters long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = Tracker(tracer.my_input, tracer.trace, fragment_len=5)\n",
    "for k, v in tracker.my_assignments.items():\n",
    "    print(k, '=', repr(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or strings that are `2` characters long (the default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = Tracker(tracer.my_input, tracer.trace)\n",
    "for k, v in tracker.my_assignments.items():\n",
    "    print(k, '=', repr(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembling a Derivation Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input fragments from the `Tracker` only tell half the story. The fragments may be created at different stages of parsing. Hence, we need to assemble the fragments to a  derivation tree of the input. We start with a few imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Grammars import START_SYMBOL, syntax_diagram, is_nonterminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivation tree `Integrator` is initialized with the input string, and the variable assignments, and it converts the assignments to the corresponding derivation tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Integrator:\n",
    "    def __init__(self, my_input, my_assignments, **kwargs):\n",
    "        self.options(kwargs)\n",
    "        self.my_input = my_input\n",
    "        self.my_assignments = my_assignments\n",
    "        self.tree = self.get_derivation_tree()\n",
    "\n",
    "    def options(self, kwargs):\n",
    "        self.logger = tab_logger if kwargs.get('log') else lambda _i, _v: None\n",
    "\n",
    "    def get_derivation_tree(self):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the `tab_logger()` is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tab_logger(indent, var):\n",
    "    print('\\t' * indent, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea is as follows:\n",
    "* We represent the derivation tree as a [straight line grammar](https://en.wikipedia.org/wiki/Straight-line_grammar) with each node represented by a key value pair. The key corresponds to the variable name, and the value corresponds to the representation of the value of the variable. **For now, we assume that the value assigned to a variable is stable. That is, it is never reassigned. In particular, there are no recursive calls, or multiple calls to the same function from different parts.** (We will show how to overcome this limitation later). The value representation may contain references to other nodes.\n",
    "* We start with a derivation tree with a single node -- the start symbol and the input string as its leaf.\n",
    "* For each pair _var_, _value_ found in `my_assignments`:\n",
    "\n",
    "* (1) We search for occurrences of _value_ in the grammar\n",
    "* (2) If found, we replace them by <_var_>\n",
    "* (3) If at least one replacement occurred, we add a new rule <_var_> $\\rightarrow$ <_value_> to the grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a wrapper to generate a nonterminal from a variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_nonterminal(var):\n",
    "    return \"<\" + var.lower() + \">\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to display the derivation tree being constructed. First, we define `stgrammar_to_tree()` which translates the straight line grammar to a derivaiton tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stgrammar_to_tree(tree, key=START_SYMBOL):\n",
    "    if key not in tree:\n",
    "        return (key, [])\n",
    "    children = [stgrammar_to_tree(tree, c) for c in tree[key]]\n",
    "    return (key, children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define `display_derivation_tree()` which can display a given straight line grammar as a derivation tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GrammarFuzzer import GrammarFuzzer, FasterGrammarFuzzer, display_tree, tree_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_derivation_tree(tree, key=START_SYMBOL, **kwargs):\n",
    "    display_tree(stgrammar_to_tree(tree, key), **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering our example previously, we started with the following input `1997,van,Ford,E350`. We initialize our derivation tree with this value. A definition may contain multiple tokens. Hence, we use a tuple to represent a definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivation_tree = {START_SYMBOL: ('1997,van,Ford,E350',)}\n",
    "display_derivation_tree(derivation_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we found that we had a method call `process_vehicle` with parameters `{'vehicle': '1997,van,Ford,E350'}` which is present in `my_assignments`. This is the same string as what is present in `START_SYMBOL` -- see (1). As we described above, we replace the matching part for `START_SYMBOL` with the new key (2), and add the new definition (3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_key_0 = to_nonterminal('vehicle')\n",
    "value_0 = '1997,van,Ford,E350'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the single string corresponding to `START_SYMBOL` using `value_0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = derivation_tree[START_SYMBOL][0].split(value_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to rejoin the `arr` after incorporating the key for `value_0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejoin(arr, sep):\n",
    "    return list(sum(zip(arr, len(arr) * [sep]), ()))[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = rejoin(arr, alt_key_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the input is completely replaced by `value_0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All it remains is to update the definition of `START_SYMBOL` with the new rule -- (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "derivation_tree[START_SYMBOL] = [i for i in v if i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since at least one replacement took place, we update our definitions with the new rule -- (3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivation_tree[alt_key_0] = (value_0,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how our tree looks after this update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_derivation_tree(derivation_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next input was as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_key_1 = to_nonterminal('year')\n",
    "value_1 = '1997'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our rule corresponding to `START_SYMBOL` no longer contains a reference to the fragment `\"1997\"`. However, the newly added rule corresponding to `alt_key_0` does -- (1). Hence, we update the rule corresponding to `alt_key_0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = derivation_tree[alt_key_0][0].split(value_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = rejoin(arr, alt_key_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This, as expected, replaces the string fragment `\"1997\"` with a token `<year>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We update the rule corresponding to `alt_key_0` as before -- (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivation_tree[alt_key_0] = [i for i in v if i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add the new rule to our derivation tree -- (3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivation_tree[alt_key_1] = (value_1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new tree is as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_derivation_tree(derivation_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing with the next assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_key_2 = to_nonterminal('kind')\n",
    "value_2 = 'van'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the rule corresponding to `alt_key_0` cotains a reference to `\"van\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in derivation_tree:\n",
    "    print(k, repr(derivation_tree[k]), 'has value_2:',\n",
    "          any((value_2 in v) for v in derivation_tree[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rule corresponding to `alt_key_0` has a reference to `\"van\"` only in the second term of the tuple.\n",
    "Hence, we replace the rule corresponding to `alt_key_0` in the second term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = derivation_tree[alt_key_0][1].split(value_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = rejoin(arr, alt_key_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we update the rule using both the unchanged first term, and the updated second term of the tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivation_tree[alt_key_0] = derivation_tree[alt_key_0][0:1] + \\\n",
    "    [i for i in v if i]\n",
    "derivation_tree[alt_key_2] = (value_2,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our new derivation tree is as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_derivation_tree(derivation_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to incorporate this in code. An already replaced *nonterminal* should not be checked for inclusion. So we explicitly exclude it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Integrator(Integrator):\n",
    "    def has_value(self, value, token):\n",
    "        return False if is_nonterminal(token) else (value in token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `replace_in_rule()` looks through the set of tokens in a rule, and replaces any matching fragments with the corresponding variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Integrator(Integrator):\n",
    "    def replace_in_rule(self, nt_var, value, rule):\n",
    "        fragments = []\n",
    "        applied = False\n",
    "        for token in rule:\n",
    "            if self.has_value(value, token):\n",
    "                fragments.extend(\n",
    "                    i for i in rejoin(token.split(value), nt_var) if i)\n",
    "                applied = True\n",
    "            else:\n",
    "                fragments.append(token)\n",
    "        return applied, tuple(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the `replace_in_rule()` to extract the *model*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_key_3 = to_nonterminal('model')\n",
    "value_3 = 'E350'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(derivation_tree[alt_key_0])\n",
    "m = Integrator(None, None)\n",
    "m.replace_in_rule(alt_key_3, value_3, derivation_tree[alt_key_0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should not affect rules that do not contain the given value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(derivation_tree[alt_key_1])\n",
    "m.replace_in_rule(alt_key_3, value_3, derivation_tree[alt_key_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "applied, v = m.replace_in_rule(alt_key_3, value_3, derivation_tree[alt_key_0])\n",
    "derivation_tree[alt_key_0] = v\n",
    "derivation_tree[alt_key_3] = (value_3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, our derivation tree changes as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_derivation_tree(derivation_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to apply a new definition to an entire grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Integrator(Integrator):\n",
    "    def apply_new_definition(self, tree, nt_var, value):\n",
    "        self.logger(0, \"%s = %s\" % (nt_var, repr(value)))\n",
    "        applied = False\n",
    "        for key, rule in tree.items():\n",
    "            self.logger(1, \"%s : %s\" % (key, repr(rule)))\n",
    "            applied_, res = self.replace_in_rule(nt_var, value, rule)\n",
    "            if not applied_:\n",
    "                continue\n",
    "            tree[key], applied = res, applied_\n",
    "            self.logger(1, \"%s -> %s\" % (key, repr(tree[key])))\n",
    "        return applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make life simple, we define a wrapper function `nt_var()` that will convert a token to its corresponding nonterminal symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Integrator(Integrator):\n",
    "    def nt_var(self, var):\n",
    "        return var if is_nonterminal(var) else to_nonterminal(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tryout the `apply_new_definition()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_4 = 'company'\n",
    "m = Integrator(None, None)\n",
    "alt_key_4 = m.nt_var(var_4)\n",
    "value_4 = 'Ford'\n",
    "m.apply_new_definition(derivation_tree, alt_key_4, value_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the new rules as below to our derivation tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivation_tree[alt_key_4] = (value_4, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our derivation tree now looks as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_derivation_tree(derivation_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivation_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm is implemented as `get_derivation_tree()`. The important aspect of this implementation is that we are not relying of the order in which variables are assigned. A smaller fragment could in principle occur before a larger fragment that contains it. Hence, we loop until all the rule assignments have been used up or no new rules are introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Integrator(Integrator):\n",
    "    def get_derivation_tree(self):\n",
    "        tree = {START_SYMBOL: (self.my_input, )}\n",
    "        my_vars = self.my_assignments.keys()\n",
    "\n",
    "        while my_vars:\n",
    "            self.logger(0, \"assignments: %d\" % len(my_vars))\n",
    "            remaining = set()\n",
    "            for var in my_vars:\n",
    "                nt_var, value = self.nt_var(var), self.my_assignments[var]\n",
    "                v = self.apply_new_definition(tree, nt_var, value)\n",
    "                if v:\n",
    "                    tree[nt_var] = (value, )\n",
    "                    self.logger(0, \"+%s = %s\" % (nt_var, value))\n",
    "                else:\n",
    "                    remaining.add(var)\n",
    "\n",
    "            if remaining == my_vars:\n",
    "                break\n",
    "            my_vars = remaining\n",
    "\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Integrator` is used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Tracer(VEHICLES[0]) as tracer:\n",
    "    process_vehicle(tracer.my_input)\n",
    "assignments = Tracker(tracer.my_input, tracer.trace).my_assignments\n",
    "dt = Integrator(tracer.my_input, assignments, log=True)\n",
    "dt.tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obtained derivation tree is as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_derivation_tree(Integrator(tracer.my_input, assignments).tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining all the pieces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trees = []\n",
    "for vehicle in VEHICLES:\n",
    "    print(vehicle)\n",
    "    with Tracer(vehicle) as tracer:\n",
    "        process_vehicle(tracer.my_input)\n",
    "    assignments = Tracker(tracer.my_input, tracer.trace).my_assignments\n",
    "    trees.append((tracer.my_input, assignments))\n",
    "    for var, val in assignments.items():\n",
    "        print(var + \" = \" + repr(val))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding derivation trees are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dt = []\n",
    "for inputstr, assignments in trees:\n",
    "    print(inputstr)\n",
    "    dt = Integrator(inputstr, assignments)\n",
    "    csv_dt.append(dt)\n",
    "    display_derivation_tree(dt.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Recovering Grammar from Derivation Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a class `Miner` that can combine multiple derivation trees to produce the grammar. The initial grammar is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Miner:\n",
    "    def __init__(self):\n",
    "        self.grammar = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `add_tree()` method gets a combined list of non-terminals from current grammar, and the tree to be added to the grammar, and updates the definitions of each non-terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Miner(Miner):\n",
    "    def add_tree(self, t):\n",
    "        merged_grammar = {}\n",
    "        for key in list(self.grammar.keys()) + list(t.tree.keys()):\n",
    "            alternates = set(self.grammar.get(key, []))\n",
    "            if key in t.tree:\n",
    "                alternates.add(''.join(t.tree[key]))\n",
    "            merged_grammar[key] = list(alternates)\n",
    "        self.grammar = merged_grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `add_tree()` is used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_grammar = Miner()\n",
    "for dt in csv_dt:\n",
    "    inventory_grammar.add_tree(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax_diagram(inventory_grammar.grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given execution traces from various inputs, one can define `recover_grammar()` to obtain the complete grammar from the traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Miner(Miner):\n",
    "    def update_grammar(self, inputstr, trace):\n",
    "        dt = Integrator(inputstr, Tracker(inputstr, trace).my_assignments)\n",
    "        self.add_tree(dt)\n",
    "        return self.grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_grammar(fn, inputs, **kwargs):\n",
    "    miner = Miner()\n",
    "    for inputstr in inputs:\n",
    "        with Tracer(inputstr, **kwargs) as tracer:\n",
    "            fn(tracer.my_input)\n",
    "        miner.update_grammar(tracer.my_input, tracer.trace)\n",
    "    return miner.grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1. Recovering the Inventory Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_grammar = recover_grammar(process_vehicle, VEHICLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax_diagram(inventory_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2. Recovering URL Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our algorithm is robust enough to recover grammar from real world programs. For example, the `urlparse` function in the Python `urlib` module accepts the following sample URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLS = [\n",
    "    'http://user:pass@www.google.com:80/?q=path#ref',\n",
    "    'https://www.cispa.saarland:80/',\n",
    "    'http://www.fuzzingbook.org/#News',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The urllib caches its intermediate results for faster access. Hence, we need to disable it using `clear_cache()` after every invocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, clear_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the sample URLs to recover grammar as follows. The `urlparse` function tends to cache its previous parsing results. Hence, we define a new method `url_parse()` that clears the cache before each call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_parse(url):\n",
    "    clear_cache()\n",
    "    urlparse(url)\n",
    "url_grammar = recover_grammar(url_parse, URLS, files=['urllib/parse.py'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `url_parse()` to recover grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax_diagram(url_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recovered grammar describes the URL format reasonably well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use our recovered grammar for fuzzing as follows.\n",
    "\n",
    "First, the inventory grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = GrammarFuzzer(inventory_grammar)\n",
    "for _ in range(10):\n",
    "    print(f.fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the URL grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = GrammarFuzzer(url_grammar)\n",
    "for _ in range(10):\n",
    "    print(f.fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with the Simple Miner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the problems with our simple grammar miner is the assumption that the values assigned to variables are stable. Unfortunately, that may not hold true in all cases. For example, here is a URL with a slightly different format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLS_X = URLS + ['ftp://freebsd.org/releases/5.8']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grammar generated from this set of samples is not as nice as what we got earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_grammar = recover_grammar(url_parse, URLS_X, files=['urllib/parse.py'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax_diagram(url_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, something has gone wrong.\n",
    "\n",
    "To investigate why the `url` definition has gone wrong, let us inspect the trace for the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "with Tracer(URLS_X[0]) as tracer:\n",
    "    urlparse(tracer.my_input)\n",
    "for i, t in enumerate(tracer.trace):\n",
    "    if t[0] in {'call', 'line'} and 'parse.py' in str(t[2]) and t[3]:\n",
    "        print(i, t[2]._t()[1], t[3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the value of `url` changes as the parsing progresses? This violates our assumption that the value assigned to a variable is stable. We next look at how this limitation can be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar Miner with Reassignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to uniquely identify different variables is to annotate them with *line numbers* both when they are defined and also when their value changes. Consider the code fragment below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking variable assignment locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C(cp_1):\n",
    "    c_2 = cp_1 + '@2'\n",
    "    c_3 = c_2 + '@3'\n",
    "    return c_3\n",
    "\n",
    "\n",
    "def B(bp_7):\n",
    "    b_8 = bp_7 + '@8'\n",
    "    return C(b_8)\n",
    "\n",
    "\n",
    "def A(ap_12):\n",
    "    a_13 = ap_12 + '@13'\n",
    "    a_14 = B(a_13) + '@14'\n",
    "    a_14 = a_14 + '@15'\n",
    "    a_13 = a_14 + '@16'\n",
    "    a_14 = B(a_13) + '@17'\n",
    "    a_14 = B(a_13) + '@18'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how all variables are either named corresponding to either where they are defined, or the value is annotated to indicate that it was changed.\n",
    "\n",
    "Let us run this under the trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Tracer('____') as tracer:\n",
    "    A(tracer.my_input)\n",
    "\n",
    "for t in tracer.trace:\n",
    "    print(t[0], \"%d:%s\" % (t[2].line_no, t[2].method), t[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each variables were referenced first as follows:\n",
    "\n",
    "* `cp_1` -- *call* `1:C`\n",
    "* `c_2` -- *line* `3:C` (but the previous event was *line* `2:C`)\n",
    "* `c_3` -- *line* `4:C` (but the previous event was *line* `3:C`)\n",
    "* `bp_7` -- *call* `7:B`\n",
    "* `b_8` -- *line* `9:B` (but the previous event was *line* `8:B`)\n",
    "* `ap_12` -- *call* `12:A`\n",
    "* `a_13` -- *line* `14:A` (but the previous event was *line* `13:A`)\n",
    "* `a_14` -- *line* `15:A` (the previous event was *return* `9:B`. However, the previous event in A was *line* `14:A`)\n",
    "* reassign `a_14` at *15* -- *line* `16:A` (the previous event was *line* `15:A`)\n",
    "* reassign `a_13` at *16* -- *line* `17:A` (the previous event was *line* `16:A`)\n",
    "* reassign `a_14` at *17* -- *return* `17:A` (the previous event in A was *line* `17:A`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our observations are that, if it is a call, the current location is the right one for any new variables being defined. On the other hand, if the variable being referenced for the first time (or reassigned a new value), then the  right location to consider is the previous location *in the same method invocation*. Next, let us see how we can incorporate this information into variable naming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to account for variable reassignments, we need to have a more intelligent data structure than a dictionary for storing variables. We first define a simple interface `Vars`. It acts as a container for variables, and is instantiated at `my_assignments`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Vars` stores references to variables as they occur during parsing in its internal dictionary `defs`. We initialize the dictionary with the original string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vars:\n",
    "    def __init__(self, original):\n",
    "        self.defs = {START_SYMBOL: original}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary needs two methods: `update()` that takes a set of key-value pairs to update itself, and `_set_kv()` that updates a particular key-value pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vars(Vars):\n",
    "    def _set_kv(self, k, v):\n",
    "        self.defs[k] = v\n",
    "\n",
    "    def __setitem__(self, k, v):\n",
    "        self._set_kv(k, v)\n",
    "\n",
    "    def update(self, v):\n",
    "        for k, v in v.items():\n",
    "            self._set_kv(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vars is a proxy for the internal dictionary. For example, here is how one can use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Vars('test')\n",
    "v.defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v['x'] = 'X'\n",
    "v.defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.update({'x': 'x', 'y': 'y'})\n",
    "v.defs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SingleAssignmentVars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now extend the simple `Vars` to account for variable reassignments. For this, we define `SingleAssignmentVars`.\n",
    "\n",
    "The idea for detecting reassignments and renaming variables is as follows: We keep track of the previous reassignments to particular variables using `accessed_seq_var`. It contains the last rename of any particular variable as its corresponding value. Second, we also maintain `new_vars` which contains a list of all new variables that were added on this iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleAssignmentVars(Vars):\n",
    "    def __init__(self, original):\n",
    "        self.accessed_seq_var = {}\n",
    "        self.new_vars = set()\n",
    "        super().__init__(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleAssignmentVars(SingleAssignmentVars):\n",
    "    def update(self, v):\n",
    "        self.new_vars = set()\n",
    "        for k, v in v.items():\n",
    "            self._set_kv(k, v)\n",
    "        return self.new_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable name now incorporate an index of who many reassignments it has gone through, effectively making each reassignment a unique variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleAssignmentVars(SingleAssignmentVars):\n",
    "    def var_name(self, var):\n",
    "        return \"%s[%d]\" % (var, self.accessed_seq_var[var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While storing variables, we need to first check whether it was previously known. If it is not, we need to initialize the rename count. This is accomplished by `var_access`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleAssignmentVars(SingleAssignmentVars):\n",
    "    def var_access(self, var):\n",
    "        if var not in self.accessed_seq_var:\n",
    "            self.accessed_seq_var[var] = 0\n",
    "        return self.var_name(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During a variable reassignment, we update the `accessed_seq_var` to reflect the new count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleAssignmentVars(SingleAssignmentVars):\n",
    "    def var_assign(self, var):\n",
    "        self.accessed_seq_var[var] += 1\n",
    "        self.new_vars.add(self.var_name(var))\n",
    "        return self.var_name(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This trio of methods can be used as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sav = SingleAssignmentVars('')\n",
    "sav.defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sav.var_access('v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sav.var_assign('v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning to it again increments the counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sav.var_assign('v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core of the logic is in `_set_kv()`. When a variable is being assigned, we get the sequenced variable name `s_var`. If the sequenced variable name was previously unknown in `defs`, then we have no further concerns. We add the sequenced variable to `defs`.\n",
    "\n",
    "If the variable is previously known, then it is an indication of a possible reassignment. In this case, we look at the value the variable is holding. We check if the value changed. If it has not, then it is not.\n",
    "\n",
    "If the value has changed, it is a reassignment. We first increment the variable usage sequence using `var_assign`, retrieve the new name, update the new name in `defs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleAssignmentVars(SingleAssignmentVars):\n",
    "    def _set_kv(self, var, val):\n",
    "        s_var = self.var_access(var)\n",
    "        if s_var in self.defs and self.defs[s_var] == val:\n",
    "            return\n",
    "        self.defs[self.var_assign(var)] = val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how it can be used. Assigning a variable the first time initializes its counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sav = SingleAssignmentVars('')\n",
    "sav['x'] = 'X'\n",
    "sav.defs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the variable is assigned again with the same value, it is probably not a reassignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sav['x'] = 'X'\n",
    "sav.defs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if the value changed, it is a reassignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sav['x'] = 'Y'\n",
    "sav.defs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a subtlety here. It is possible for a child method to be called from the middle of a parent method, and for both to use the same variable name with different values. In this case, when the child returns, parent will have the old variable with old value in context. With our implementation, we consider this as a reassignment. However, this is OK because adding a new reassignment is harmless, but missing one is not. Further, we will discuss later how this can be avoided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need a way to track the individual method calls as they are being made. For this we define the `ActivationRecord`. Each method invocation gets a separate identifier, and when the method call is over, the identifier is reset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationRecord:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.options(kwargs)\n",
    "        self.method_id = START_SYMBOL\n",
    "        self.method_register = 0\n",
    "        self.mstack = [self.method_id]\n",
    "\n",
    "    def enter(self, method):\n",
    "        self.method_register += 1\n",
    "        self.method_id = \"%s:%d\" % (method, self.method_register)\n",
    "        self.logger('call', \"%s%s\" % (self.indent(), self.method_id))\n",
    "        self.mstack.append(self.method_id)\n",
    "\n",
    "    def leave(self):\n",
    "        self.mstack.pop()\n",
    "        self.logger('return', \"%s%s\" % (self.indent(), self.method_id))\n",
    "        self.method_id = self.mstack[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few extra functions to make life simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationRecord(ActivationRecord):\n",
    "    def options(self, kwargs):\n",
    "        self.logger = event_logger if kwargs.get('log') else lambda _evt, _var: None\n",
    "\n",
    "    def indent(self):\n",
    "        return len(self.mstack) * \"\\t\"\n",
    "\n",
    "    def at(self, n):\n",
    "        return self.mstack[n]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(mstack) - 1\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.method_id\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr(self.method_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a convenience method to display a given stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_stack(istack):\n",
    "    def stack_to_tree(stack):\n",
    "        current, *rest = stack\n",
    "        if not rest:\n",
    "            return (repr(current), [])\n",
    "        return (repr(current), [stack_to_tree(rest)])\n",
    "    display_tree(stack_to_tree(istack.mstack), graph_attr=lr_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we can use the activation record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = ActivationRecord()\n",
    "display_stack(ar)\n",
    "ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar.enter('hello')\n",
    "display_stack(ar)\n",
    "ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar.enter('world')\n",
    "display_stack(ar)\n",
    "ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar.leave()\n",
    "display_stack(ar)\n",
    "ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar.enter('world')\n",
    "display_stack(ar)\n",
    "ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar.leave()\n",
    "display_stack(ar)\n",
    "ar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AssignmentTracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `AssignmentTracker` keeps the assignment definitions using the `SingleAssignmentVars` we defined previously. Further, it also tracks the method invocations in the activation record `ar`.\n",
    "\n",
    "It contains a number of variables. The `current_event` contains the event name that is being processed. The `var_def_lines` stores the line number where a particular variable was defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssignmentTracker(Tracker):\n",
    "    def __init__(self, my_input, trace, **kwargs):\n",
    "        self.options(kwargs)\n",
    "        self.my_input = my_input\n",
    "\n",
    "        self.current_event = None\n",
    "        self.var_def_lines = {}\n",
    "\n",
    "        self.method_init()\n",
    "        self.my_assignments = SingleAssignmentVars(my_input)\n",
    "\n",
    "        self.trace = trace\n",
    "        self.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `method_init()` method takes care of keeping track of method invocations using the activation record. Event locations is for keeping track of the locations accessed *within this method*. This is used for line number tracking of variable definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssignmentTracker(AssignmentTracker):\n",
    "    def method_init(self):\n",
    "        self.ar = ActivationRecord()\n",
    "        self.event_locations = {self.ar.method_id: []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stack looks like below when it is initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AssignmentTracker('hello', [])\n",
    "a.method_init()\n",
    "a.ar.mstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fine-tune the process, we define an optional parameter called `track_return`. During tracing a method return, Python produces a virtual variable that contains the result of the returned value. If the `track_return` is set, we capture this value as a variable.\n",
    "\n",
    "* `track_return` -- if true, add a *virtual variable* to the Vars representing the return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssignmentTracker(AssignmentTracker):\n",
    "    def options(self, kwargs):\n",
    "        self.track_return = kwargs.get('track_return') or False\n",
    "        super().options(kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There can be different kinds of events during a trace, which includes `call` when a function is entered, `return` when the function returns, `exception` when an exception is thrown and `line` when a statement is executed.\n",
    "\n",
    "The previous `Tracker` was too simplistic in that it did not distinguish between the different events. We rectify that and define `on_call()`, `on_return()`, and `on_line()` respectively that gets called on their corresponding events.\n",
    "\n",
    "Note that `on_line()` is called also for `on_return()`. The reason is that, Python invokes the trace function *before* the corresponding line is executed. Hence, effectively, the `on_return()` is called with the binding produced by the execution of the previous statement in the environment. Our processing in effect is done on values that were bound by the previous statement. Hence, calling `on_line()` here is appropriate as it provides the event handler a chance to work on the previous binding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssignmentTracker(AssignmentTracker):\n",
    "    def update_vars(self, my_vars):\n",
    "        added_vars = self.my_assignments.update(self.fragments(my_vars))\n",
    "        self.var_location_register(added_vars)\n",
    "\n",
    "    def on_call(self, arg, cxt, my_vars):\n",
    "        self.method_enter(cxt)\n",
    "        self.update_vars(cxt.parameters(my_vars))\n",
    "\n",
    "    def on_line(self, arg, cxt, my_vars):\n",
    "        self.method_statement(cxt)\n",
    "        self.update_vars(my_vars)\n",
    "\n",
    "    def on_return(self, arg, cxt, my_vars):\n",
    "        self.on_line(arg, cxt, my_vars)\n",
    "        self.method_exit(cxt)\n",
    "\n",
    "        if not self.track_return:\n",
    "            return\n",
    "        var = '(<-%s)' % cxt.method\n",
    "        self.update_vars({var: arg})\n",
    "\n",
    "    def on_exception(self, arg, cxt, my_vara):\n",
    "        return\n",
    "\n",
    "    def track_event(self, event, arg, cxt, my_vars):\n",
    "        self.current_event = event\n",
    "        dispatch = {\n",
    "            'call': self.on_call,\n",
    "            'return': self.on_return,\n",
    "            'line': self.on_line,\n",
    "            'exception': self.on_exception\n",
    "        }\n",
    "        dispatch[event](arg, cxt, my_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define book keeping codes for `register_event()` `method_enter()` and `method_exit()` which are the methods responsible for keeping track of the method stack. The basic idea is that, each `method_enter()` represents a new method invocation. Hence it merits a new method id, which is generated from the `method_register`, and saved in the `method_id`. Since this is a new method, the method stack is extended by one element with this id. In the case of `method_exit()`, we pop the method stack, and reset the current `method_id` to what was below the current one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssignmentTracker(AssignmentTracker):\n",
    "    def method_enter(self, cxt):\n",
    "        self.ar.enter(cxt.method)\n",
    "        self.register_event(cxt)\n",
    "\n",
    "    def method_exit(self, cxt):\n",
    "        self.register_event(cxt)\n",
    "        self.ar.leave()\n",
    "\n",
    "    def method_statement(self, cxt):\n",
    "        self.register_event(cxt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the method events, we also register the event using `register_event()` which keeps track of the line numbers that were referenced in *this* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssignmentTracker(AssignmentTracker):\n",
    "    def register_event(self, cxt):\n",
    "        if self.ar.method_id not in self.event_locations:\n",
    "            self.event_locations[self.ar.method_id] = []\n",
    "        self.event_locations[self.ar.method_id].append(cxt.line_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `var_location_register()` keeps the locations of newly added variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssignmentTracker(AssignmentTracker):\n",
    "    def var_location_register(self, my_vars):\n",
    "        def loc(mid):\n",
    "            # First refernce. Check the current event. If it is call, we can use\n",
    "            # the current location info as is.\n",
    "            if self.current_event == 'call':\n",
    "                return self.event_locations[mid][-1]\n",
    "            # if it is line, then use the previous event in the current method\n",
    "            # invocation.\n",
    "            elif self.current_event == 'line':\n",
    "                return self.event_locations[mid][-2]\n",
    "            # return is similar to the line.\n",
    "            elif self.current_event == 'return':\n",
    "                return self.event_locations[mid][-2]\n",
    "            else:\n",
    "                assert False\n",
    "\n",
    "        my_loc = loc(self.ar.method_id)\n",
    "        for var in my_vars:\n",
    "            self.var_def_lines[var] = my_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use `AssignmentTracker` to track the different variables. To verify that our variable line number inference works, we recover definitions from the functions A, B and C (with data annotations removed so that the input fragments are correctly identified). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C(cp_1):\n",
    "    c_2 = cp_1\n",
    "    c_3 = c_2\n",
    "    return c_3\n",
    "\n",
    "\n",
    "def B(bp_7):\n",
    "    b_8 = bp_7\n",
    "    return C(b_8)\n",
    "\n",
    "\n",
    "def A(ap_12):\n",
    "    a_13 = ap_12\n",
    "    a_14 = B(a_13)\n",
    "    a_14 = a_14\n",
    "    a_13 = a_14\n",
    "    a_14 = B(a_13)\n",
    "    a_14 = B(a_14)[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running `A()` with sufficient input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Tracer('---xxx') as tracer:\n",
    "    A(tracer.my_input)\n",
    "tracker = AssignmentTracker(tracer.my_input, tracer.trace, log=True)\n",
    "for k, v in tracker.my_assignments.defs.items():\n",
    "    print(k, tracker.var_def_lines.get(k), '=', repr(v))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the line numbers are now correctly identified for each variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us add a final method `defined_vars()` to retrieve the variable names correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssignmentTracker(AssignmentTracker):\n",
    "    def defined_vars(self):\n",
    "        def to_lno(v):\n",
    "            if v == START_SYMBOL:\n",
    "                return v\n",
    "            else:\n",
    "                grp = re.match(r'(.+)\\[(.+)\\]', v).groups()\n",
    "                return \"%s:%d[%s]\" % (grp[0], self.var_def_lines[v], grp[1])\n",
    "\n",
    "        return {to_lno(k): v for k, v in self.my_assignments.defs.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let us try retrieving the assignments for a real world example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "traces = []\n",
    "for inputstr in URLS_X:\n",
    "    clear_cache()\n",
    "    with Tracer(inputstr, files=['urllib/parse.py']) as tracer:\n",
    "        urlparse(tracer.my_input)\n",
    "    traces.append((tracer.my_input, tracer.trace))\n",
    "\n",
    "    tracker = AssignmentTracker(tracer.my_input, tracer.trace, log=True)\n",
    "    for k, v in tracker.defined_vars().items():\n",
    "        print(k, '=', repr(v))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line numbers of variables can be verified from the source code of [urllib/parse.py](https://github.com/python/cpython/blob/3.6/Lib/urllib/parse.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recovering a Derivation Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous `get_derivation_tree` was simplistic in that it tried to check for string inclusions without regard to the order in which the variable assignments were made. However, when one considers parsing, strings are fragmented in order. That is, a larger string that includes a smaller string will be assigned to a variable *before* the smaller string is assigned to a variable.\n",
    "\n",
    "Hence, while assembling the derivation tree, we only look at variable assignments that happened *before* the current variable assignment took place. The algorithm is as follows.\n",
    "\n",
    "For each (*var*, *value*) found:\n",
    "* We search for occurrences of *value* in the rules present in the grammar\n",
    "* We replace them by <*var*>\n",
    "* We add a new rule <*var*> $\\rightarrow$ value to the grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Integrator(Integrator):\n",
    "    def get_derivation_tree(self):\n",
    "        tree = {}\n",
    "        for var in self.my_assignments:\n",
    "            nt_var, value = self.nt_var(var), self.my_assignments[var]\n",
    "            if tree:\n",
    "                v = self.apply_new_definition(tree, nt_var, value)\n",
    "                if not v:\n",
    "                    continue\n",
    "            self.logger(0, \"+%s = %s\" % (nt_var, value))\n",
    "            tree[nt_var] = (value, )\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does handling variable reassignments help with our URL examples? We look at these next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: Recovering URL Derivation Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we obtain the derivation tree of the URL 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### URL 1 derivation tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "with Tracer(URLS_X[0], files=['urllib/parse.py']) as tracer:\n",
    "    urlparse(tracer.my_input)\n",
    "sm = AssignmentTracker(tracer.my_input, tracer.trace)\n",
    "dt = Integrator(tracer.my_input, sm.defined_vars())\n",
    "display_derivation_tree(dt.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we obtain the derivation tree of URL 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### URL 4 derivation tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cache()\n",
    "with Tracer(URLS_X[-1], files=['urllib/parse.py']) as tracer:\n",
    "    urlparse(tracer.my_input)\n",
    "sm = AssignmentTracker(tracer.my_input, tracer.trace)\n",
    "dt = Integrator(tracer.my_input, sm.defined_vars())\n",
    "display_derivation_tree(dt.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivation trees seem to belong to the same grammar. Hence, we obtain the grammar for the complete set. First, we update the `recover_grammar()` to use `AssignTracker`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recover Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Miner(Miner):\n",
    "    def update_grammar(self, inputstr, trace):\n",
    "        at = AssignmentTracker(inputstr, trace)\n",
    "        dt = Integrator(inputstr, at.defined_vars())\n",
    "        self.add_tree(dt)\n",
    "        return self.grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_grammar(fn, inputs, **kwargs):\n",
    "    miner = Miner()\n",
    "    for inputstr in inputs:\n",
    "        with Tracer(inputstr, **kwargs) as tracer:\n",
    "            fn(tracer.my_input)\n",
    "        miner.update_grammar(tracer.my_input, tracer.trace)\n",
    "    return miner.grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the modified `recover_grammar()` on derivation trees obtained from URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url_grammar = recover_grammar(url_parse, URLS_X, files=['urllib/parse.py'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recovered grammar is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "syntax_diagram(url_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us fuzz a little to see if the produced values are sane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = GrammarFuzzer(url_grammar)\n",
    "for _ in range(10):\n",
    "    print(f.fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our modifications does seem to help. Next, we check whether we can still retrieve the grammar for inventory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: Recovering Inventory Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_grammar = recover_grammar(process_vehicle, VEHICLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "syntax_diagram(inventory_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using fuzzing to produce values from the grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = GrammarFuzzer(inventory_grammar)\n",
    "for _ in range(10):\n",
    "    print(f.fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with the Grammar Miner with Reassignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the problems with our grammar miner is that it doesn't yet account for the current context. That is, when replacing, a variable can replace tokens that it does not have access to (and hence, it is not a frament of). Consider this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with Tracer(INVENTORY) as tracer:\n",
    "    process_inventory(tracer.my_input)\n",
    "sm = AssignmentTracker(tracer.my_input, tracer.trace)\n",
    "dt = Integrator(tracer.my_input, sm.defined_vars())\n",
    "display_tree(stgrammar_to_tree(dt.tree), graph_attr=lr_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the derivation tree obtained is not quite what we expected. The issue is easily seen if we enable logging in the `Integrator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dt = Integrator(tracer.my_input, sm.my_assignments.defs, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for when `car` gets replaced. i.e the string `+<kind[2]> = car` in the above log. From the next loop onwards, one can see that the definition of `vehicle[2]` has changed as follows:\n",
    "\n",
    "* `<vehicle[2]> : ('2000,car,', '<company[2]>', ',', '<model[2]>')`\n",
    "* `<vehicle[2]> : ('2000,', '<kind[2]>', ',', '<company[2]>', ',', '<model[2]>')`\n",
    "\n",
    "This is as expected. However, we note that `inventory[1]` has also changed from the first to second.\n",
    "\n",
    "* `<inventory[1]> : ('<vehicle[1]>', '\\n', '<vehicle[2]>', '\\n1999,car,Chevy,Venture')`\n",
    "* `<inventory[1]> : ('<vehicle[1]>', '\\n', '<vehicle[2]>', '\\n1999,', '<kind[2]>', ',Chevy,Venture')`\n",
    "\n",
    "That is, the variable `kind[2]` replaced the value `car` in `inventory[1]` third token. However, `kind[2]` is from `process_vehicle()` which should have access only to `vehicle[2]`. The problem here is that, because of this replacement, later replacements such as `vehicle[2]` cannot occur any more. One way to overcome this is to restrict the variable replacements to only those variables that are in scope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar Miner with Scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to incorporate inspection of the variables in the current context. We already have a stack of method calls so that we can obtain the current method at any point. We need to do the same for variables.\n",
    "\n",
    "For that, we extend the `ActivationRecord` to a new class `InputStack` which holds the method invoked as well as the parameters observed. It is essentially the record of activation of the method. We start with the original input at the base of the stack, and for each new method-call, we push the parameters of that call into the stack as a new record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class InputStack(ActivationRecord):\n",
    "    def __init__(self, i, fragment_len=FRAGMENT_LEN):\n",
    "        self.inputs = [{START_SYMBOL: i}]\n",
    "        self.fragment_len = fragment_len\n",
    "        super().__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to check if a particular variable be saved, we define `in_current_record()` which checks only the last activation record for inclusion (rather than the original input string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputStack(InputStack):\n",
    "    def in_current_record(self, val):\n",
    "        return any(val in var for var in self.inputs[-1].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_istack = InputStack('hello my world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_istack.in_current_record('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_istack.in_current_record('bye')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_istack.inputs.append({'greeting': 'hello', 'location': 'world'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_istack.in_current_record('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_istack.in_current_record('my')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the method `ignored()` that returns true if either the variable is not a string, or the variable length is less than the defined `fragment_len`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputStack(InputStack):\n",
    "    def ignored(self, val):\n",
    "        return not (isinstance(val, str) and len(val) > self.fragment_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_istack = InputStack('hello world')\n",
    "my_istack.ignored(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_istack.ignored('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_istack.ignored('help')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define the `in_scope()` method that checks whether the variable needs to be ignored, and if it is not to be ignored, whether the variable value is present in the current activation record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputStack(InputStack):\n",
    "    def in_scope(self, k, val):\n",
    "        if self.ignored(val):\n",
    "            return False\n",
    "        return self.in_current_record(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we update `enter()` that pushes relevant variables in the current context to the activation record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputStack(InputStack):\n",
    "    def enter(self, method, inputs):\n",
    "        my_inputs = {k: v for k, v in inputs.items() if self.in_scope(k, v)}\n",
    "        self.inputs.append(my_inputs)\n",
    "        super().enter(method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a method returns, we also need a corresponding `leave()` to pop out the inputs and unwind the activation record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputStack(InputStack):\n",
    "    def leave(self):\n",
    "        self.inputs.pop()\n",
    "        super().leave()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ScopedVars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to update our `SingleAssignmentVars` to include information about where the variable was defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScopedVars(SingleAssignmentVars):\n",
    "    def __init__(self, original):\n",
    "        self.accessed_seq_var = {}\n",
    "        self.defs = {START_SYMBOL: (original, ':0')}\n",
    "        self.new_vars = set()\n",
    "        self.method_id = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to save the current method invocation so as to determine which variables are in scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScopedVars(ScopedVars):\n",
    "    def set_current_method(self, method):\n",
    "        self.method_id = method\n",
    "        if method not in self.accessed_seq_var:\n",
    "            self.accessed_seq_var[method] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This information is now incorporated in the variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScopedVars(ScopedVars):\n",
    "    def var_name(self, var):\n",
    "        return \"%s[%s:vseq:%d]\" % (var, self.method_id,\n",
    "                                   self.accessed_seq_var[self.method_id][var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is useful to define a method `split_var()` that can recover the information from the string constructed by `var_name()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_var(var):\n",
    "    r = r'([^:<>\\[\\]]+):([^:<>\\[\\]]+):([^:<>\\[\\]]+)\\[([^:<>\\[\\]]+):([^:<>\\[\\]]+):vseq:([^:<>\\[\\]]+)\\]'\n",
    "    v = re.match(r, var)\n",
    "    if v is None:\n",
    "        return {}\n",
    "    vals = v.groups()\n",
    "    return {\n",
    "        'method': vals[0],\n",
    "        'var': vals[1],\n",
    "        'lno': vals[2],\n",
    "        'mscope': vals[3],\n",
    "        'mseq': vals[4],\n",
    "        'vseq': vals[5]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, `var_access` simply initializes the corresponding counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScopedVars(ScopedVars):\n",
    "    def var_access(self, var):\n",
    "        if var not in self.accessed_seq_var[self.method_id]:\n",
    "            self.accessed_seq_var[self.method_id][var] = 0\n",
    "        return self.var_name(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During a variable reassignment, we update the `accessed_seq_var` to reflect the new count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScopedVars(ScopedVars):\n",
    "    def var_assign(self, var):\n",
    "        self.accessed_seq_var[self.method_id][var] += 1\n",
    "        self.new_vars.add(self.var_name(var))\n",
    "        return self.var_name(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scope Tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `InputStack` and `Vars` defined, we can now define the `ScopeTracker`. The `ScopeTracker` only saves variables if the value is present in the current activation record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScopeTracker(AssignmentTracker):\n",
    "    def __init__(self, my_input, trace, **kwargs):\n",
    "        self.options(kwargs)\n",
    "        self.current_event = None\n",
    "        self.var_def_lines = {}\n",
    "\n",
    "        self.method_init(my_input)\n",
    "        self.my_assignments = ScopedVars(my_input)\n",
    "\n",
    "        self.trace = trace\n",
    "        self.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScopeTracker(ScopeTracker):\n",
    "    def method_init(self, my_input):\n",
    "        self.ar = InputStack(my_input)\n",
    "        self.event_locations = {self.ar.method_id: []}\n",
    "\n",
    "    def method_enter(self, cxt, params):\n",
    "        self.ar.enter(cxt.method, params)\n",
    "        self.register_event(cxt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a wrapper for checking whether a variable is present in the activation record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScopeTracker(ScopeTracker):\n",
    "    def is_input_fragment(self, var, value):\n",
    "        return self.ar.in_scope(var, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `update_vars()` update the variables, and additionally annotates them with the sope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScopeTracker(ScopeTracker):\n",
    "    def update_vars(self, my_vars, r):\n",
    "        added_vars = self.my_assignments.update({\n",
    "            var: (val, self.ar.at(r))\n",
    "            for var, val in self.fragments(my_vars).items()\n",
    "        })\n",
    "        self.var_location_register(added_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define methods `on_call`, `on_line` and `on_return` that is responsible for processing of corresponding events. The `on_call()` method is similar to the `on_call()` method on parent. The main changes are that\n",
    "\n",
    "* it pushes the current (interesting) parameters on stack, and hence update the activation record\n",
    "* It updates the `my_assignments` with `var:value` pairs where the `var` is annotated with the scope where the variable is applicable. In the case of `call`, the parameters are fragments of the parent scope. Hence, we pass the record number `-2` which is the previous activation record (current activation record is at `-1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScopeTracker(ScopeTracker):\n",
    "    def on_call(self, arg, cxt, my_vars):\n",
    "        my_parameters = cxt.parameters(my_vars)\n",
    "        self.method_enter(cxt, my_parameters)\n",
    "\n",
    "        self.my_assignments.set_current_method(self.ar.method_id)\n",
    "        self.update_vars(cxt.qualified(my_parameters), -2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `on_return()` is the counterpart to `on_call()`. It pops the stack, and updates the `my_assignments` variable with a virtual parameter corresponding to the return value if the return value is being tracked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScopeTracker(ScopeTracker):\n",
    "    def on_return(self, arg, cxt, my_vars):\n",
    "        self.on_line(arg, cxt, my_vars)\n",
    "        self.method_exit(cxt)\n",
    "        self.my_assignments.set_current_method(self.ar.method_id)\n",
    "        if not self.track_return:\n",
    "            return\n",
    "        var = '(<-%s)' % cxt.method\n",
    "        self.update_vars({var: arg}, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the `on_line()` method is very similar to the parent, except that the variables for `my_assignments` are annotated with the scope. In the case of `on_line`, the variables should contain fragments of the *current* activation record. Hence, we pass the record number `-1` to retrieve the scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScopeTracker(ScopeTracker):\n",
    "    def on_line(self, arg, cxt, my_vars):\n",
    "        self.method_statement(cxt)\n",
    "        my_vars = cxt.qualified(my_vars)\n",
    "        self.update_vars(my_vars, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few convenience methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_token(token):\n",
    "    return split_var(token[1:-1]) if is_nonterminal(token) else {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can uniquely identify a variable using just its name (1), its method sequence (3), and the assignment sequence (4). retrieved from the `scope()` information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abbrev_var(var):\n",
    "    v = split_var(var)\n",
    "    return var if len(v) < 5 else \"%s:%s[%s:%s]\" % (\n",
    "        v['var'], v['lno'], v['mseq'], v['vseq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abbrev_token(var):\n",
    "    return \"<%s>\" % abbrev_var(var[1:-1]) if is_nonterminal(var) else var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `ScopeTracker` as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vehicle_traces = []\n",
    "with Tracer(INVENTORY) as tracer:\n",
    "    process_inventory(tracer.my_input)\n",
    "sm = ScopeTracker(tracer.my_input, tracer.trace)\n",
    "vehicle_traces.append((tracer.my_input, sm))\n",
    "for k, v in sm.defined_vars().items():\n",
    "    print(abbrev_var(k), '=', repr(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recovering a Derivation Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define `mseq()` to retrieve the current method context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScopeIntegrator(Integrator):\n",
    "    def mseq(self, key, dval=0):\n",
    "        return dval if key == START_SYMBOL else int(split_token(key)['mseq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference in `apply_new_definition()` is that we add a second condition that checks for scope. In particular, variables are only allowed to replace portions of string fragments that were in scope. The scope is indicated by `scope_of_var` variable. An exception is made for cases where an internal child method call may have generated a large frament. In that case, the `mseq` of the internal child method call would be larger than the current `mseq`. If so, we allow the replacement to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScopeIntegrator(ScopeIntegrator):\n",
    "    def apply_new_definition(self, tree, nt_var, value_):\n",
    "        value, scope_of_var = value_\n",
    "        mseq_of_var = self.mseq(nt_var)\n",
    "        self.logger(\n",
    "            0, \"%s = %s\\t%s\" % (nt_var, repr(value), \"[%s]\" % scope_of_var))\n",
    "        applied = False\n",
    "        for key, rule in tree.items():\n",
    "            self.logger(1, \"%s : %s\" % (key, repr(rule)))\n",
    "            if scope_of_var not in key:\n",
    "                mseq_of_key = self.mseq(key)\n",
    "                if mseq_of_var > mseq_of_key:\n",
    "                    continue\n",
    "            applied_, res = self.replace_in_rule(nt_var, value, rule)\n",
    "            if not applied_:\n",
    "                continue\n",
    "            tree[key], applied = res, applied_\n",
    "            self.logger(1, \"%s -> %s\" % (key, repr(tree[key])))\n",
    "        return applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_derivation_tree()` is almost exactly same as that of the parent, except that we now have to handle the context annotations in variable assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScopeIntegrator(ScopeIntegrator):\n",
    "    def get_derivation_tree(self):\n",
    "        tree = {}\n",
    "        for var in self.my_assignments:\n",
    "            nt_var, value = self.nt_var(var), self.my_assignments[var]\n",
    "            if tree:\n",
    "                v = self.apply_new_definition(tree, nt_var, value)\n",
    "                if not v:\n",
    "                    continue\n",
    "            self.logger(0, \"+%s = %s\" % (nt_var, repr(value[0])))  # <-- change\n",
    "            tree[nt_var] = (value[0], )  # <-- change\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We update our `stgrammar_to_tree()` method to use the new abbreviations that show only the variable name and line number where it was defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stgrammar_to_tree(tree, key=START_SYMBOL, abbrev=abbrev_token):\n",
    "    if key not in tree:\n",
    "        return (repr(key), [])\n",
    "    children = [stgrammar_to_tree(tree, c) for c in tree[key]]\n",
    "    return (abbrev(key), children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: Recovering URL Parse Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We verify that our URL parse tree recovery still works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url_dts = []\n",
    "for inputstr in URLS_X:\n",
    "    clear_cache()\n",
    "    with Tracer(inputstr, files=['urllib/parse.py']) as tracer:\n",
    "        urlparse(tracer.my_input)\n",
    "    sm = ScopeTracker(tracer.my_input, tracer.trace)\n",
    "    for k, v in sm.my_assignments.defs.items():\n",
    "        print(abbrev_var(k), '=', repr(v))\n",
    "    dt = ScopeIntegrator(tracer.my_input, sm.defined_vars())\n",
    "    display_derivation_tree(dt.tree, graph_attr=lr_graph)\n",
    "    url_dts.append(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: Recovering Inventory Parse Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we look at recovering the parse tree from `process_inventory()` which failed last time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with Tracer(INVENTORY) as tracer:\n",
    "    process_inventory(tracer.my_input)\n",
    "sm = ScopeTracker(tracer.my_input, tracer.trace)\n",
    "for k, v in sm.defined_vars().items():\n",
    "    print(abbrev_var(k), '=', repr(v))\n",
    "vehicle_dt = ScopeIntegrator(tracer.my_input, sm.defined_vars())\n",
    "display_derivation_tree(vehicle_dt.tree, graph_attr=lr_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recovered parse tree seems reasonable.\n",
    "\n",
    "One of the things that one might notice from our Example (2) is that the three subtrees -- `vehicle[2:1]`, `vehicle[4:1]` and `vehicle[6:1]` are quite alike. We will examine how this can be exploited to generate a grammar directly, next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grammar Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed how some of the children were quite alike. These children can be abstracted out directly to produce a context free grammar from a single derivation tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScopedMiner(Miner):\n",
    "    def abbrev_token(self, var):\n",
    "        return \"<%s>\" % self.abbrev_var(var[1:-1]) if is_nonterminal(\n",
    "            var) else var\n",
    "\n",
    "    def abbrev_var(self, var):\n",
    "        v = split_var(var)\n",
    "        return var if len(v) < 5 else \"%s[%s:%s]\" % (\n",
    "            v['var'], v['method'], v['lno'])\n",
    "\n",
    "    def add_tree(self, t):\n",
    "        merged_grammar = {}\n",
    "        my_tree = t.tree\n",
    "        abbrev_keys = {self.abbrev_token(k) for k in t.tree}\n",
    "        keylst = list(self.grammar.keys()) + list(abbrev_keys)\n",
    "\n",
    "        for key in keylst:\n",
    "            alternates = set(self.grammar.get(key, []))\n",
    "            if key in abbrev_keys:\n",
    "                rules = [\n",
    "                    my_tree[k] for k in my_tree if self.abbrev_token(k) == key\n",
    "                ]\n",
    "                for r in rules:\n",
    "                    if len(r) == 1:\n",
    "                        if key == self.abbrev_token(r[0]):\n",
    "                            continue\n",
    "                    alternates.add(tuple([self.abbrev_token(t) for t in r]))\n",
    "            merged_grammar[key] = list(alternates)\n",
    "        self.grammar = {k: v for k, v in merged_grammar.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grammar is in canonical form, which needs to be massaged to display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si = ScopedMiner()\n",
    "si.add_tree(vehicle_dt)\n",
    "new_grammar = {}\n",
    "for k in si.grammar:\n",
    "    new_grammar[k] = list(set([''.join(a) for a in si.grammar[k]]))\n",
    "syntax_diagram(new_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "si = ScopedMiner()\n",
    "for url_dt in url_dts:\n",
    "    si.add_tree(url_dt)\n",
    "new_grammar = {}\n",
    "for k in si.grammar:\n",
    "    new_grammar[k] = list(set([''.join(a) for a in si.grammar[k]]))\n",
    "syntax_diagram(new_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One might notice that the grammar is not entirely human readable, with a number of single token definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the last piece of the puzzle is the cleanup method `clean_grammar()`, which cleans up such definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScopedMiner(ScopedMiner):\n",
    "    def clean_grammar(self):\n",
    "        replacements = {}\n",
    "        for k in self.grammar:\n",
    "            if k == START_SYMBOL:\n",
    "                continue\n",
    "            alts = self.grammar[k]\n",
    "            if len(alts) != 1:\n",
    "                continue\n",
    "            rule = alts[0]\n",
    "            if len(rule) != 1:\n",
    "                continue\n",
    "            tok = rule[0]\n",
    "            if not is_nonterminal(tok):\n",
    "                continue\n",
    "            replacements[k] = tok\n",
    "\n",
    "        while True:\n",
    "            changed = set()\n",
    "            for k in self.grammar:\n",
    "                if k in replacements:\n",
    "                    continue\n",
    "                new_alts = []\n",
    "                for alt in self.grammar[k]:\n",
    "                    new_alt = []\n",
    "                    for t in alt:\n",
    "                        if t in replacements:\n",
    "                            new_alt.append(replacements[t])\n",
    "                            changed.add(t)\n",
    "                        else:\n",
    "                            new_alt.append(t)\n",
    "                    new_alts.append(new_alt)\n",
    "                self.grammar[k] = new_alts\n",
    "            if not changed:\n",
    "                break\n",
    "            for k in changed:\n",
    "                self.grammar.pop(k, None)\n",
    "        new_grammar = {}\n",
    "        for k in self.grammar:\n",
    "            new_grammar[k] = list(set([''.join(a) for a in self.grammar[k]]))\n",
    "        return new_grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `add_tree()` is used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si = ScopedMiner()\n",
    "si.add_tree(vehicle_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax_diagram(si.clean_grammar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScopedMiner(ScopedMiner):\n",
    "    def update_grammar(self, inputstr, trace):\n",
    "        at = ScopeTracker(inputstr, trace)\n",
    "        dt = ScopeIntegrator(inputstr, at.defined_vars())\n",
    "        self.add_tree(dt)\n",
    "        return self.grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_grammar(fn, inputs, **kwargs):\n",
    "    miner = ScopedMiner()\n",
    "    for inputstr in inputs:\n",
    "        with Tracer(inputstr, **kwargs) as tracer:\n",
    "            fn(tracer.my_input)\n",
    "        miner.update_grammar(tracer.my_input, tracer.trace)\n",
    "    return miner.clean_grammar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_grammar = recover_grammar(url_parse, URLS_X, files=['urllib/parse.py'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "syntax_diagram(url_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = GrammarFuzzer(url_grammar)\n",
    "for _ in range(10):\n",
    "    print(f.fuzz())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_grammar = recover_grammar(process_inventory, [INVENTORY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax_diagram(inventory_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = GrammarFuzzer(inventory_grammar)\n",
    "for _ in range(10):\n",
    "    print(f.fuzz())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Lessons Learned\n",
    "\n",
    "* Given a set of sample inputs for program, we can learn an input grammar by examining variable values during execution if the program relies on handwritten parsers.\n",
    "* Simple string inclusion checks are sufficient to obtain reasonably accurate grammars from real world programs.\n",
    "* The resulting grammars can be directly used for fuzzing, and can have a multiplier effect on any samples you have.\n",
    "* Notice that we use *String* inclusion testing as a way of determining whether a particular string fragment  came from the original input string. While this may seem rather error-prone compared to dynamic tainting, we note that numerous tracing tools such as `dtrace` and `ptrace` allow one to obtain the information we seek from execution of binaries directly in different platforms. However, methods for obtaining dynamic taints almost always involve instrumenting the binaries before they can be used. Hence, this method of string inclusion can be more generally applied than dynamic tainting approaches. Further, dynamic taints are often lost due to implicit transmission, or at the boundary between *Python* and *C* code. String inclusion has not such problems. Hence, our approach can often obtain better results than relying on dynamic tainting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "* [Use _mutations_ on existing inputs to get more valid inputs](MutationFuzzer.ipynb)\n",
    "* [Use _grammars_ (i.e., a specification of the input format) to get even more valid inputs](Grammars.ipynb)\n",
    "* [Reduce _failing inputs_ for efficient debugging](Reducer.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Recovering the input specification of an arbitrary program is a well researched topic. The majority of research has happened on the black box approach where nothing more is known about the program in question. The excellent reference by Higuera~\\cite{higuera2010grammatical} covers all the classical approaches. The current state of the art in black box grammar mining is described by Clark~\\cite{clark2013learning}. Our approach relies on the detail knowledge of the program in question, and also on the ability to execute the program under observation. The pioneering work in this area was done by Lin et al.~\\cite{Lin2008} who invented a way to retrieve the parse trees from top down and bottom up parsers. The current approach is based directly on the work of Hoschele et al.~\\cite{Hoschele2017}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Exercise 1: Flattening complex objects\n",
    "\n",
    "Our grammar miners only check for string fragments. However, programs may often pass containers or custom objects containing input fragments. For example, consider the plausible modification for our inventory processor, where we use a custom object `Vehicle` to carry fragments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vehicle:\n",
    "    def __init__(self, vehicle):\n",
    "        year, kind, company, model, *_ = vehicle.split(',')\n",
    "        self.year, self.kind, self.company, self.model = year, kind, company, model\n",
    "\n",
    "\n",
    "def process_inventory(inventory):\n",
    "    res = []\n",
    "    for vehicle in inventory.split('\\n'):\n",
    "        ret = process_vehicle(vehicle)\n",
    "        res.extend(ret)\n",
    "    return '\\n'.join(res)\n",
    "\n",
    "\n",
    "def process_vehicle(vehicle):\n",
    "    v = Vehicle(vehicle)\n",
    "    if v.kind == 'van':\n",
    "        return process_van(v)\n",
    "\n",
    "    elif v.kind == 'car':\n",
    "        return process_car(v)\n",
    "\n",
    "    else:\n",
    "        raise Exception('Invalid entry')\n",
    "\n",
    "\n",
    "def process_van(vehicle):\n",
    "    res = [\n",
    "        \"We have a %s %s van from %s vintage.\" % (vehicle.company,\n",
    "                                                  vehicle.model, vehicle.year)\n",
    "    ]\n",
    "    iyear = int(vehicle.year)\n",
    "    if iyear > 2010:\n",
    "        res.append(\"It is a recent model!\")\n",
    "    else:\n",
    "        res.append(\"It is an old but reliable model!\")\n",
    "    return res\n",
    "\n",
    "\n",
    "def process_car(vehicle):\n",
    "    res = [\n",
    "        \"We have a %s %s car from %s vintage.\" % (vehicle.company,\n",
    "                                                  vehicle.model, vehicle.year)\n",
    "    ]\n",
    "    iyear = int(vehicle.year)\n",
    "    if iyear > 2016:\n",
    "        res.append(\"It is a recent model!\")\n",
    "    else:\n",
    "        res.append(\"It is an old but reliable model!\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recover the grammar as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_grammar = recover_grammar(process_inventory, [INVENTORY])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new vehicle grammar is missing in details, especially as to the different models and company for a van and car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "syntax_diagram(vehicle_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is that, we are looking specifically for string objects that contain fragments of the input string during tracing. Can you modify our grammar miner to correctly account for the complex objects too?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "**Solution.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown"
   },
   "source": [
    "The problem can be understood if we execute the tracer under verbose logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "with Tracer(INVENTORY, methods=INVENTORY_METHODS, log=True) as tracer:\n",
    "    process_inventory(tracer.my_input)\n",
    "print()    \n",
    "print('Traced values:')\n",
    "for t in tracer.trace:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown"
   },
   "source": [
    "You can see that we lose track of string fragments as soon as they are incorporated into the `Vehicle` object. The way out is to trace these variables separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown"
   },
   "source": [
    "For that, we develop the `flatten()` method that given any custom complex object and its key, returns a list of flattened *key*,*value* pairs that correspond to the object passed in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "def flatten(key, val):\n",
    "    tv = type(val)\n",
    "    if isinstance(val, (int, float, complex, str, bytes, bytearray)):\n",
    "        return [(key, val)]\n",
    "    elif isinstance(val, (set, frozenset, list, tuple, range)):\n",
    "        values = [(i,e) for i, elt in enumerate(val) for e in flatten(i, elt)]\n",
    "        return [(\"%s.%d\" % (key, i), v) for i, v in values]\n",
    "    elif isinstance(val, dict):\n",
    "        values = [e for k, elt in val.items() for e in flatten(k, elt)]\n",
    "        return [(\"%s.%s\" % (key, k), v) for k, v in values]\n",
    "    elif isinstance(val, str):\n",
    "        return [(key, val)]\n",
    "    elif hasattr(val, '__dict__'):\n",
    "        values = [e for k, elt in val.__dict__.items()\n",
    "                  for e in flatten(k, elt)]\n",
    "        return [(\"%s.%s\" % (key, k), v) for k, v in values]\n",
    "    else:\n",
    "        return [(key, str(v))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown"
   },
   "source": [
    "Next, we hook the `flatten()` into the `Context` class so that the parameters we obtain are flattened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "class Context(Context):\n",
    "    def extract_vars(self, frame):\n",
    "        vals = inspect.getargvalues(frame).locals\n",
    "        return {k1:v1 for k,v in vals.items() for k1,v1 in flatten(k,v)}\n",
    "\n",
    "    def parameters(self, all_vars):\n",
    "        def check_param(k):\n",
    "            return any(k.startswith(p) for p in self.parameter_names)\n",
    "        return {k: v for k, v in all_vars.items() if check_param(k)}\n",
    "\n",
    "    def qualified(self, all_vars):\n",
    "        return {\"%s:%s\" % (self.method, k): v for k, v in all_vars.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown"
   },
   "source": [
    "With this change, we have the following trace output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "with Tracer(INVENTORY, methods=INVENTORY_METHODS, log=True) as tracer:\n",
    "    process_inventory(tracer.my_input)\n",
    "print()    \n",
    "print('Traced values:')\n",
    "for t in tracer.trace:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown"
   },
   "source": [
    "Our change seems to have worked. Let us derive the grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "vehicle_grammar = recover_grammar(process_inventory, [INVENTORY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "syntax_diagram(vehicle_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "shown"
   },
   "source": [
    "The recovered grammar contains all the details that we were able to recover before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Incorporating Taints from InformationFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been using *string inclusion* to check whether a particular fragment came from the input string. This is unsatisfactory as it required us to compromise on the size of the strings tracked, which was limited to those greater than `FRAGMENT_LEN`. Further, it is possible that a single method could process a string where a fragment repeats, but is part of different tokens. For example, an embedded comma in the CSV file would cause our parser to fail. One way to avoid this is to rely on *dynamic taints*, and check for taint inclusion rather than string inclusion.\n",
    "\n",
    "The chapter on [information flow](InformationFlow.ipynb) details how to incorporate dynamic taints. Can you update our grammar miner based on scope to use *dynamic taints* instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- **Advanced.** The *dynamic taint* approach is limited in that it can not observe implicit flows. For example, consider the fragment below.\n",
    "\n",
    "```python\n",
    "if my_fragment == 'begin':\n",
    "    return 'begin'\n",
    "```\n",
    "\n",
    "In this case, we lose track of the string `begin` that is returned even though it is dependent on the value of `my_fragment`. For such cases, a better (but costly) alternative is to rely on concolic execution and capture the constraints as it relates to input characters on each variable.\n",
    "\n",
    "The chapter on [symbolic execution](SymbolicExecution.ipynb) details how to incorporate concolic symbolic execution to program execution. Can you update our grammar miner to use *concolic exeuction* to track taints instead?\n",
    "-->"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.2",
    "jupytext_version": "0.8.6"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "374.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
