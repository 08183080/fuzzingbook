{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Fuzzing Test Suites with Mutation Analysis\n",
    "\n",
    "In the [chapter on coverage](Coverage.ipynb), we showed how one identify which parts of the program are executed by a program, and hence get a sense of the effectiveness of a set of test cases in covering the program structure. However, is structural coverage a good measure of effectiveness? One of the problems with structural coverage measures is that it fails to check whether the program executions generated by the test suite were actually correct. That is, an execution that produces a wrong output that is unnoticed by the test suite is counted exactly the same as an execution that produces the right output for coverage. Indeed, if one deletes the assertions in a typical test case, the coverage would not change for the new test suite, but the new test suite is much less useful than the original one.\n",
    "\n",
    "This is indeed, not an optimal state of affairs. How can we verify that our tests are actually useful? One alternative (hinted in the chapter on coverage) is to inject bugs into the program, and evaluate the effectiveness of test suites in catching these injected bugs. However, that that introduces another problem. How do we produce these bugs in the first place? Any manual effort is likely to be biased by the preconceptions of the developer as to where the bugs are likely to occur, and what effect it would have. Further, writing good bugs is likely to take a significant amount of time, for a very indirect benefit. Hence such a solution is not sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Mutation Analysis offers an alternative solution. The insight from Mutation Analysis is to consider the probability of insertion of a bug from the perspective of a programmer. If one assumes that the attention received by each program element in the program is sufficiently similar, one can further assume that each token in the program have a similar probability of being incorrectly transcribed. Of course, the programmer will correct any mistakes that gets detected by the compilers (or other static analysis tools). So the set of valid tokens different from the original that make it past the compilation stage is considered to be its possible set of _mutations_ that represent the _probable faults_ in the program. A test suite is then judged by its capability to detect (and hence prevent) such mutations. The proportion of such mutants detected over all _valid_ mutants produced is taken as the mutation score. In this chapter, we see how one can implement Mutation Analysis in Python programs. The mutation score obtained represents the ability of any program analysis tools to prevent faults, and can be used to judge static test suites, test generators such as fuzzers, and also static and symbolic execution frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be intuitive to consider a slightly different perspective. A test suite is a program that can be considered to accept as its input, the program to be tested.  What is the best way to evaluate such a program (the test suite)? We can essentially *fuzz* the test suite by applying small mutations to the input program, and verifying that the test suite in question does not produce unexpected behaviors. The test suite is supposed to only allow the original through; and hence any mutant that is not detected as faulty represents a bug in the test suite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Prerequisites**\n",
    "\n",
    "* You need some understanding of how a program is executed.\n",
    "* You should have read [the chapter on coverage](Coverage.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the `triangle()` program below. We want to verify that the program works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangle(a, b, c):\n",
    "    if a == b:\n",
    "        if b == c:\n",
    "            return 'Equilateral'\n",
    "        else:\n",
    "            return 'Isosceles'\n",
    "    else:\n",
    "        if b == c:\n",
    "            return \"Isosceles\"\n",
    "        else:\n",
    "            if a == c:\n",
    "                return \"Isosceles\"\n",
    "            else:\n",
    "                return \"Scalene\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes, we would like to proceed as though the program was in a different file. We can do that by producing a `Module` object in Python, and attaching the function to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_code(code, name):\n",
    "    module = imp.new_module(name)\n",
    "    exec(code, module.__dict__)\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We attach the `triangle()` function to the `shape` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = import_code(inspect.getsource(triangle), 'shape')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now invoke triangle through the module `shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape.triangle(1,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to test the `triangle()` function. For that, we define a `TestTriangle` class as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "class TestTriangle(unittest.TestCase):\n",
    "\n",
    "    def test_equilateral(self):\n",
    "        assert shape.triangle(1,1,1) == 'Equilateral'\n",
    "\n",
    "    def test_isosceles(self):\n",
    "        assert shape.triangle(1,2,1) == 'Isosceles'\n",
    "        assert shape.triangle(2,2,1) == 'Isosceles'\n",
    "        assert shape.triangle(1,2,2) == 'Isosceles'\n",
    "\n",
    "    def test_scalene(self):\n",
    "        assert shape.triangle(1,2,3) == 'Scalene'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a helper function `suite()` that looks through a given class and identifies the test functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def suite(test_class):\n",
    "    suite = unittest.TestSuite()\n",
    "    for f in test_class.__dict__:\n",
    "        if f.startswith('test_'):\n",
    "            suite.addTest(test_class(f))\n",
    "    return suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tests in `TestTriangle` class can be invoked with different test runners. The simplest is to directly invoke the `run()` method of the `TestCase`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite(TestTriangle).run(unittest.TestResult())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `TextTestRunner` class provides ability to control the verbosity of execution. It also allows one to return on the *first* failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "runner = unittest.TextTestRunner(verbosity=0, failfast=True)\n",
    "runner.run(suite(TestTriangle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the effectiveness of our test suite? As we saw in the [chapter on coverage](Coverage.ipynb), one can use structural coverage techniques such as statement coverage to obtain a measure of effectiveness of the test case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import fuzzingbook_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Coverage import Coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a function `show_coverage()` to visualize the coverage obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coverage(Coverage):\n",
    "    def show_coverage(self, fn):\n",
    "        src = inspect.getsource(fn)\n",
    "        name = fn.__name__\n",
    "        covered = set([lineno for method, lineno in self._trace if method == name])\n",
    "        for i, s in enumerate(src.split('\\n')):\n",
    "            print('%s %2d: %s' % ('#' if i + 1 in covered else ' ', i + 1, s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the program under coverage is accomplished as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Coverage() as cov:\n",
    "    suite(TestTriangle).run(unittest.TestResult())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coverage obtained is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov.show_coverage(triangle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that our test suite is reasonably good. However, does the coverage obtained tell the whole story? What of the `WeakTestTriangle` defined below? We have replaced equality assertions with somewhat weaker assertions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeakTestTriangle(unittest.TestCase):\n",
    "    def test_equilateral(self):\n",
    "        assert shape.triangle(1,1,1) == 'Equilateral'\n",
    "\n",
    "    def test_isosceles(self):\n",
    "        assert shape.triangle(1,2,1) != 'Equilateral'\n",
    "        assert shape.triangle(2,2,1) != 'Equilateral'\n",
    "        assert shape.triangle(1,2,2) != 'Equilateral'\n",
    "\n",
    "    def test_scalene(self):\n",
    "        assert shape.triangle(1,2,3) != 'Equilateral'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much coverage does it obtain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Coverage() as cov:\n",
    "    suite(WeakTestTriangle).run(unittest.TestResult())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov.show_coverage(triangle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `WeakTestTriagle` obtains exactly the same coverage as that of `TestTriangle`. However, a moment's reflection should convince one that the `WeakTestTriangle` is not as effective as `TestTriangle`. However, _coverage_ is unable to distinguish between the two test suites. What are we missing in coverage?\n",
    "The problem here is that coverage is unable to evaluate the _quality_ of our assertions. Indeed, coverage does not care about assertions at all. However, as we saw above, assertions are an extremely important part of test suite effectiveness. Hence, what we need is a way to evaluate the quality of assertions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in the [chapter on coverage](Coverage.ipynb), coverage was presented as a _proxy_ for the likelihood of a test suite to uncover bugs. What if actually try to evaluate the likelihood of a test suite to uncover bugs? All we need is to inject bugs into the program, one at a time, and count the number of such bugs that our test suite detects. The frequency of detection will provide us with the actual likelihood of the test suite to uncover bugs. This technique is called _fault injection_. Here is an example for _fault injection_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangle(a, b, c):\n",
    "    if a == b:\n",
    "        if b == c:\n",
    "            return 'Equilateral'\n",
    "        else:\n",
    "            #return 'Isosceles'\n",
    "            return None #<-- injected fault\n",
    "    else:\n",
    "        if b == c:\n",
    "            return \"Isosceles\"\n",
    "        else:\n",
    "            if a == c:\n",
    "                return \"Isosceles\"\n",
    "            else:\n",
    "                return \"Scalene\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see if our test suites are good enough to catch this fault. We first attach the function to the `shape` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = import_code(inspect.getsource(triangle), 'shape')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check whether `WeakTestTriangle` test suite can detect this change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite(WeakTestTriangle).run(unittest.TestResult())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `WeakTestTriangle` is unable to detect any changes. What about our `TestTriangle` suite?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite(TestTriangle).run(unittest.TestResult())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `TestTriangle` is able to detect this fault, which is evidence that `TestTriangle` is probably a better test suite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Fault injection_ can provide a good measure of effectiveness of a test suite, provided we have a list of possible faults. The problem is that collecting such a set of _unbiased_ faults is rather expensive. It is difficult to create good faults that are reasonably hard to detect, and it is a manual process. Given that it is a manual process, the generated faults will be biased by the preconceptions of the developer who creates it. Even when such curated faults are available, they are unlikely to be exhaustive, and likely to miss important classes of bugs, and parts of the program. Hence, _fault injection_ is an insufficient replacement for coverage. Can we do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mutation Analysis provides an alternative to a curated set of faults. The key insight is that, if one assumes that the programmer understands the program in question, the majority of errors made are very likely small transcription errors (a small number of tokens). A compiler will likely catch most of these errors. Hence, the majority of residual faults in a program is likely to be due to small (single token) variations at certain points in the structure of the program from the correct program (This particular assumption is called the *Competent Programmer Hypothesis* or the *Finite Neighborhood Hypothesis*). What about the larger faults composed of multiple changes to the program? The key insight here is that, for a significant majority of such faults, test cases that can detect a single change in isolation is very likely to detect the larger composite fault that contains it. (This assumption is called the *Coupling Effect*.) How can we use these assumptions in practice? The idea is to simply generate *all* possible *valid* variants of the program that differs from the original by a small change (such as a single token change) (Such variants are called *mutants*). Next, the given test suite is applied to each variant thus generated. Any mutant detected by the test suite is said to have been *killed* by the test suite. The effectiveness of a test suite is given by the proportion of mutants killed to the valid mutants generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next implement a simple mutation analysis framework and use it to evaluate our test suites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Mutating Programs by Deleting Statements\n",
    "\n",
    "Consider the `triangle()` program we discussed previously. A simple way to produce valid mutated version of this program is to replace some of its statements by `pass`.\n",
    "\n",
    "We begin by importing the AST manipulation modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astunparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ProgramMutator` is the main class responsible for mutation analysis of the test suite. It accepts the name of the module to be tested, and its source code. It normalizes the source code given by parsing and unparsing it once. This is required to ensure that later `diff`s between the original and mutant is not derailed by differences in whitespace comments etc.\n",
    "\n",
    "**Note.** In the real world, one should be able to obtain the source code of any given Python function. Unfortunately, with Jupyter notebooks, we are unable to obtain sources for functions defined in other notebooks. Hence, we require the source also to be provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgramMutator:\n",
    "    def __init__(self, name, src):\n",
    "        self.name = name\n",
    "        self.ast = ast.parse(src)\n",
    "        self.src = astunparse.unparse(self.ast)\n",
    "        self.nmutations = self.get_mutation_count()\n",
    "        self.un_detected = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_mutation_count()` fetches the number of possible mutations available. We will see later how this can be implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgramMutator(ProgramMutator):\n",
    "    def get_mutation_count(self):\n",
    "        sdc = StmtDeletionMutator()\n",
    "        sdc.visit(self.ast)\n",
    "        return sdc.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Mutator` provides the base class for implementing individual mutations. It accepts a list of locations to mutate. It assumes that the method `mutable_visit` is invoked on all nodes of interest as determined by the subclass. When the `Mutator` is invoked without a list of locations to mutate, it simply loops through all possible mutation points and retains a count in `self.count`. If it is invoked with a specific list of locations to mutate, the `mutable_visit()` method calls the `mutation_visit()` which performs the mutation on the node. Note that a single location can produce multiple mutations. (Hence the hashmap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mutator(ast.NodeTransformer):\n",
    "    def __init__(self, mutate_locations=None):\n",
    "        self.count = 0\n",
    "        self.mutate_locations = {} if mutate_locations is None else mutate_locations\n",
    "\n",
    "    def mutable_visit(self, node):\n",
    "        self.count += 1 # statements start at line no 1\n",
    "        if self.count in self.mutate_locations:\n",
    "            return self.mutation_visit(node)\n",
    "        return self.generic_visit(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `StmtDeletionMutator` simply hooks into all the statement processing visitors. It performs mutation by replacing the given statement with `pass`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StmtDeletionMutator(Mutator):\n",
    "    def mutation_visit(self, Node): return ast.Pass()\n",
    "    def visit_Return(self, node): return self.mutable_visit(node)\n",
    "    def visit_Delete(self, node): return self.mutable_visit(node)\n",
    "\n",
    "    def visit_Assign(self, node): return self.mutable_visit(node)\n",
    "    def visit_AnnAssign(self, node): return self.mutable_visit(node)\n",
    "    def visit_AugAssign(self, node): return self.mutable_visit(node)\n",
    "\n",
    "    def visit_Raise(self, node): return self.mutable_visit(node)\n",
    "    def visit_Assert(self, node): return self.mutable_visit(node)\n",
    "\n",
    "    def visit_Global(self, node): return self.mutable_visit(node)\n",
    "    def visit_Nonlocal(self, node): return self.mutable_visit(node)\n",
    "\n",
    "    def visit_Expr(self, node): return self.mutable_visit(node)\n",
    "\n",
    "    def visit_Pass(self, node): return self.mutable_visit(node)\n",
    "    def visit_Break(self, node): return self.mutable_visit(node)\n",
    "    def visit_Continue(self, node): return self.mutable_visit(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain the number of mutations produced for `triangle()` as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProgramMutator('shape', inspect.getsource(triangle)).nmutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a way to obtain the individual mutants. For this, we convert our `ProgramMutator` to an *iterable*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgramMutator(ProgramMutator):\n",
    "    def __iter__(self):\n",
    "        return PMIterator(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PMIterator`, which is the *iterator* class for `ProgramMutator` is defined as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMIterator:\n",
    "    def __init__(self, pm):\n",
    "        self.pm = pm\n",
    "        self.idx = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `next()` method returns the corresponding `Mutant`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMIterator(PMIterator):\n",
    "    def __next__(self):\n",
    "        i = self.idx\n",
    "        if i >= self.pm.nmutations:\n",
    "            raise StopIteration()\n",
    "        self.idx += 1\n",
    "        return Mutant(self.pm, {self.idx:[]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Mutant` class contains logic for generating mutants when given the locations to mutate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mutant:\n",
    "    def __init__(self, pm, locations):\n",
    "        self.pm = pm\n",
    "        self.i = locations\n",
    "        self.name = \"%s_%s\" % (self.pm.name, '_'.join([str(i) for i in self.i]))\n",
    "        self._src = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how it can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in ProgramMutator('shape', inspect.getsource(triangle)):\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define `mutator()` method that can be overridden by child classes if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mutant(Mutant):\n",
    "    def mutator(self, locations):\n",
    "        return StmtDeletionMutator(locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `generate_mutant()` simply calls the `mutator()` method, and passes the mutator a copy of the AST. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mutant(Mutant):\n",
    "    def generate_mutant(self, locations):\n",
    "        mutant_ast = self.mutator(locations).visit(ast.parse(self.pm.src)) # copy\n",
    "        return astunparse.unparse(mutant_ast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `src()` method returns the mutated source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mutant(Mutant):\n",
    "    def src(self):\n",
    "        if self._src is None:\n",
    "            self._src = self.generate_mutant(self.i)\n",
    "        return self._src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how one can obtain the mutants, and visualize the difference from the original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for mutant in ProgramMutator('shape', inspect.getsource(triangle)):\n",
    "    shape_src = mutant.pm.src\n",
    "    for line in difflib.unified_diff(mutant.pm.src.split('\\n'),\n",
    "                                  mutant.src().split('\\n'),\n",
    "                                  fromfile=mutant.pm.name,\n",
    "                                  tofile=mutant.name, n=3):\n",
    "        print(line)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add the `diff()` method to `Mutant` so that it can be called directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mutant(Mutant):\n",
    "    def diff(self):\n",
    "        return '\\n'.join(difflib.unified_diff(self.pm.src.split('\\n'),\n",
    "                                  self.src().split('\\n'),\n",
    "                                  fromfile='original',\n",
    "                                  tofile='mutant',\n",
    "                                         n=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to implement the actual evaluation. For doing that, we require the ability to accept the module where the test suite is defined, and invoke the test method on it. The method `getitem` accepts the test module, fixes the import entries on the test module to correctly point to the mutant module, and passes it to the test runner `MutantTestRunner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mutant(Mutant):\n",
    "    def __getitem__(self, test_module):\n",
    "        test_module.__dict__[self.pm.name] = import_code(self.src(), self.pm.name)\n",
    "        return MutantTestRunner(self, test_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MutantTestRunner` simply calls all `test_` methods on the test module, checks if the mutant was discovered, and returns the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ExpectError import ExpectTimeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MutantTestRunner:\n",
    "    def __init__(self, mutant, test_module):\n",
    "        self.mutant = mutant\n",
    "        self.tm = test_module\n",
    "        \n",
    "    def runTest(self, tc):\n",
    "        suite = unittest.TestSuite()\n",
    "        test_class = self.tm.__dict__[tc]\n",
    "        for f in test_class.__dict__:\n",
    "            if f.startswith('test_'):\n",
    "                suite.addTest(test_class(f))\n",
    "        runner = unittest.TextTestRunner(verbosity=0, failfast=True)\n",
    "        try:\n",
    "            with ExpectTimeout(1):\n",
    "                res = runner.run(suite)\n",
    "                if res.wasSuccessful():\n",
    "                    self.mutant.pm.un_detected.add(self)\n",
    "                return res\n",
    "        except SyntaxError:\n",
    "            print('Syntax Error (%s)' % self.mutant.name)\n",
    "            return None\n",
    "        raise Exception('Unhandled exception during test execution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mutation score is computed by `score()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgramMutator(ProgramMutator):\n",
    "    def score(self):\n",
    "        return (self.nmutations - len(self.un_detected))/self.nmutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we use our framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_module = sys.modules[__name__]\n",
    "for mutant in ProgramMutator('shape', inspect.getsource(triangle)):\n",
    "    mutant[test_module].runTest('WeakTestTriangle')\n",
    "mutant.pm.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `WeakTestTriangle` test suite resulted in only `20%` mutation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mutant in ProgramMutator('shape', inspect.getsource(triangle)):\n",
    "    mutant[test_module].runTest('TestTriangle')\n",
    "mutant.pm.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, we were able to achieve `100%` mutation score with `TestTriangle` test suite.\n",
    "\n",
    "Here is another example, `gcd()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ControlFlow as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcd_src = \"\"\"\\\n",
    "def gcd(a, b):\n",
    "    if a<b:\n",
    "        c: int = a\n",
    "        a: int = b\n",
    "        b: int = c\n",
    "\n",
    "    while b != 0 :\n",
    "        c: int = a\n",
    "        a: int = b\n",
    "        b: int = c % b\n",
    "    return a\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestGCD(unittest.TestCase):\n",
    "    def test_simple(self):\n",
    "        assert cfg.gcd(1,0) == 1\n",
    "        \n",
    "    def test_mirror(self):\n",
    "        assert cfg.gcd(0,1) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for mutant in ProgramMutator('cfg', gcd_src):\n",
    "    mutant[test_module].runTest('TestGCD')\n",
    "mutant.pm.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our `TestGCD` test suite is able to obtain `42%` mutation score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Weak Mutator\n",
    "\n",
    "\\todo{Add}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Lessons Learned\n",
    "\n",
    "* _Lesson one_\n",
    "* _Lesson two_\n",
    "* _Lesson three_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "_Link to subsequent chapters (notebooks) here, as in:_\n",
    "\n",
    "* [use _mutations_ on existing inputs to get more valid inputs](MutationFuzzer.ipynb)\n",
    "* [use _grammars_ (i.e., a specification of the input format) to get even more valid inputs](Grammars.ipynb)\n",
    "* [reduce _failing inputs_ for efficient debugging](Reducer.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "_Cite relevant works in the literature and put them into context, as in:_\n",
    "\n",
    "The idea of ensuring that each expansion in the grammar is used at least once goes back to Burkhardt \\cite{Burkhardt1967}, to be later rediscovered by Paul Purdom \\cite{Purdom1972}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercises\n",
    "\n",
    "_Close the chapter with a few exercises such that people have things to do.  To make the solutions hidden (to be revealed by the user), have them start with_\n",
    "\n",
    "```markdown\n",
    "**Solution.**\n",
    "```\n",
    "\n",
    "_Your solution can then extend up to the next title (i.e., any markdown cell starting with `#`)._\n",
    "\n",
    "_Running `make metadata` will automatically add metadata to the cells such that the cells will be hidden by default, and can be uncovered by the user.  The button will be introduced above the solution._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Exercise 1: _Title_\n",
    "\n",
    "_Text of the exercise_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "# Some code that is part of the exercise\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "_Some more text for the exercise_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** _Some text for the solution_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# Some code for the solution\n",
    "2 + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "_Some more text for the solution_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution": "hidden",
    "solution2": "hidden",
    "solution2_first": true,
    "solution_first": true
   },
   "source": [
    "### Exercise 2: _Title_\n",
    "\n",
    "_Text of the exercise_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "solution": "hidden",
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** _Solution for the exercise_"
   ]
  }
 ],
 "metadata": {
  "ipub": {
   "bibliography": "fuzzingbook.bib",
   "toc": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
