{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Fuzzing Test Suites with Mutation Analysis\n",
    "\n",
    "In the [chapter on coverage](Coverage.ipynb), we showed how one identify which parts of the program are executed by a program, and hence get a sense of the effectiveness of a set of test cases in covering the program structure. However, is structural coverage a good measure of effectiveness? One of the problems with structural coverage measures is that it fails to check whether the program executions generated by the test suite were actually correct. That is, an execution that produces a wrong output that is unnoticed by the test suite is counted exactly the same as an execution that produces the right output for coverage. Indeed, if one deletes the assertions in a typical test case, the coverage would not change for the new test suite, but the new test suite is much less useful than the original one.\n",
    "\n",
    "This is indeed, not an optimal state of affairs. How can we verify that our tests are actually useful? One alternative (hinted in the chapter on coverage) is to inject bugs into the program, and evaluate the effectiveness of test suites in catching these injected bugs. However, that that introduces another problem. How do we produce these bugs in the first place? Any manual effort is likely to be biased by the preconceptions of the developer as to where the bugs are likely to occur, and what effect it would have. Further, writing good bugs is likely to take a significant amount of time, for a very indirect benefit. Hence such a solution is not sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Mutation Analysis offers an alternative solution. The insight from Mutation Analysis is to consider the probability of insertion of a bug from the perspective of a programmer. If one assumes that the attention received by each program element in the program is sufficiently similar, one can further assume that each token in the program have a similar probability of being incorrectly transcribed. Of course, the programmer will correct any mistakes that gets detected by the compilers (or other static analysis tools). So the set of valid tokens different from the original that make it past the compilation stage is considered to be its possible set of _mutations_ that represent the _probable faults_ in the program. A test suite is then judged by its capability to detect (and hence prevent) such mutations. The proportion of such mutants detected over all _valid_ mutants produced is taken as the mutation score. In this chapter, we see how one can implement Mutation Analysis in Python programs. The mutation score obtained represents the ability of any program analysis tools to prevent faults, and can be used to judge static test suites, test generators such as fuzzers, and also static and symbolic execution frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be intuitive to consider a slightly different perspective. A test suite is a program that can be considered to accept as its input, the program to be tested.  What is the best way to evaluate such a program (the test suite)? We can essentially *fuzz* the test suite by applying small mutations to the input program, and verifying that the test suite in question does not produce unexpected behaviors. The test suite is supposed to only allow the original through; and hence any mutant that is not detected as faulty represents a bug in the test suite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Prerequisites**\n",
    "\n",
    "* You need some understanding of how a program is executed.\n",
    "* You should have read [the chapter on coverage](Coverage.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is Structural Coverage Adequacy Sufficient?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the `triangle()` program below. We want to verify that the program works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangle(a, b, c):\n",
    "    if a == b:\n",
    "        if b == c:\n",
    "            return 'Equilateral'\n",
    "        else:\n",
    "            return 'Isosceles'\n",
    "    else:\n",
    "        if b == c:\n",
    "            return \"Isosceles\"\n",
    "        else:\n",
    "            if a == c:\n",
    "                return \"Isosceles\"\n",
    "            else:\n",
    "                return \"Scalene\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few test cases to ensure that the program works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strong_oracle(fn):\n",
    "    assert fn(1,1,1) == 'Equilateral'\n",
    "\n",
    "    assert fn(1,2,1) == 'Isosceles'\n",
    "    assert fn(2,2,1) == 'Isosceles'\n",
    "    assert fn(1,2,2) == 'Isosceles'\n",
    "\n",
    "    assert fn(1,2,3) == 'Scalene'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the effectiveness of our test suite? As we saw in the [chapter on coverage](Coverage.ipynb), one can use structural coverage techniques such as statement coverage to obtain a measure of effectiveness of the test case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import fuzzingbook_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Coverage import Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a function `show_coverage()` to visualize the coverage obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coverage(Coverage):\n",
    "    def show_coverage(self, fn):\n",
    "        src = inspect.getsource(fn)\n",
    "        name = fn.__name__\n",
    "        covered = set([lineno for method, lineno in self._trace if method == name])\n",
    "        for i, s in enumerate(src.split('\\n')):\n",
    "            print('%s %2d: %s' % ('#' if i + 1 in covered else ' ', i + 1, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Coverage() as cov:\n",
    "    strong_oracle(triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov.show_coverage(triangle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `strong_oracle()` seems to have adequately covered all possible conditions.\n",
    "That is, our set of test cases is reasonably good according to structural coverage. However, does the coverage obtained tell the whole story? Consider this test suite instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weak_oracle(fn):\n",
    "    assert fn(1,1,1) == 'Equilateral'\n",
    "\n",
    "    assert fn(1,2,1) != 'Equilateral'\n",
    "    assert fn(2,2,1) != 'Equilateral'\n",
    "    assert fn(1,2,2) != 'Equilateral'\n",
    "\n",
    "    assert fn(1,2,3) != 'Equilateral'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that we are checking here is that a triangle with unequal sides is not equilateral. What is the coverage obtained?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Coverage() as cov:\n",
    "    weak_oracle(triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov.show_coverage(triangle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, there does not seem to be _any_ difference in coverage.\n",
    "The `weak_oracle()` obtains exactly the same coverage as that of `strong_oracle()`. However, a moment's reflection should convince one that the `weak_oracle()` is not as effective as `strong_oracle()`. However, _coverage_ is unable to distinguish between the two test suites. What are we missing in coverage?\n",
    "The problem here is that coverage is unable to evaluate the _quality_ of our assertions. Indeed, coverage does not care about assertions at all. However, as we saw above, assertions are an extremely important part of test suite effectiveness. Hence, what we need is a way to evaluate the quality of assertions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fault Injection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in the [chapter on coverage](Coverage.ipynb), coverage was presented as a _proxy_ for the likelihood of a test suite to uncover bugs. What if actually try to evaluate the likelihood of a test suite to uncover bugs? All we need is to inject bugs into the program, one at a time, and count the number of such bugs that our test suite detects. The frequency of detection will provide us with the actual likelihood of the test suite to uncover bugs. This technique is called _fault injection_. Here is an example for _fault injection_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangle_m1(a, b, c):\n",
    "    if a == b:\n",
    "        if b == c:\n",
    "            return 'Equilateral'\n",
    "        else:\n",
    "            #return 'Isosceles'\n",
    "            return None #<-- injected fault\n",
    "    else:\n",
    "        if b == c:\n",
    "            return \"Isosceles\"\n",
    "        else:\n",
    "            if a == c:\n",
    "                return \"Isosceles\"\n",
    "            else:\n",
    "                return \"Scalene\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see if our test suites are good enough to catch this fault. We first check whether `weak_oracle()` can detect this change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ExpectError import ExpectError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError():\n",
    "    weak_oracle(triangle_m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `weak_oracle()` is unable to detect any changes. What about our `strong_oracle()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ExpectError():\n",
    "    strong_oracle(triangle_m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `strong_oracle()` is able to detect this fault, which is evidence that `strong_oracle()` is probably a better test suite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Fault injection_ can provide a good measure of effectiveness of a test suite, provided we have a list of possible faults. The problem is that collecting such a set of _unbiased_ faults is rather expensive. It is difficult to create good faults that are reasonably hard to detect, and it is a manual process. Given that it is a manual process, the generated faults will be biased by the preconceptions of the developer who creates it. Even when such curated faults are available, they are unlikely to be exhaustive, and likely to miss important classes of bugs, and parts of the program. Hence, _fault injection_ is an insufficient replacement for coverage. Can we do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mutation Analysis provides an alternative to a curated set of faults. The key insight is that, if one assumes that the programmer understands the program in question, the majority of errors made are very likely small transcription errors (a small number of tokens). A compiler will likely catch most of these errors. Hence, the majority of residual faults in a program is likely to be due to small (single token) variations at certain points in the structure of the program from the correct program (This particular assumption is called the *Competent Programmer Hypothesis* or the *Finite Neighborhood Hypothesis*). What about the larger faults composed of multiple changes to the program? The key insight here is that, for a significant majority of such faults, test cases that can detect a single change in isolation is very likely to detect the larger composite fault that contains it. (This assumption is called the *Coupling Effect*.) How can we use these assumptions in practice? The idea is to simply generate *all* possible *valid* variants of the program that differs from the original by a small change (such as a single token change) (Such variants are called *mutants*). Next, the given test suite is applied to each variant thus generated. Any mutant detected by the test suite is said to have been *killed* by the test suite. The effectiveness of a test suite is given by the proportion of mutants killed to the valid mutants generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next implement a simple mutation analysis framework and use it to evaluate our test suites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Simple Mutator for Functions\n",
    "\n",
    "Consider the `triangle()` program we discussed previously. A simple way to produce valid mutated version of this program is to replace some of its statements by `pass`.\n",
    "\n",
    "We begin by importing the AST manipulation modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astunparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MuFunctionAnalyzer` is the main class responsible for mutation analysis of the test suite. It accepts the function to be tested. It normalizes the source code given by parsing and unparsing it once. This is required to ensure that later `diff`s between the original and mutant is not derailed by differences in whitespace comments etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuFunctionAnalyzer:\n",
    "    def __init__(self, fn, log=False):\n",
    "        self.fn = fn\n",
    "        self.name = fn.__name__\n",
    "        src = inspect.getsource(fn)\n",
    "        self.ast = ast.parse(src)\n",
    "        self.src = astunparse.unparse(self.ast) # normalize\n",
    "        self.mutator = self.mutator_object()\n",
    "        self.nmutations = self.get_mutation_count()\n",
    "        self.un_detected = set()\n",
    "        self.mutants = []\n",
    "        self.log = log\n",
    "        \n",
    "    def mutator_object(self, locations=None):\n",
    "        return StmtDeletionMutator(locations)\n",
    "    \n",
    "    def register(self, m):\n",
    "        self.mutants.append(m)\n",
    "        \n",
    "    def finish(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_mutation_count()` fetches the number of possible mutations available. We will see later how this can be implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuFunctionAnalyzer(MuFunctionAnalyzer):\n",
    "    def get_mutation_count(self):\n",
    "        self.mutator.visit(self.ast)\n",
    "        return self.mutator.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Mutator` provides the base class for implementing individual mutations. It accepts a list of locations to mutate. It assumes that the method `mutable_visit` is invoked on all nodes of interest as determined by the subclass. When the `Mutator` is invoked without a list of locations to mutate, it simply loops through all possible mutation points and retains a count in `self.count`. If it is invoked with a specific list of locations to mutate, the `mutable_visit()` method calls the `mutation_visit()` which performs the mutation on the node. Note that a single location can produce multiple mutations. (Hence the hashmap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mutator(ast.NodeTransformer):\n",
    "    def __init__(self, mutate_location=-1):\n",
    "        self.count = 0\n",
    "        self.mutate_location = mutate_location\n",
    "\n",
    "    def mutable_visit(self, node):\n",
    "        self.count += 1 # statements start at line no 1\n",
    "        if self.count == self.mutate_location:\n",
    "            return self.mutation_visit(node)\n",
    "        return self.generic_visit(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `StmtDeletionMutator` simply hooks into all the statement processing visitors. It performs mutation by replacing the given statement with `pass`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StmtDeletionMutator(Mutator):\n",
    "    def mutation_visit(self, Node): return ast.Pass()\n",
    "    def visit_Return(self, node): return self.mutable_visit(node)\n",
    "    def visit_Delete(self, node): return self.mutable_visit(node)\n",
    "\n",
    "    def visit_Assign(self, node): return self.mutable_visit(node)\n",
    "    def visit_AnnAssign(self, node): return self.mutable_visit(node)\n",
    "    def visit_AugAssign(self, node): return self.mutable_visit(node)\n",
    "\n",
    "    def visit_Raise(self, node): return self.mutable_visit(node)\n",
    "    def visit_Assert(self, node): return self.mutable_visit(node)\n",
    "\n",
    "    def visit_Global(self, node): return self.mutable_visit(node)\n",
    "    def visit_Nonlocal(self, node): return self.mutable_visit(node)\n",
    "\n",
    "    def visit_Expr(self, node): return self.mutable_visit(node)\n",
    "\n",
    "    def visit_Pass(self, node): return self.mutable_visit(node)\n",
    "    def visit_Break(self, node): return self.mutable_visit(node)\n",
    "    def visit_Continue(self, node): return self.mutable_visit(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain the number of mutations produced for `triangle()` as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MuFunctionAnalyzer(triangle).nmutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a way to obtain the individual mutants. For this, we convert our `ProgramMutator` to an *iterable*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuFunctionAnalyzer(MuFunctionAnalyzer):\n",
    "    def __iter__(self):\n",
    "        return PMIterator(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PMIterator`, which is the *iterator* class for `ProgramMutator` is defined as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMIterator:\n",
    "    def __init__(self, pm):\n",
    "        self.pm = pm\n",
    "        self.idx = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `next()` method returns the corresponding `Mutant`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMIterator(PMIterator):\n",
    "    def __next__(self):\n",
    "        i = self.idx\n",
    "        if i >= self.pm.nmutations:\n",
    "            self.pm.finish()\n",
    "            raise StopIteration()\n",
    "        self.idx += 1\n",
    "        mutant = Mutant(self.pm, self.idx, log=self.pm.log)\n",
    "        self.pm.register(mutant)\n",
    "        return mutant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Mutant` class contains logic for generating mutants when given the locations to mutate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mutant:\n",
    "    def __init__(self, pm, location, log=False):\n",
    "        self.pm = pm\n",
    "        self.i = location\n",
    "        self.name = \"%s_%s\" % (self.pm.name, self.i)\n",
    "        self._src = None\n",
    "        self.tests = []\n",
    "        self.detected = False\n",
    "        self.log = log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how it can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in MuFunctionAnalyzer(triangle):\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `generate_mutant()` simply calls the `mutator()` method, and passes the mutator a copy of the AST. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mutant(Mutant):\n",
    "    def generate_mutant(self, location):\n",
    "        mutant_ast = self.pm.mutator_object(location).visit(ast.parse(self.pm.src)) # copy\n",
    "        return astunparse.unparse(mutant_ast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `src()` method returns the mutated source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mutant(Mutant):\n",
    "    def src(self):\n",
    "        if self._src is None:\n",
    "            self._src = self.generate_mutant(self.i)\n",
    "        return self._src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how one can obtain the mutants, and visualize the difference from the original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for mutant in MuFunctionAnalyzer(triangle):\n",
    "    shape_src = mutant.pm.src\n",
    "    for line in difflib.unified_diff(mutant.pm.src.split('\\n'),\n",
    "                                  mutant.src().split('\\n'),\n",
    "                                  fromfile=mutant.pm.name,\n",
    "                                  tofile=mutant.name, n=3):\n",
    "        print(line)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add the `diff()` method to `Mutant` so that it can be called directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mutant(Mutant):\n",
    "    def diff(self):\n",
    "        return '\\n'.join(difflib.unified_diff(self.pm.src.split('\\n'),\n",
    "                                  self.src().split('\\n'),\n",
    "                                  fromfile='original',\n",
    "                                  tofile='mutant',\n",
    "                                         n=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to implement the actual evaluation. We define our mutant as a context manager that verifies that all assertions given succeeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mutant(Mutant):\n",
    "    def __enter__(self):\n",
    "        if self.log:\n",
    "            print('->\\t%s' % self.name)\n",
    "        c = compile(self.src(), '<mutant>', 'exec')\n",
    "        eval(c, globals())\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        if self.log:\n",
    "            print('<-\\t%s' % self.name)\n",
    "        if exc_type is not None:\n",
    "            self.detected = True\n",
    "            if self.log:\n",
    "                print(\"Detected %s\" % self.name, exc_type, exc_value)\n",
    "        globals()[self.pm.name] = self.pm.fn\n",
    "        if self.log:\n",
    "            print()\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `finish()` simply invokes the method on the mutant, checks if the mutant was discovered, and returns the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ExpectError import ExpectTimeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuFunctionAnalyzer(MuFunctionAnalyzer):\n",
    "    def finish(self):\n",
    "        self.un_detected = {mutant for mutant in self.mutants if not mutant.detected}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mutation score is computed by `score()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuFunctionAnalyzer(MuFunctionAnalyzer):\n",
    "    def score(self):\n",
    "        return (self.nmutations - len(self.un_detected))/self.nmutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we use our framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for mutant in MuFunctionAnalyzer(triangle):\n",
    "    with mutant:\n",
    "        assert triangle(1,1,1) == 'Equilateral', \"Equal Check1\"\n",
    "        assert triangle(1,0,1) != 'Equilateral', \"Equal Check2\"\n",
    "        assert triangle(1,0,2) != 'Equilateral', \"Equal Check3\"\n",
    "mutant.pm.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `weak_oracle()` test suite resulted in only `20%` mutation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mutant in MuFunctionAnalyzer(triangle):\n",
    "    with mutant:\n",
    "        weak_oracle(triangle)\n",
    "mutant.pm.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are modifying the global namespace, we do not have to refer to the function directly within the for loop of mutant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracle():\n",
    "    strong_oracle(triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mutant in MuFunctionAnalyzer(triangle):\n",
    "    with mutant:\n",
    "        oracle()\n",
    "mutant.pm.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, we were able to achieve `100%` mutation score with `strong_oracle` test suite.\n",
    "\n",
    "Here is another example, `gcd()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcd(a, b):\n",
    "    if a<b:\n",
    "        c: int = a\n",
    "        a: int = b\n",
    "        b: int = c\n",
    "\n",
    "    while b != 0 :\n",
    "        c: int = a\n",
    "        a: int = b\n",
    "        b: int = c % b\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for mutant in MuFunctionAnalyzer(gcd, log=True):\n",
    "    with mutant:\n",
    "        assert gcd(1, 0) == 1, \"Minimal\"\n",
    "        assert gcd(0, 1) == 1, \"Mirror\"\n",
    "mutant.pm.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our `TestGCD` test suite is able to obtain `42%` mutation score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Mutator for Modules and Test Suites\n",
    "\n",
    "Consider the `triangle()` program we discussed previously. As we discussed, a simple way to produce valid mutated version of this program is to replace some of its statements by `pass`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes, we would like to proceed as though the program was in a different file. We can do that by producing a `Module` object in Python, and attaching the function to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_code(code, name):\n",
    "    module = imp.new_module(name)\n",
    "    exec(code, module.__dict__)\n",
    "    return module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We attach the `triangle()` function to the `shape` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = import_code(inspect.getsource(triangle), 'shape')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now invoke triangle through the module `shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape.triangle(1,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to test the `triangle()` function. For that, we define a `StrongShapeTest` class as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "class StrongShapeTest(unittest.TestCase):\n",
    "\n",
    "    def test_equilateral(self):\n",
    "        assert shape.triangle(1,1,1) == 'Equilateral'\n",
    "\n",
    "    def test_isosceles(self):\n",
    "        assert shape.triangle(1,2,1) == 'Isosceles'\n",
    "        assert shape.triangle(2,2,1) == 'Isosceles'\n",
    "        assert shape.triangle(1,2,2) == 'Isosceles'\n",
    "\n",
    "    def test_scalene(self):\n",
    "        assert shape.triangle(1,2,3) == 'Scalene'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a helper function `suite()` that looks through a given class and identifies the test functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def suite(test_class):\n",
    "    suite = unittest.TestSuite()\n",
    "    for f in test_class.__dict__:\n",
    "        if f.startswith('test_'):\n",
    "            suite.addTest(test_class(f))\n",
    "    return suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tests in `TestTriangle` class can be invoked with different test runners. The simplest is to directly invoke the `run()` method of the `TestCase`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite(StrongShapeTest).run(unittest.TestResult())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `TextTestRunner` class provides ability to control the verbosity of execution. It also allows one to return on the *first* failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "runner = unittest.TextTestRunner(verbosity=0, failfast=True)\n",
    "runner.run(suite(StrongShapeTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the program under coverage is accomplished as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Coverage() as cov:\n",
    "    suite(StrongShapeTest).run(unittest.TestResult())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coverage obtained is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov.show_coverage(triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeakShapeTest(unittest.TestCase):\n",
    "    def test_equilateral(self):\n",
    "        assert shape.triangle(1,1,1) == 'Equilateral'\n",
    "\n",
    "    def test_isosceles(self):\n",
    "        assert shape.triangle(1,2,1) != 'Equilateral'\n",
    "        assert shape.triangle(2,2,1) != 'Equilateral'\n",
    "        assert shape.triangle(1,2,2) != 'Equilateral'\n",
    "\n",
    "    def test_scalene(self):\n",
    "        assert shape.triangle(1,2,3) != 'Equilateral'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much coverage does it obtain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Coverage() as cov:\n",
    "    suite(WeakShapeTest).run(unittest.TestResult())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov.show_coverage(triangle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MuProgramAnalyzer` is the main class responsible for mutation analysis of the test suite. It accepts the name of the module to be tested, and its source code. It normalizes the source code given by parsing and unparsing it once. This is required to ensure that later `diff`s between the original and mutant is not derailed by differences in whitespace comments etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuProgramAnalyzer(MuFunctionAnalyzer):\n",
    "    def __init__(self, name, src):\n",
    "        self.name = name\n",
    "        self.ast = ast.parse(src)\n",
    "        self.src = astunparse.unparse(self.ast)\n",
    "        self.changes = []\n",
    "        self.mutator = self.mutator_object()\n",
    "        self.nmutations = self.get_mutation_count()\n",
    "        self.un_detected = set()\n",
    "        \n",
    "    def mutator_object(self, locations=None):\n",
    "        return AdvStmtDeletionMutator(self, locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Mutator` provides the base class for implementing individual mutations. It accepts a list of locations to mutate. It assumes that the method `mutable_visit` is invoked on all nodes of interest as determined by the subclass. When the `Mutator` is invoked without a list of locations to mutate, it simply loops through all possible mutation points and retains a count in `self.count`. If it is invoked with a specific list of locations to mutate, the `mutable_visit()` method calls the `mutation_visit()` which performs the mutation on the node. Note that a single location can produce multiple mutations. (Hence the hashmap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvMutator(Mutator):\n",
    "    def __init__(self, analyzer, mutate_locations=None):\n",
    "        self.count = 0\n",
    "        self.mutate_locations = [] if mutate_locations is None else mutate_locations\n",
    "        self.pm = analyzer\n",
    "\n",
    "    def mutable_visit(self, node):\n",
    "        self.count += 1 # statements start at line no 1\n",
    "        return self.mutation_visit(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `AdvStmtDeletionMutator` simply hooks into all the statement processing visitors. It performs mutation by replacing the given statement with `pass`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvStmtDeletionMutator(AdvMutator, StmtDeletionMutator):\n",
    "    def __init__(self, analyzer, mutate_locations=None):\n",
    "        AdvMutator.__init__(self, analyzer, mutate_locations)\n",
    "        \n",
    "    def mutation_visit(self, node):\n",
    "        index = 0 # there is only one way to delete a statement -- replace it by pass\n",
    "        if not self.mutate_locations: # counting pass\n",
    "            self.pm.changes.append((self.count, index))\n",
    "            return self.generic_visit(node)\n",
    "        else:\n",
    "            # get matching changes for this pass \n",
    "            mutating_lines = set((count,idx) for (count, idx) in self.mutate_locations)\n",
    "            if (self.count, index) in mutating_lines:\n",
    "                return ast.Pass()\n",
    "            else:\n",
    "                return self.generic_visit(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain the number of mutations produced for `triangle()` as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MuProgramAnalyzer('shape', inspect.getsource(triangle)).nmutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a way to obtain the individual mutants. For this, we convert our `ProgramMutator` to an *iterable*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuProgramAnalyzer(MuProgramAnalyzer):\n",
    "    def __iter__(self):\n",
    "        return AdvPMIterator(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `AdvPMIterator`, which is the *iterator* class for `ProgramMutator` is defined as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvPMIterator:\n",
    "    def __init__(self, pm):\n",
    "        self.pm = pm\n",
    "        self.idx = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `next()` method returns the corresponding `Mutant`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvPMIterator(AdvPMIterator):\n",
    "    def __next__(self):\n",
    "        i = self.idx\n",
    "        if i >= len(self.pm.changes):\n",
    "            raise StopIteration()\n",
    "        self.idx += 1\n",
    "        return AdvMutant(self.pm, [self.pm.changes[i]]) # there could be multiple changes in one mutant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Mutant` class contains logic for generating mutants when given the locations to mutate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvMutant(Mutant):\n",
    "    def __init__(self, pm, locations):\n",
    "        self.pm = pm\n",
    "        self.i = locations\n",
    "        self.name = \"%s_%s\" % (self.pm.name, '_'.join([str(i) for i in self.i]))\n",
    "        self._src = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how it can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_src = inspect.getsource(triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in MuProgramAnalyzer('shape', shape_src):\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `generate_mutant()` simply calls the `mutator()` method, and passes the mutator a copy of the AST. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvMutant(AdvMutant):\n",
    "    def generate_mutant(self, locations):\n",
    "        mutant_ast = self.pm.mutator_object(locations).visit(ast.parse(self.pm.src)) # copy\n",
    "        return astunparse.unparse(mutant_ast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `src()` method returns the mutated source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvMutant(AdvMutant):\n",
    "    def src(self):\n",
    "        if self._src is None:\n",
    "            self._src = self.generate_mutant(self.i)\n",
    "        return self._src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how one can obtain the mutants, and visualize the difference from the original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add the `diff()` method to `Mutant` so that it can be called directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvMutant(AdvMutant):\n",
    "    def diff(self):\n",
    "        return '\\n'.join(difflib.unified_diff(self.pm.src.split('\\n'),\n",
    "                                  self.src().split('\\n'),\n",
    "                                  fromfile='original',\n",
    "                                  tofile='mutant',\n",
    "                                         n=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for mutant in MuProgramAnalyzer('shape', inspect.getsource(triangle)):\n",
    "    print(mutant.name)\n",
    "    print(mutant.diff())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to implement the actual evaluation. For doing that, we require the ability to accept the module where the test suite is defined, and invoke the test method on it. The method `getitem` accepts the test module, fixes the import entries on the test module to correctly point to the mutant module, and passes it to the test runner `MutantTestRunner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvMutant(AdvMutant):\n",
    "    def __getitem__(self, test_module):\n",
    "        test_module.__dict__[self.pm.name] = import_code(self.src(), self.pm.name)\n",
    "        return MutantTestRunner(self, test_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MutantTestRunner` simply calls all `test_` methods on the test module, checks if the mutant was discovered, and returns the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ExpectError import ExpectTimeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MutantTestRunner:\n",
    "    def __init__(self, mutant, test_module):\n",
    "        self.mutant = mutant\n",
    "        self.tm = test_module\n",
    "        \n",
    "    def runTest(self, tc):\n",
    "        suite = unittest.TestSuite()\n",
    "        test_class = self.tm.__dict__[tc]\n",
    "        for f in test_class.__dict__:\n",
    "            if f.startswith('test_'):\n",
    "                suite.addTest(test_class(f))\n",
    "        runner = unittest.TextTestRunner(verbosity=0, failfast=True)\n",
    "        try:\n",
    "            with ExpectTimeout(1):\n",
    "                res = runner.run(suite)\n",
    "                if res.wasSuccessful():\n",
    "                    self.mutant.pm.un_detected.add(self)\n",
    "                return res\n",
    "        except SyntaxError:\n",
    "            print('Syntax Error (%s)' % self.mutant.name)\n",
    "            return None\n",
    "        raise Exception('Unhandled exception during test execution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mutation score is computed by `score()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuProgramAnalyzer(MuProgramAnalyzer):\n",
    "    def score(self):\n",
    "        return (self.nmutations - len(self.un_detected))/self.nmutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we use our framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_module = sys.modules[__name__]\n",
    "for mutant in MuProgramAnalyzer('shape', shape_src):\n",
    "    mutant[test_module].runTest('WeakShapeTest')\n",
    "mutant.pm.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `WeakShape` test suite resulted in only `20%` mutation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mutant in MuProgramAnalyzer('shape', shape_src):\n",
    "    mutant[test_module].runTest('StrongShapeTest')\n",
    "mutant.pm.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, we were able to achieve `100%` mutation score with `StrongShapeTest` test suite.\n",
    "\n",
    "Here is another example, `gcd()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcd_src = inspect.getsource(gcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestGCD(unittest.TestCase):\n",
    "    def test_simple(self):\n",
    "        assert cfg.gcd(1,0) == 1\n",
    "        \n",
    "    def test_mirror(self):\n",
    "        assert cfg.gcd(0,1) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for mutant in MuProgramAnalyzer('cfg', gcd_src):\n",
    "    mutant[test_module].runTest('TestGCD')\n",
    "mutant.pm.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our `TestGCD` test suite is able to obtain `42%` mutation score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dealing with Immortal (Equivalent) Mutants\n",
    "\n",
    "\\todo{Check with Marcel about equivalent mutant estimation using STADS paper}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dealing with Redundant Mutants\n",
    "\n",
    "\\todo{Check with Marcel about redundant mutant estimation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Lessons Learned\n",
    "\n",
    "* We have learned why structural coverage is insufficient to evaluate the quality of test suites.\n",
    "* We have learned how to use Mutation Analysis for evaluating test suite quality.\n",
    "* We have learned the limitations of Mutation Analysis -- Immortal and Redundant mutants, and how to estimate them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "* While naive fuzzing generates poor quality oracles, techniques such as [symbolic](SymbolicFuzzer.ipynb) and [concolic](ConcolicFuzzer.ipynb) can enhance the quality oracles used in fuzzing.\n",
    "* [Dynamic invariants](DynamicInvariants.ipynb) can also be of great help in improving the quality of oracles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "The idea of Mutation Analysis was first introduced by Lipton et al."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Exercise 1:  Arithmetic Expression Mutators\n",
    "\n",
    "Our simple statement deletion mutation is only one of the ways in which a program could be mutated. Another category of mutants is `expression mutation` where arithmetic operators such as `{+,-,*,/}` etc are replaced for one another. For example, given an expression such as\n",
    "```\n",
    "x = x + 1\n",
    "```\n",
    "One can mutate it to\n",
    "```\n",
    "x = x - 1\n",
    "```\n",
    "and\n",
    "```\n",
    "x = x * 1\n",
    "```\n",
    "and\n",
    "```\n",
    "x = x / 1\n",
    "```\n",
    "\n",
    "I. Can you produce an `AdvArithmeticOperatorMutator` that produces such mutants?\n",
    "\n",
    "II. Can you fix the function mutator such that one can write `ArithmeticOperatorMutator` also? (Why is it not possible with the current implementation?)\n",
    "\n",
    "**Hint.** Check how many mutants can be produced per token for the function mutator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution.** None provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution": "hidden",
    "solution_first": true
   },
   "source": [
    "### Exercise 2: Byte Code Mutator\n",
    "\n",
    "We have seen how to mutate the AST given the source. One of the deficiencies with this approach is that the Python bytecode is targeted by other languages too. In such cases, the source may not be readily converted to a Python AST, and it is desirable to mutate the bytecode instead. Can you implement a bytecode mutator for Python function that mutates the bytecode instead of fetching the source and then mutating it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "solution": "hidden"
   },
   "source": [
    "**Solution.** None provided."
   ]
  }
 ],
 "metadata": {
  "ipub": {
   "bibliography": "fuzzingbook.bib",
   "toc": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "417.85px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
