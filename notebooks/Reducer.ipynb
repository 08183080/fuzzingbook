{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Reducing Failure-Inducing Inputs\n",
    "\n",
    "By construction, fuzzers create inputs that may be hard to read.  This causes issues during _debugging_, when a human has to analyze the exact cause of the failure.  In this chapter, we present techniques that _automatically reduce and simplify failure-inducing inputs to a minimum_ in order to ease debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Prerequisites**\n",
    "\n",
    "* As reduction is typically used together with fuzzing, reading the [chapter on basic fuzzing](Fuzzer.ipynb) is a good idea.\n",
    "* The simple \"delta debugging\" technique for reduction has no specific prerequisites.\n",
    "* The later grammar-based techniques require knowledge on [derivation trees](GrammarFuzzer.ipynb) and [parsing](Parser.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Why Reducing?\n",
    "\n",
    "At this point, we have seen a number of test generation techniques that all in some form produce inputs in order to trigger failures.  If they are successful – that is, the program actually fails – we must find out why the failure occurred and how to fix it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Here's an example of such a situation.  We have a class `MysteryRunner` class with a `run()` method that – given its code – can occasionally fail.  But under which circumstances does this actually happen?  We have deliberately obscured the exact condition in order to make this non-obvious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import fuzzingbook_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Fuzzer import RandomFuzzer, Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MysteryRunner(Runner):\n",
    "    def run(self, inp):\n",
    "        x = inp.find(chr(0o17 + 0o31))\n",
    "        y = inp.find(chr(0o27 + 0o22))\n",
    "        if x >= 0 and y >= 0 and x < y:\n",
    "            return (inp, Runner.FAIL)\n",
    "        else:\n",
    "            return (inp, Runner.PASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us fuzz the function until we find a failing input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystery = MysteryRunner()\n",
    "random_fuzzer = RandomFuzzer()\n",
    "while True:\n",
    "    inp = random_fuzzer.fuzz()\n",
    "    result, outcome = mystery.run(inp)\n",
    "    if outcome == mystery.FAIL:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failing_input = result\n",
    "failing_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something in this input causes `MysteryRunner` to fail.  But what is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Manual Input Reduction\n",
    "\n",
    "One important step in the debugging process is _reduction_ – that is, to identify those circumstances of a failure that are relevant for the failure to occur, and to _omit_ (if possible) those parts that are not.  As Kernighan and Pike \\cite{Kernighan1999} put it:\n",
    "\n",
    "> For every circumstance of the problem, check whether it is relevant for the problem to occur.  If it is not, remove it from the problem report or the test case in question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically for inputs, they suggest a _divide and conquer_ process:\n",
    "\n",
    "> Proceed by binary search.  Throw away half the input and see if the output is still wrong; if not, go back to the previous state and discard the other half of the input.\n",
    "\n",
    "This is something we can easily try out.  For instance, we can see whether the error still occurs if we only feed in the first half:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_length = len(failing_input) // 2   # // is integer division\n",
    "first_half = failing_input[:half_length]\n",
    "mystery.run(first_half)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope – the first half alone does not suffice.  Maybe the second half?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_half = failing_input[half_length:]\n",
    "mystery.run(second_half)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This did not go so well either.  We may still proceed by cutting away _smaller chunks_ – say, one character after another.  If our test is deterministic and easily repeated, it is clear that this process eventually will yield a reduced input.  But still, it is a rather inefficient process, especially for long inputs.  What we need is a _strategy_ that effectively minimizes a failure-inducing input – a strategy that can be automated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delta Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One strategy to effectively reduce failure-inducing inputs is _delta debugging_ \\cite{Zeller2002}.  Delta Debugging implements the \"binary search\" strategy, as listed above, but with a twist: If neither half fails (also as above), it keeps on cutting away smaller and smaller chunks from the input, until it eliminates individual characters.  Thus, after cutting away the first half, we cut away\n",
    "the first quarter, the second quarter, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us illustrate this on our example, and see what happens if we cut away the first quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarter_length = len(failing_input) // 4\n",
    "input_without_first_quarter = failing_input[quarter_length:]\n",
    "mystery.run(input_without_first_quarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah! This has failed, and reduced our failing input by 25%.  Let's remove another quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_without_first_and_second_quarter = failing_input[quarter_length * 2:]\n",
    "mystery.run(input_without_first_and_second_quarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not too surprising, as we had that one before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_without_first_and_second_quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about removing the third quarter, then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_without_first_and_third_quarter = failing_input[quarter_length:\n",
    "                                                      quarter_length * 2] + failing_input[quarter_length * 3:]\n",
    "mystery.run(input_without_first_and_third_quarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about removing the third quarter, then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_without_first_and_fourth_quarter = failing_input[quarter_length:quarter_length * 3]\n",
    "mystery.run(input_without_first_and_fourth_quarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes!  This has succeeded.  Our input is now 50% smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now tried to remove pieces that make up $\\frac{1}{2}$ and $\\frac{1}{4}$ of the original failing string.  In the next iteration, we would go and remove even smaller pieces – $\\frac{1}{8}$, $\\frac{1}{16}$ and so on.  We continue until we are down to $\\frac{1}{97}$ – that is, individual characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this is comething we happily let a computer do for us.  We first introduce a `Reducer` class as an abstract superclass for all kinds of reducers.  The `test()` methods runs a single test (with logging, if so wanted); the `reduce()` method will eventually reduce an input to the minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reducer(object):\n",
    "    def __init__(self, runner, log_test=False):\n",
    "        \"\"\"Attach reducer to the given `runner`\"\"\"\n",
    "        self.runner = runner\n",
    "        self.log_test = log_test\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.tests = 0\n",
    "\n",
    "    def test(self, inp):\n",
    "        result, outcome = self.runner.run(inp)\n",
    "        self.tests += 1\n",
    "        if self.log_test:\n",
    "            print(\"Test #%d\" % self.tests, repr(inp), repr(len(inp)), outcome)\n",
    "        return outcome\n",
    "\n",
    "    def reduce(self, inp):\n",
    "        self.reset()\n",
    "        # Default: Don't reduce\n",
    "        return inp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `CachingReducer` variant saves test results, such that we don't have to run the same tests again and again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CachingReducer(Reducer):\n",
    "    def reset(self):\n",
    "        super().reset()\n",
    "        self.cache = {}\n",
    "\n",
    "    def test(self, inp):\n",
    "        if inp in self.cache:\n",
    "            return self.cache[inp]\n",
    "\n",
    "        outcome = super().test(inp)\n",
    "        self.cache[inp] = outcome\n",
    "        return outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here comes the _Delta Debugging_ reducer.  Delta Debugging implements the strategy sketched above: It first removes larger chunks of size $\\frac{1}{2}$; if this does not fail, then we proceed to chunks of size $\\frac{1}{4}$, then $\\frac{1}{8}$ and so on.\n",
    "\n",
    "Our implementation uses almost the same Python code as Zeller in \\cite{Zeller2011}; the only difference is that it has been adapted to work on Python 3 and our `Runner` framework.    The variable `n` (initially 2) indicates the granularity – in each step, chunks of size $\\frac{1}{n}$ are cut away.  If none of the test fails (`some_complement_is_failing` is False), then `n` is doubled – until it reaches the length of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeltaDebuggingReducer(CachingReducer):\n",
    "    def reduce(self, inp):\n",
    "        self.reset()\n",
    "        assert self.test(inp) != Runner.PASS\n",
    "\n",
    "        n = 2     # Initial granularity\n",
    "        while len(inp) >= 2:\n",
    "            start = 0\n",
    "            subset_length = len(inp) / n\n",
    "            some_complement_is_failing = False\n",
    "\n",
    "            while start < len(inp):\n",
    "                complement = inp[:int(start)] + \\\n",
    "                    inp[int(start + subset_length):]\n",
    "\n",
    "                if self.test(complement) == Runner.FAIL:\n",
    "                    inp = complement\n",
    "                    n = max(n - 1, 2)\n",
    "                    some_complement_is_failing = True\n",
    "                    break\n",
    "\n",
    "                start += subset_length\n",
    "\n",
    "            if not some_complement_is_failing:\n",
    "                if n == len(inp):\n",
    "                    break\n",
    "                n = min(n * 2, len(inp))\n",
    "\n",
    "        return inp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how the `DeltaDebuggingReducer` works, let us run it on our failing input.  With each step, we see how the remaining input gets smaller and smaller, until only three characters remain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_reducer = DeltaDebuggingReducer(mystery, log_test=True)\n",
    "dd_reducer.reduce(failing_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know why `MysteryRunner` fails – it suffices that the input contains two matching parentheses with a number between them.  Delta Debugging determines this is 29 steps.  Its result is _1-minimal_, meaning that every character contained is required to produce the error; removing any (as seen in tests `#27` and `#28`, above) no longer makes the test fail.  This property is guaranteed by the delta debugging algorithm, which in its last stage always tries to delete characters one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "A reduced test case such as the one above has many advantages:\n",
    "\n",
    "* A reduced test case __reduces the _cognitive load_ of the programmer__.  The test case is shorter and focused, and thus does not burden the programmer with irrelevant details.  A reduced input typically leads to shorter executions and smaller program states, both of which reduce the search space as it comes to understanding the bug.  In our case, we have eliminated lots of irrelevant input – only the two characters the reduced input contains are relevant.\n",
    "\n",
    "* A reduced test case __is easier to communicate__.  All one needs here is the summary: `MysteryRunner fails on \"()\"`, which is much better than `MysteryRunner fails on a 4100-character input (attached)`.\n",
    "\n",
    "* A reduced test case helps in __identifying duplicates__.  If similar bugs have been reported already, and all of them have been reduced to the same cause (namely that the input contains matching parentheses), then it becomes obvious that all these bugs are different symptoms of the same underlying cause – and would all be resolved at once with one code fix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How effective is delta debugging?  In the best case (when the left half or the right half fails), the number of tests is logarithmic proportional to the length $n$ of an input (i.e., $O(\\log_2 n)$); this is the same complexity as binary search.  In the worst case, though, delta debugging can require a number of tests proportional to $n^2$  (i.e., $O(n^2)$) – this happens in the case when we are down to character granularity, and we have to repeatedly tried to delete all characters, only to find that deleting the last character results in a failure \\cite{Zeller2002}.  (This is a pretty pathological situation, though.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, delta debugging is a very robust algorithm that is easy to implement, easy to deploy, and easy to use – provided that the underlying test case is deterministic and runs quickly enough to warrant a number of experiments.  As these are the same prerequisites that make fuzzing effective, delta debugging makes an excellent companion to fuzzing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Grammar-Based Input Reduction\n",
    "\n",
    "In the second half of this chapter, we will introduce an algorithm that makes use of _grammars_ to reduce inputs even faster.  The general idea is to start with a _derivation tree_, and then substitute subtrees by smaller subtrees of the same type.  These alternate subtrees can either come\n",
    "\n",
    "1. From the tree itself, or\n",
    "2. By applying an alternate grammar expansion using elements from the tree.\n",
    "\n",
    "Let us show these two strategies using an example.  We start with a derivation tree from an arithmetic expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Parser import EarleyParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GrammarFuzzer import all_terminals, expansion_to_children, display_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Grammars import EXPR_GRAMMAR, nonterminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = \"1 + (2 * 3)\"\n",
    "derivation_tree = EarleyParser(EXPR_GRAMMAR).parse(inp)[0]\n",
    "display_tree(derivation_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying by Replacing Subtrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify this tree, we could replace any `<expr>` symbol up in the tree with some `<expr>` subtree down in the tree.  For instance, we could replace the uppermost `<expr>` with its right `<expr>` subtree, yielding the string `(2 + 3)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_derivation_tree = copy.deepcopy(derivation_tree)\n",
    "sub_expr_tree = new_derivation_tree[1][0][1][2]  # We really should have some query language\n",
    "display_tree(sub_expr_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_derivation_tree[1][0] = sub_expr_tree\n",
    "display_tree(new_derivation_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_terminals(new_derivation_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing one subtree by another only works as long as individual elements such as `<expr>` occur multiple times in our tree.  In the reduced `new_derivation_tree`, above, we could replace further `<expr>` trees only once more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying by Alternative Expansions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second means to simplify this tree is to apply _alternative expansions_.  That is, for a symbol, we check whether there is an alternative expansion with a smaller number of children.  Then, we replace the symbol with the alternative expansion, filling in needed symbols from the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, consider the `new_derivation_tree` above.  The applied expansion for `<term>` has been\n",
    "\n",
    "    <term> ::= <term> * <factor>\n",
    "    \n",
    "Lat us replace this with the alternative expansion:\n",
    "\n",
    "    <term> ::= <factor>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_tree = new_derivation_tree[1][0][1][0][1][0][1][1][1][0]\n",
    "display_tree(term_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shorter_term_tree = term_tree[1][2]\n",
    "display_tree(shorter_term_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_derivation_tree[1][0][1][0][1][0][1][1][1][0] = shorter_term_tree\n",
    "display_tree(new_derivation_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_terminals(new_derivation_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we replace derivation subtrees by (smaller) subtrees, and if we search for alternate expansions that again yield smaller subtrees, we can systematically simplify the input.  This could be much faster than delta debugging, as our inputs would always be syntactically valid.  However, we need a strategy for when to apply which simplification rule. This is what we develop in the remainder of this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Class for Reducing with Grammars\n",
    "\n",
    "We introduce the `GrammarReducer` class, which is again a `Reducer`.  Note that we derive from `CachingReducer`, as the strategy will produce several duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarReducer(CachingReducer):\n",
    "    def __init__(self, runner, parser, log_test=False, log_reduce=False):\n",
    "        super().__init__(runner, log_test=log_test)\n",
    "        self.parser = parser\n",
    "        self.grammar = parser.grammar()\n",
    "        self.start_symbol = parser.start_symbol()\n",
    "        self.log_reduce = log_reduce\n",
    "        self.try_all_combinations = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Few Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_list_to_string(q):\n",
    "    return \"[\" + \", \".join([all_terminals(tree) for tree in q]) + \"]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_list_to_string([derivation_tree, derivation_tree])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def possible_combinations(list_of_lists):\n",
    "    # convert a list [[X1, X2], [Y1, Y2], ...]\n",
    "    # into [X1, Y1], [X1, Y2], [X2, Y1], [X2, Y2], ...\n",
    "    if len(list_of_lists) == 0:\n",
    "        return []\n",
    "\n",
    "    # print(list_of_lists)\n",
    "\n",
    "    ret = []\n",
    "    for e in list_of_lists[0]:\n",
    "        if len(list_of_lists) == 1:\n",
    "            ret.append([e])\n",
    "        else:\n",
    "            for c in possible_combinations(list_of_lists[1:]):\n",
    "                new_combo = [e] + c\n",
    "                ret.append(new_combo)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_combinations([[1, 2], ['a', 'b']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the number of nodes\n",
    "def number_of_nodes(tree):\n",
    "    (symbol, children) = tree\n",
    "    return 1 + sum([number_of_nodes(c) for c in children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_nodes(derivation_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return height of a tree\n",
    "def max_height(tree):\n",
    "    (symbol, children) = tree\n",
    "    if len(children) == 0:\n",
    "        return 1\n",
    "    return 1 + max([max_height(c) for c in children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_height(derivation_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplification Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarReducer(GrammarReducer):\n",
    "    def subtrees_with_symbol(self, tree, symbol, depth=-1, ignore_root=True):\n",
    "        # Find all subtrees in TREE whose root is SYMBOL.\n",
    "        # If IGNORE_ROOT is true, ignore the root note of TREE.\n",
    "\n",
    "        ret = []\n",
    "        (child_symbol, children) = tree\n",
    "        if depth <= 0 and not ignore_root and child_symbol == symbol:\n",
    "            ret.append(tree)\n",
    "\n",
    "        # Search across all children\n",
    "        if depth != 0 and children is not None:\n",
    "            for c in children:\n",
    "                ret += self.subtrees_with_symbol(c, symbol, depth=depth - 1, ignore_root=False)\n",
    "\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_reducer = GrammarReducer(mystery, EarleyParser(EXPR_GRAMMAR), log_reduce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[all_terminals(t) for t in grammar_reducer.subtrees_with_symbol(derivation_tree, \"<term>\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternate Expansions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarReducer(GrammarReducer):\n",
    "    def alternate_reductions(self, tree, symbol, depth=-1):\n",
    "        reductions = []\n",
    "        \n",
    "        expansions = self.grammar.get(symbol, [])\n",
    "        expansions.sort(key=lambda expansion: len(expansion_to_children(expansion)))\n",
    "\n",
    "        for expansion in expansions:\n",
    "            expansion_children = expansion_to_children(expansion)\n",
    "\n",
    "            match = True\n",
    "            new_children_reductions = []\n",
    "            for (alt_symbol, _) in expansion_children:\n",
    "                child_reductions = self.subtrees_with_symbol(tree, alt_symbol, depth=depth)\n",
    "                if len(child_reductions) == 0:\n",
    "                    match = False   # Child not found; cannot apply rule\n",
    "                    break\n",
    "\n",
    "                new_children_reductions.append(child_reductions)\n",
    "\n",
    "            if not match:\n",
    "                continue  # Try next alternative\n",
    "\n",
    "            # Use the first suitable combination\n",
    "            for new_children in possible_combinations(new_children_reductions):\n",
    "                new_tree = (symbol, new_children)\n",
    "                if number_of_nodes(new_tree) < number_of_nodes(tree):\n",
    "                    reductions.append(new_tree)\n",
    "                    if not self.try_all_combinations:\n",
    "                        break\n",
    "\n",
    "        # Sort by number of nodes\n",
    "        reductions.sort(key=number_of_nodes)\n",
    "        \n",
    "        return reductions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Both Strategies Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarReducer(GrammarReducer):\n",
    "    def symbol_reductions(self, tree, symbol, depth=-1):\n",
    "        \"\"\"Find all expansion alternatives for the given symbol\"\"\"\n",
    "        reductions = (self.subtrees_with_symbol(tree, symbol, depth=depth)\n",
    "                      + self.alternate_reductions(tree, symbol, depth=depth))\n",
    "\n",
    "        # Filter duplicates\n",
    "        unique_reductions = []\n",
    "        for r in reductions:\n",
    "            if r not in unique_reductions:\n",
    "                unique_reductions.append(r)\n",
    "\n",
    "        return unique_reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_reducer = GrammarReducer(mystery, EarleyParser(EXPR_GRAMMAR), log_reduce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_terminals(derivation_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reductions = grammar_reducer.symbol_reductions(derivation_tree, \"<expr>\")\n",
    "tree_list_to_string([r for r in reductions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reductions = grammar_reducer.symbol_reductions(derivation_tree, \"<factor>\")\n",
    "tree_list_to_string([r for r in reductions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Reduction Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarReducer(GrammarReducer):\n",
    "    def reduce_subtree(self, tree, subtree, depth):\n",
    "        symbol, children = subtree\n",
    "        if len(children) == 0:\n",
    "            return\n",
    "\n",
    "        if self.log_reduce:\n",
    "            print(\"Reducing\", all_terminals(subtree), \"with depth\", depth)\n",
    "\n",
    "        while True:\n",
    "            reduced = False\n",
    "            for i, child in enumerate(children):\n",
    "                (child_symbol, _) = child\n",
    "                for reduction in self.symbol_reductions(child, child_symbol, depth):\n",
    "                    if number_of_nodes(reduction) >= number_of_nodes(child):\n",
    "                        continue\n",
    "\n",
    "                    # Try this reduction\n",
    "                    if self.log_reduce:\n",
    "                        print(\"Replacing\", all_terminals(children[i]), \"by\", all_terminals(reduction))\n",
    "                    children[i] = reduction\n",
    "                    if self.test(all_terminals(tree)) == Runner.FAIL:\n",
    "                        # Success\n",
    "                        if self.log_reduce:\n",
    "                            print(\"New tree:\", all_terminals(tree))\n",
    "                        reduced = True\n",
    "                        break\n",
    "                    else:\n",
    "                        # Didn't work out - restore\n",
    "                        children[i] = child\n",
    "\n",
    "            if not reduced:\n",
    "                if self.log_reduce:\n",
    "                    print(\"Tried all alternatives for\", all_terminals(subtree))\n",
    "                break\n",
    "\n",
    "        # Run recursively\n",
    "        for c in children:\n",
    "            self.reduce_subtree(tree, c, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarReducer(GrammarReducer):\n",
    "    def reduce_tree(self, tree):\n",
    "        for depth in range(max_height(tree)):\n",
    "            self.reduce_subtree(tree, tree, depth)\n",
    "        return tree        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting Things Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarReducer(GrammarReducer):\n",
    "    def parse(self, inp):\n",
    "        tree = self.parser.parse(inp)[0]\n",
    "        print(all_terminals(tree))\n",
    "        return tree\n",
    "\n",
    "    def reduce(self, inp):\n",
    "        tree = self.parse(inp)\n",
    "        smallest_tree = self.reduce_tree(tree)\n",
    "        return all_terminals(smallest_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_reducer = GrammarReducer(mystery, EarleyParser(EXPR_GRAMMAR), log_test=True)\n",
    "grammar_reducer.reduce(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_reducer = DeltaDebuggingReducer(mystery, log_test=True)\n",
    "dd_reducer.reduce(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the grammar-based reducer needs far fewer steps.  (On the other hand, the delta debugging reducer can reduce a bit further, as it is not bound by the grammar.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GrammarFuzzer import GrammarFuzzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = GrammarFuzzer(EXPR_GRAMMAR, min_nonterminals=100).fuzz()\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_reducer = GrammarReducer(mystery, EarleyParser(EXPR_GRAMMAR), log_test=True)\n",
    "grammar_reducer.reduce(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_reducer = DeltaDebuggingReducer(mystery, log_test=True)\n",
    "dd_reducer.reduce(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above: It pays off to use grammars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more complex the input, the better off we are with grammar-based reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GeneratorGrammarFuzzer import GeneratorGrammarFuzzer, CONSTRAINED_VAR_GRAMMAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalMysteryRunner(MysteryRunner):\n",
    "    def __init__(self):\n",
    "        self.parser = EarleyParser(CONSTRAINED_VAR_GRAMMAR)\n",
    "    def run(self, inp):\n",
    "        try:\n",
    "            tree = self.parser.parse(inp)[0]\n",
    "        except SyntaxError:\n",
    "            return (inp, Runner.UNRESOLVED)\n",
    "        \n",
    "        return super().run(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_mystery = EvalMysteryRunner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_fuzzer = GeneratorGrammarFuzzer(CONSTRAINED_VAR_GRAMMAR)\n",
    "while True:\n",
    "    inp = var_fuzzer.fuzz()\n",
    "    print(inp)\n",
    "    if eval_mystery.run(inp)[1] == Runner.FAIL:\n",
    "        break\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_reducer = GrammarReducer(eval_mystery, EarleyParser(CONSTRAINED_VAR_GRAMMAR), log_test=True)\n",
    "grammar_reducer.reduce(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_reducer = DeltaDebuggingReducer(eval_mystery, EarleyParser(CONSTRAINED_VAR_GRAMMAR))\n",
    "dd_reducer.reduce(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only does grammar-based reduction need far fewer tests, the reduced result is also smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Lessons Learned\n",
    "\n",
    "* Reducing failure-inducing inputs to a minimum is helpful for testing and debugging.\n",
    "* _Delta Debugging_ is a simple and robust algorithm to easily reduce test cases.\n",
    "* For complex inputs, consider _grammar-based_ reduction instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "_Link to subsequent chapters (notebooks) here, as in:_\n",
    "\n",
    "* [use _mutations_ on existing inputs to get more valid inputs](MutationFuzzer.ipynb)\n",
    "* [use _grammars_ (i.e., a specification of the input format) to get even more valid inputs](Grammars.ipynb)\n",
    "* [reduce _failing inputs_ for efficient debugging](Reducer.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "The delta debugging algorithm discussed here stems from \\cite{Zeller2002}; actually, this is the exact Python implementation as used by Zeller in 2002.  The idea of systematically reducing inputs has been discovered a number of times, although not as  automatic and generic as delta debugging. \\cite{Slutz1998}, for instance, discusses systematic reduction of SQL statements for SQL databases; the general process as manual work is well described by \\cite{Kernighan1999}.\n",
    "\n",
    "\\cite{Herfert2017}\n",
    "\n",
    "\\todo{Discuss hierarchical DD, Csmith / C-reduce}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercises\n",
    "\n",
    "Close the chapter with a few exercises such that people have things to do.  To make the solutions hidden (to be revealed by the user), have them start with\n",
    "\n",
    "```markdown\n",
    "**Solution.**\n",
    "```\n",
    "\n",
    "Your solution can then extend up to the next title (i.e., any markdown cell starting with `#`).\n",
    "\n",
    "Running `make metadata` will automatically add metadata to the cells such that the cells will be hidden by default, and can be uncovered by the user.  The button will be introduced above the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Exercise 1: _Title_\n",
    "\n",
    "_Text of the exercise_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "# Some code that is part of the exercise\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "_Some more text for the exercise_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** _Some text for the solution_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# Some code for the solution\n",
    "2 + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "_Some more text for the solution_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution": "hidden",
    "solution2": "hidden",
    "solution2_first": true,
    "solution_first": true
   },
   "source": [
    "### Exercise 2: _Title_\n",
    "\n",
    "_Text of the exercise_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "solution": "hidden",
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** _Solution for the exercise_"
   ]
  }
 ],
 "metadata": {
  "ipub": {
   "bibliography": "fuzzingbook.bib",
   "toc": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
