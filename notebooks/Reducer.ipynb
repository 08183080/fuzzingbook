{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Reducing Failure-Inducing Inputs\n",
    "\n",
    "By construction, fuzzers create inputs that may be hard to read.  This causes issues during _debugging_, when a human has to analyze the exact cause of the failure.  In this chapter, we present techniques that _automatically reduce and simplify failure-inducing inputs to a minimum_ in order to ease debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Prerequisites**\n",
    "\n",
    "* As reduction is typically used together with fuzzing, reading the [chapter on basic fuzzing](Fuzzer.ipynb) is a good idea.\n",
    "* The simple \"delta debugging\" technique for reduction has no specific prerequisites.\n",
    "* The later grammar-based techniques require knowledge on [derivation trees](GrammarFuzzer.ipynb) and [parsing](Parser.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Why Reducing?\n",
    "\n",
    "At this point, we have seen a number of test generation techniques that all in some form produce input in order to trigger failures.  If they are successful – that is, the program actually fails – we must find out why the failure occurred and how to fix it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Here's an example of such a situation.  We have a class `MysteryRunner` class with a `run()` method that – given its code – can occasionally fail.  But under which circumstances does this actually happen?  We have deliberately obscured the exact condition in order to make this non-obvious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import fuzzingbook_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Fuzzer import RandomFuzzer, Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MysteryRunner(Runner):\n",
    "    def run(self, inp):\n",
    "        x = inp.find(chr(0o17 + 0o31))\n",
    "        y = inp.find(chr(0o27 + 0o22))\n",
    "        if x >= 0 and y >= 0 and x < y:\n",
    "            return (inp, Runner.FAIL)\n",
    "        else:\n",
    "            return (inp, Runner.PASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us fuzz the function until we find a failing input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystery = MysteryRunner()\n",
    "random_fuzzer = RandomFuzzer()\n",
    "while True:\n",
    "    inp = random_fuzzer.fuzz()\n",
    "    result, outcome = mystery.run(inp)\n",
    "    if outcome == mystery.FAIL:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failing_input = result\n",
    "failing_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something in this input causes `MysteryRunner` to fail.  But what is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Manual Input Reduction\n",
    "\n",
    "One important step in the debugging process is _reduction_ – that is, to identify those circumstances of a failure that are relevant for the failure to occur, and to _omit_ (if possible) those parts that are not.  As Kernighan and Pike \\cite{Kernighan1999} put it:\n",
    "\n",
    "> For every circumstance of the problem, check whether it is relevant for the problem to occur.  If it is not, remove it from the problem report or the test case in question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically for inputs, they suggest a _divide and conquer_ process:\n",
    "\n",
    "> Proceed by binary search.  Throw away half the input and see if the output is still wrong; if not, go back to the previous state and discard the other half of the input.\n",
    "\n",
    "This is something we can easily try out.  For instance, we can see whether the error still occurs if we only feed in the first half:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_length = len(failing_input) // 2   # // is integer division\n",
    "first_half = failing_input[:half_length]\n",
    "mystery.run(first_half)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope – the first half alone does not suffice.  Maybe the second half?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_half = failing_input[half_length:]\n",
    "mystery.run(second_half)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This did not go so well either.  We may still proceed by cutting away _smaller chunks_ – say, one character after another.  If our test is deterministic and easily repeated, it is clear that this process eventually will yield a reduced input.  But still, it is a rather inefficient process, especially for long inputs.  What we need is a _strategy_ that effectively minimizes a failure-inducing input – a strategy that can be automated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delta Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One strategy to effectively reduce failure-inducing inputs is _delta debugging_ \\cite{Zeller2002}.  Delta Debugging implements the \"binary search\" strategy, as listed above, but with a twist: If neither half fails (also as above), it keeps on cutting away smaller and smaller chunks from the input, until it eliminates individual characters.  Thus, after cutting away the first half, we cut away\n",
    "the first quarter, the second quarter, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us illustrate this on our example, and see what happens if we cut away the first quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarter_length = len(failing_input) // 4\n",
    "input_without_first_quarter = failing_input[quarter_length:]\n",
    "mystery.run(input_without_first_quarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah! This has failed, and reduced our failing input by 25%.  Let's remove another quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_without_first_and_second_quarter = failing_input[quarter_length * 2:]\n",
    "mystery.run(input_without_first_and_second_quarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not too surprising, as we had that one before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_without_first_and_second_quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about removing the third quarter, then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_without_first_and_third_quarter = failing_input[quarter_length:quarter_length * 2] + failing_input[quarter_length * 3:]\n",
    "mystery.run(input_without_first_and_third_quarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about removing the third quarter, then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_without_first_and_fourth_quarter = failing_input[quarter_length:quarter_length * 3]\n",
    "mystery.run(input_without_first_and_fourth_quarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes!  This has succeeded.  Our input is now 50% smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now tried to remove pieces that make up $\\frac{1}{2}$ and $\\frac{1}{4}$ of the original failing string.  In the next iteration, we would go and remove even smaller pieces – $\\frac{1}{8}$, $\\frac{1}{16}$ and so on.  We continue until we are down to $\\frac{1}{97}$ – that is, individual characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this is comething we happily let a computer do for us.  We first introduce a `Reducer` class as an abstract superclass for all kinds of reducers.  The `test()` methods runs a single test (with logging, if so wanted); the `reduce()` method will eventually reduce an input to the minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reducer(object):\n",
    "    def __init__(self, runner, log=False):\n",
    "        \"\"\"Attach reducer to the given `runner`\"\"\"\n",
    "        self.runner = runner\n",
    "        self.log = log\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.tests = 0\n",
    "\n",
    "    def test(self, inp):\n",
    "        result, outcome = self.runner.run(inp)\n",
    "        self.tests += 1\n",
    "        if self.log:\n",
    "            print(\"Test #%d\" % self.tests, repr(inp), repr(len(inp)), outcome)\n",
    "        return outcome\n",
    "\n",
    "    def reduce(self, inp):\n",
    "        self.reset()\n",
    "        # Default: Don't reduce\n",
    "        return inp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `CachingReducer` variant saves test results, such that we don't have to run the same tests again and again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CachingReducer(Reducer):\n",
    "    def reset(self):\n",
    "        super().reset()\n",
    "        self.cache = {}\n",
    "\n",
    "    def test(self, inp):\n",
    "        if inp in self.cache:\n",
    "            return self.cache[inp]\n",
    "        \n",
    "        outcome = super().test(inp)\n",
    "        self.cache[inp] = outcome\n",
    "        return outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here comes the _Delta Debugging_ reducer.  Delta Debugging implements the strategy sketched above: It first removes larger chunks of size $\\frac{1}{2}$; if this does not fail, then we proceed to chunks of size $\\frac{1}{4}$, then $\\frac{1}{8}$ and so on.\n",
    "\n",
    "Our implementation uses almost the same Python code as Zeller in \\cite{Zeller2011}; the only difference is that it has been adapted to work on Python 3 and our `Runner` framework.    The variable `n` (initially 2) indicates the granularity – in each step, chunks of size $\\frac{1}{n}$ are cut away.  If none of the test fails (`some_complement_is_failing` is False), then `n` is doubled – until it reaches the length of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeltaDebuggingReducer(CachingReducer):\n",
    "    def reduce(self, inp):\n",
    "        self.reset()\n",
    "        assert self.test(inp) == Runner.FAIL\n",
    "\n",
    "        n = 2     # Initial granularity\n",
    "        while len(inp) >= 2:\n",
    "            start = 0\n",
    "            subset_length = len(inp) / n\n",
    "            some_complement_is_failing = False\n",
    "\n",
    "            while start < len(inp):\n",
    "                complement = inp[:int(start)] + inp[int(start + subset_length):]\n",
    "\n",
    "                if self.test(complement) == Runner.FAIL:\n",
    "                    inp = complement\n",
    "                    n = max(n - 1, 2)\n",
    "                    some_complement_is_failing = True\n",
    "                    break\n",
    "\n",
    "                start += subset_length\n",
    "\n",
    "            if not some_complement_is_failing:\n",
    "                if n == len(inp):\n",
    "                    break\n",
    "                n = min(n * 2, len(inp))\n",
    "\n",
    "        return inp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how the `DeltaDebuggingReducer` works, let us run it on our failing input.  With each step, we see how the remaining input gets smaller and smaller, until only two characters remain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_reducer = DeltaDebuggingReducer(mystery, log=True)\n",
    "dd_reducer.reduce(failing_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know why `MysteryRunner` fails – it suffices that the input contains two matching parentheses.  Delta Debugging determines this is 29 steps.  Its result is _1-minimal_, meaning that every character contained is required to produce the error; removing any (as seen in tests `#27` and `#28`, above) no longer makes the test fail.  This property is guaranteed by the delta debugging algorithm, which in its last stage always tries to delete characters one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "A reduced test case such as the one above has many advantages:\n",
    "\n",
    "* A reduced test case __reduces the _cognitive load_ of the programmer__.  The test case is shorter and focused, and thus does not burden the programmer with irrelevant details.  A reduced input typically leads to shorter executions and smaller program states, both of which reduce the search space as it comes to understanding the bug.  In our case, we have eliminated lots of irrelevant input – only the two characters the reduced input contains are relevant.\n",
    "\n",
    "* A reduced test case __is easier to communicate__.  All one needs here is the summary: `MysteryRunner fails on \"()\"`, which is much better than `MysteryRunner fails on a 4100-character input (attached)`.\n",
    "\n",
    "* A reduced test case helps in __identifying duplicates__.  If similar bugs have been reported already, and all of them have been reduced to the same cause (namely that the input contains matching parentheses), then it becomes obvious that all these bugs are different symptoms of the same underlying cause – and would all be resolved at once with one code fix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How effective is delta debugging?  In the best case (wither the left half or the right half fails), the number of tests is logarithmic proportional to the length $n$ of an input (i.e., $O(\\log_2 n)$); this is the same complexity as binary search.  In the worst case, though, delta debugging can require a number of tests proportional to $n^2$  (i.e., $O(n^2)$) – this happens in the case when we are down to character granularity, and we have to repeatedly tried to delete all characters, only to find that deleting the last character results in a failure \\cite{Zeller2002}.  (This is a pretty pathological situation, though.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, delta debugging is a very robust algorithm that is easy to implement, easy to deploy, and easy to use – provided that the underlying test case is deterministic and runs quickly enough to warrant a number of experiments.  As these are the same prerequisites that make fuzzing effective, delta debugging makes an excellent companion to fuzzing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Grammar-Based Input Reduction\n",
    "\n",
    "\\todo{Add}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Parser import PEGParser, parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GrammarFuzzer import all_terminals, expansion_to_children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For logging the queue\n",
    "def queue_to_string(q):\n",
    "    return \"[\" + \", \".join([all_terminals(tree) for tree in q]) + \"]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivation_tree = (\"<start>\",\n",
    "                   [(\"<expr>\",\n",
    "                     [(\"<expr>\", None),\n",
    "                      (\" + \", []),\n",
    "                         (\"<term>\", None)]\n",
    "                     )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue_to_string([derivation_tree, derivation_tree])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Grammars import START_SYMBOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarReducer(Reducer):\n",
    "    def __init__(self, runner, grammar, start_symbol=START_SYMBOL, log=False):\n",
    "        super().__init__(runner, log=log)\n",
    "        self.grammar = grammar\n",
    "        self.start_symbol = start_symbol\n",
    "        self.parser = PEGParser(grammar, start_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarReducer(GrammarReducer):\n",
    "    def derivation_reductions(self, tree):\n",
    "        (symbol, children) = tree\n",
    "        if len(children) == 0:\n",
    "            return []  # Terminal symbol\n",
    "\n",
    "        print(\"Trying alternative expansions for \" + symbol)\n",
    "\n",
    "        # Possible expansions for this symbol\n",
    "        expansions = self.grammar[symbol]\n",
    "        print(\"Expansions: \" + repr(expansions))\n",
    "\n",
    "        alternatives = \\\n",
    "            [expansion_to_children(expansion) for expansion in expansions]\n",
    "\n",
    "        reductions = []\n",
    "        for alternative in alternatives:\n",
    "\n",
    "            if len(alternative) > len(children):\n",
    "                continue  # New alternative has more children\n",
    "\n",
    "            match = True\n",
    "            new_children_reductions = []\n",
    "            # print(\"Trying alternative expansion \" + queue_to_string(alternative))\n",
    "            for alt_child in alternative:\n",
    "                (alt_symbol, _) = alt_child\n",
    "                child_reductions = subtrees_with_symbol(alt_symbol, tree)\n",
    "                if len(child_reductions) == 0:\n",
    "                    # Child not found; cannot apply rule\n",
    "                    match = False\n",
    "                    break\n",
    "\n",
    "                # print(\"Found alternatives \" + queue_to_string(child_reductions))\n",
    "                new_children_reductions.append(child_reductions)\n",
    "\n",
    "            if not match:\n",
    "                continue  # Try next alternative\n",
    "\n",
    "            # Go through the possible combinations\n",
    "            for new_children in possible_combinations(new_children_reductions):\n",
    "                new_tree = (symbol, new_children)\n",
    "\n",
    "                if number_of_nodes(new_tree) >= number_of_nodes(tree):\n",
    "                    continue  # No reduction\n",
    "\n",
    "                reductions.append(new_tree)\n",
    "\n",
    "        # Apply this recursively\n",
    "        if children is not None:\n",
    "            for i in range(0, len(children)):\n",
    "                child = children[i]\n",
    "                child_reductions = self.derivation_reductions(child)\n",
    "                for reduced_child in child_reductions:\n",
    "                    new_children = (children[:i] + \n",
    "                            [reduced_child] +\n",
    "                            children[i + 1:])\n",
    "                    reductions.append((symbol, new_children))\n",
    "\n",
    "        # Filter duplicates\n",
    "        unique_reductions = []\n",
    "        for r in reductions:\n",
    "            if r not in unique_reductions:\n",
    "                unique_reductions.append(r)\n",
    "        reductions = unique_reductions\n",
    "\n",
    "        if len(reductions) > 0:\n",
    "            # We have a new expansion\n",
    "            print(\"Can reduce \" + symbol + \" \" + all_terminals(tree) + \\\n",
    "                 \" to reduced subtrees \" + queue_to_string(reductions))\n",
    "\n",
    "        return reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarReducer(GrammarReducer):\n",
    "    def reductions(self, tree):\n",
    "        return self.derivation_reductions(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarReducer(GrammarReducer):\n",
    "    # Reduce with respect to a given test\n",
    "    def reduce_tree(self, tree):\n",
    "        # Find possible reductions\n",
    "        smallest_tree = tree\n",
    "        tree_reductions = self.reductions(tree)\n",
    "        print(\"Alternatives: \" + queue_to_string(tree_reductions))\n",
    "\n",
    "        while len(tree_reductions) > 0:\n",
    "            t = tree_reductions[0]\n",
    "            tree_reductions = tree_reductions[1:]\n",
    "            s = all_terminals(t)\n",
    "            if self.test(s) == Runner.FAIL:\n",
    "                # Found new smallest tree; try to reduce that one further\n",
    "                smallest_tree = t\n",
    "                tree_reductions = self.reductions(t)\n",
    "                tree_reductions.sort(key = lambda tree: -number_of_nodes(tree))\n",
    "                print(\"New smallest tree: \" + all_terminals(smallest_tree))\n",
    "\n",
    "        return smallest_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarReducer(GrammarReducer):\n",
    "    def parse(self, inp):\n",
    "        cursor, tree = self.parser.unify_key(self.start_symbol, inp) # TODO: Have \"Parser\" base class\n",
    "        print(all_terminals(tree))\n",
    "        return tree\n",
    "\n",
    "    def reduce(self, inp):\n",
    "        tree = self.parse(inp)\n",
    "        smallest_tree = self.reduce_tree(tree)\n",
    "        return all_terminals(smallest_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all subtrees in TREE whose root is SEARCH_SYMBOL.\n",
    "# If IGNORE_ROOT is true, ignore the root note of TREE.\n",
    "def subtrees_with_symbol(search_symbol, tree, ignore_root = True):\n",
    "    ret = []\n",
    "    (symbol, children) = tree\n",
    "    if not ignore_root and symbol == search_symbol:\n",
    "        ret.append(tree)\n",
    "    \n",
    "    # Search across all children\n",
    "    if children is not None:\n",
    "        for c in children:\n",
    "            ret += subtrees_with_symbol(search_symbol, c, False)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a list [[X1, X2], [Y1, Y2], ...] \n",
    "# into [X1, Y1], [X1, Y2], [X2, Y1], [X2, Y2], ...\n",
    "def possible_combinations(list_of_lists):\n",
    "    if len(list_of_lists) == 0:\n",
    "        return []\n",
    "\n",
    "    # print(list_of_lists)\n",
    "\n",
    "    ret = []\n",
    "    for e in list_of_lists[0]:\n",
    "        if len(list_of_lists) == 1:\n",
    "            ret.append([e])\n",
    "        else:\n",
    "            for c in possible_combinations(list_of_lists[1:]):\n",
    "                new_combo = [e] + c\n",
    "                # print(\"New combo: \", repr(new_combo))\n",
    "                ret.append(new_combo)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the number of nodes\n",
    "def number_of_nodes(tree):\n",
    "    (symbol, children) = tree\n",
    "    n = 1\n",
    "    for c in children:\n",
    "        n += number_of_nodes(c)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Grammars import EXPR_GRAMMAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = \"1 + (2 * 3)\"\n",
    "grammar_reducer = GrammarReducer(mystery, EXPR_GRAMMAR)\n",
    "grammar_reducer.reduce(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## _Section 4_\n",
    "\n",
    "\\todo{Add}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Lessons Learned\n",
    "\n",
    "* _Lesson one_\n",
    "* _Lesson two_\n",
    "* _Lesson three_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "_Link to subsequent chapters (notebooks) here, as in:_\n",
    "\n",
    "* [use _mutations_ on existing inputs to get more valid inputs](MutationFuzzer.ipynb)\n",
    "* [use _grammars_ (i.e., a specification of the input format) to get even more valid inputs](Grammars.ipynb)\n",
    "* [reduce _failing inputs_ for efficient debugging](Reducer.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "The delta debugging algorithm discussed here stems from \\cite{Zeller2002}; actually, this is the exact Python implementation as used by Zeller in 2002.  The idea of systematically reducing inputs has been discovered a number of times, although not as  automatic and generic as delta debugging. \\cite{Slutz1998}, for instance, discusses systematic reduction of SQL statements for SQL databases; the general process as manual work is well described by \\cite{Kernighan1999}.\n",
    "\n",
    "\\todo{Add more: hierarchical DD, grammar-based reduction, Csmith / C-reduce}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Exercises\n",
    "\n",
    "Close the chapter with a few exercises such that people have things to do.  To make the solutions hidden (to be revealed by the user), have them start with\n",
    "\n",
    "```markdown\n",
    "**Solution.**\n",
    "```\n",
    "\n",
    "Your solution can then extend up to the next title (i.e., any markdown cell starting with `#`).\n",
    "\n",
    "Running `make metadata` will automatically add metadata to the cells such that the cells will be hidden by default, and can be uncovered by the user.  The button will be introduced above the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Exercise 1: _Title_\n",
    "\n",
    "_Text of the exercise_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "# Some code that is part of the exercise\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "_Some more text for the exercise_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** _Some text for the solution_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# Some code for the solution\n",
    "2 + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "_Some more text for the solution_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "solution": "hidden",
    "solution2": "hidden",
    "solution2_first": true,
    "solution_first": true
   },
   "source": [
    "### Exercise 2: _Title_\n",
    "\n",
    "_Text of the exercise_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "solution": "hidden",
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** _Solution for the exercise_"
   ]
  }
 ],
 "metadata": {
  "ipub": {
   "bibliography": "fuzzingbook.bib",
   "toc": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
