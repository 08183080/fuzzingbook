{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Grammar-based Mutational Fuzzing\n",
    "\\todo{}\n",
    "\n",
    "In this chapter, we are going to expand on what we have learned in the chapters on [blackbox](MutationFuzzer.ipynb) and [greybox](Greybox_Fuzzing.ipynb) mutational fuzzing. Into these mutational fuzzers, we integrate the capability to generate *valid program inputs*. We explore dictionaries, grammars, and structural mutators. \n",
    "\n",
    "This chapter is *self-contained*. Don't worry if you haven't actually read the chapters on mutational fuzzing ðŸ˜Š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Related chapters**\n",
    "\n",
    "* [Blackbox Mutational Fuzzing](MutationFuzzer.ipynb)\n",
    "* [Greybox Mutational Fuzzing](Greybox_Fuzzing.ipynb)\n",
    "* [Grammar-based Generational Fuzzing](Grammars.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import fuzzingbook_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary: Injecting Important Keywords\n",
    "Today, dictionaries are the main mechanism to inform a greybox fuzzer about important keywords in the input.\n",
    "\n",
    "\\todo{}\n",
    "* **Seed**. \\todo{}\n",
    "* **Mutator**. \\todo{}\n",
    "* **PowerSchedule**. \\todo{}\n",
    "* **GreyboxFuzzer**. \\todo{}\n",
    "* **FunctionCoverageRunner**. \\todo{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Greybox_Fuzzing import Mutator, Seed, PowerSchedule, GreyboxFuzzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictMutator(Mutator):\n",
    "    def __init__(self, dictionary):\n",
    "        super().__init__()\n",
    "        self.dictionary = dictionary\n",
    "        self.mutators.append(self.insert_from_dictionary)\n",
    "        \n",
    "    def insert_from_dictionary(self,s):\n",
    "        \"\"\"Returns s with a keyword from the dictionary inserted\"\"\"\n",
    "        pos = random.randint(0, len(s))\n",
    "        random_keyword = random.choice(self.dictionary)\n",
    "        return s[:pos] + random_keyword + s[pos:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create wrapper function\n",
    "def my_parser(inp):\n",
    "    parser = HTMLParser()  # resets the HTMLParser object for every fuzz input\n",
    "    parser.feed(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Greybox_Fuzzing import FunctionCoverageRunner\n",
    "import time, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000\n",
    "seed_input = \" \" # empty seed\n",
    "parser_runner = FunctionCoverageRunner(my_parser)\n",
    "greybox_fuzzer  = GreyboxFuzzer([seed_input], Mutator(), PowerSchedule())\n",
    "\n",
    "start = time.time()\n",
    "greybox_fuzzer.runs(parser_runner, trials=n)\n",
    "end = time.time()\n",
    "\n",
    "\"It took the fuzzer %0.2f seconds to generate and execute %d inputs.\" % (end - start, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=5000\n",
    "html_dict = [\"<a>\",\"</a>\",\"<a/>\", \"='a'\"]\n",
    "dict_fuzzer = GreyboxFuzzer([seed_input], DictMutator(html_dict), PowerSchedule())\n",
    "start = time.time()\n",
    "dict_fuzzer.runs(parser_runner, trials=n)\n",
    "end = time.time()\n",
    "\n",
    "\"It took the fuzzer %0.2f seconds to generate and execute %d inputs.\" % (end - start, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the fuzzers compare in terms of coverage over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Coverage import population_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, dict_coverage = population_coverage(dict_fuzzer.inputs, my_parser)\n",
    "_, greybox_coverage = population_coverage(greybox_fuzzer.inputs, my_parser)\n",
    "line_dict, = plt.plot(dict_coverage, label=\"With Dictionary\")\n",
    "line_greybox, = plt.plot(greybox_coverage, label=\"Without Dictionary\")\n",
    "plt.legend(handles=[line_dict, line_greybox])\n",
    "plt.xlim(0,n)\n",
    "plt.title('Coverage over time')\n",
    "plt.xlabel('# of inputs')\n",
    "plt.ylabel('lines covered')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural Mutation of Valid Seeds\n",
    "\\todo{} \n",
    "\n",
    "This allows to _mutate_ existing inputs while preserving syntactical correctness, and to _reuse_ fragments from existing inputs while generating new ones.  The combination of parsing and fuzzing, as demonstrated in this chapter, has been highly successful in practice: The _LangFuzz_ fuzzer for JavaScript has found more than 2,600 bugs in JavaScript interpreters this way.\n",
    "\n",
    "Recombining parsed inputs was pioneered by _Langfuzz_ \\cite{Holler2012}. The main challenge is that program inputs often carry additional constraints beyond what is described by the syntax. For example, in Java, one needs to declare a variable (using a specific format for declaration) before it can be used in an expression. This restriction is not captured in the _Java CFG_. Checking for type correctness is another example for additional restrictions carried by program definitions.\n",
    "\n",
    "When fuzzing compilers and interpreters, naive generation of programs using the language *CFG* often fails to achieve significant deeper coverage due to these kinds of checks external to the grammar. Holler et al. suggests using pre-existing valid code fragments to get around these restrictions. The idea is that the pre-existing valid code fragments already conform to the restrictions external to the grammar, and can often provide a means to evade validity checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from Grammars import is_valid_grammar, srange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\todo{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XML_TOKENS = {\"<id>\",\"<text>\"}\n",
    "\n",
    "XML_GRAMMAR = {\n",
    "    \"<start>\": [\"<xml-tree>\"],\n",
    "    \"<xml-tree>\": [\"<text>\",\n",
    "                   \"<xml-open-tag><xml-tree><xml-close-tag>\", \n",
    "                   \"<xml-openclose-tag>\", \n",
    "                   \"<xml-tree><xml-tree>\"],\n",
    "    \"<xml-open-tag>\":      [\"<<id>>\", \"<<id> <xml-attribute>>\"],\n",
    "    \"<xml-openclose-tag>\": [\"<<id>/>\", \"<<id> <xml-attribute>/>\"],\n",
    "    \"<xml-close-tag>\":     [\"</<id>>\"],\n",
    "    \"<xml-attribute>\" :    [\"<id>=<id>\", \"<xml-attribute> <xml-attribute>\"],\n",
    "    \"<id>\":                [\"<letter>\", \"<id><letter>\"],\n",
    "    \"<text>\" :             [\"<text><letter_space>\",\"<letter_space>\"],\n",
    "    \"<letter>\":            srange(string.ascii_letters + string.digits +\"\\\"\"+\"'\"+\".\"),\n",
    "    \"<letter_space>\":      srange(string.ascii_letters + string.digits +\"\\\"\"+\"'\"+\" \"+\"\\t\"),\n",
    "}\n",
    "\n",
    "assert is_valid_grammar(XML_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Parser import EarleyParser\n",
    "from GrammarFuzzer import display_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = EarleyParser(XML_GRAMMAR, tokens=XML_TOKENS)\n",
    "\n",
    "for tree in parser.parse(\"<html>Text</html>\"):\n",
    "    display_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Parser import terminals\n",
    "import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timeout(Exception):\n",
    "    pass\n",
    "def timeout(signum, frame):\n",
    "    raise Timeout()\n",
    "    \n",
    "signal.signal(signal.SIGALRM, timeout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartMutator(Mutator):\n",
    "    \n",
    "    def __init__(self, parser):\n",
    "        self.parser = parser\n",
    "        # Init each symbol in fragments dict w/ empty set\n",
    "        self.fragments = {k: [] for k in self.parser.cgrammar}\n",
    "        super().__init__()\n",
    "        \n",
    "    def is_excluded(self, symbol):\n",
    "        return ((not symbol in self.parser.grammar()) or\n",
    "                symbol in self.parser.tokens or\n",
    "                symbol in terminals(self.parser.grammar()))\n",
    "    \n",
    "    def add_fragment(self, structure):\n",
    "        (symbol, children) = structure\n",
    "        if not self.is_excluded(symbol):\n",
    "            self.fragments[symbol].append(structure)\n",
    "            for substructure in children:\n",
    "                self.add_fragment(substructure)\n",
    "\n",
    "    def add_to_fragment_pool(self, seed):\n",
    "        try: # only allow quick parsing of 200ms\n",
    "            signal.setitimer(signal.ITIMER_REAL, 0.2)\n",
    "            seed.structure = next(self.parser.parse(seed.data))\n",
    "            signal.setitimer(signal.ITIMER_REAL, 0)\n",
    "            \n",
    "            self.add_fragment(seed.structure)\n",
    "            seed.has_structure = True\n",
    "        except (SyntaxError, Timeout):\n",
    "            seed.has_structure = False\n",
    "            signal.setitimer(signal.ITIMER_REAL, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GrammarFuzzer import tree_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.parse(\"<b>Text</b>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_seed = Seed(\"<b>Text</b>\")\n",
    "parser = EarleyParser(XML_GRAMMAR, tokens=XML_TOKENS)\n",
    "smart_mutator = SmartMutator(parser)\n",
    "smart_mutator.add_to_fragment_pool(simple_seed)\n",
    "for key in smart_mutator.fragments:\n",
    "    print(key)\n",
    "    for f in smart_mutator.fragments[key]:\n",
    "        print(\"|-%s\" % tree_to_string(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartMutator(SmartMutator):\n",
    "    def __init__(self, parser):\n",
    "        super().__init__(parser)\n",
    "        self.mutators = [self.swap_substructure]\n",
    "        self.seen_seeds = []\n",
    "    \n",
    "    def count_nodes(self, structure):\n",
    "        symbol, children = structure\n",
    "        if self.is_excluded(symbol):\n",
    "            return 0\n",
    "        return 1 + sum(map(self.count_nodes, children))\n",
    "        \n",
    "    def swap_substructure(self, seed):\n",
    "        if seed.has_structure:\n",
    "            n_nodes = self.count_nodes(seed.structure)\n",
    "            self.to_swap = random.randint(2, n_nodes)\n",
    "\n",
    "            def recursive_swap(structure):\n",
    "                symbol, children = structure\n",
    "                if self.is_excluded(symbol):\n",
    "                    return symbol, children\n",
    "            \n",
    "                self.to_swap -= 1\n",
    "                if self.to_swap == 0: \n",
    "                    return random.choice(list(self.fragments[symbol]))\n",
    "                return symbol, list(map(recursive_swap, children))\n",
    "            new_structure = recursive_swap(seed.structure)\n",
    "            new_seed = Seed(tree_to_string(new_structure))\n",
    "            new_seed.has_structure = True\n",
    "            new_seed.structure = new_structure\n",
    "            return new_seed\n",
    "        return seed\n",
    "    \n",
    "    def mutate(self, seed):\n",
    "        if not seed in self.seen_seeds:\n",
    "            self.seen_seeds.append(seed)\n",
    "            self.add_to_fragment_pool(seed)\n",
    "        return super().mutate(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_seed = Seed(\"<html><header><title>Hello</title></header><body>World<br/></body></html>\")\n",
    "smart_mutator = SmartMutator(parser)\n",
    "smart_mutator.mutate(valid_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartMutator(SmartMutator):\n",
    "    def __init__(self, parser):\n",
    "        super().__init__(parser)\n",
    "        self.mutators.append(self.delete_substructure)\n",
    "    \n",
    "    def delete_substructure(self, seed):\n",
    "        if seed.has_structure:\n",
    "            n_nodes = self.count_nodes(seed.structure)\n",
    "            self.to_delete = random.randint(2, n_nodes)\n",
    "        \n",
    "            def recursive_delete(structure):\n",
    "                symbol, children = structure\n",
    "                if self.is_excluded(symbol):\n",
    "                    return symbol, children\n",
    "            \n",
    "                self.to_delete -= 1\n",
    "                if self.to_delete == 0: \n",
    "                    return symbol, []\n",
    "                return symbol, list(map(recursive_delete, children))\n",
    "            new_structure = recursive_delete(seed.structure)\n",
    "            new_seed = Seed(tree_to_string(new_structure))\n",
    "            new_seed.has_structure = True\n",
    "            new_seed.structure = new_structure\n",
    "            # do not return an empty new_seed\n",
    "            if not new_seed.data: return seed\n",
    "            else: return new_seed\n",
    "        return seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartGreyboxFuzzer(GreyboxFuzzer):\n",
    "    def __init__(self, seeds, dumb_mutator, smart_mutator, schedule):\n",
    "        super().__init__(seeds, dumb_mutator, schedule)\n",
    "        self.smart_mutator = smart_mutator\n",
    "    \n",
    "    def create_candidate(self):\n",
    "        \"\"\"Returns an input generated by structural mutation of a seed in the population\"\"\"\n",
    "        seed = self.schedule.choose(self.population)\n",
    "        smart_trials = 1 << random.randint(0,2)\n",
    "        for i in range(smart_trials):\n",
    "            seed = self.smart_mutator.mutate(seed)\n",
    "        \n",
    "        # Unstructured mutation\n",
    "        candidate = seed.data\n",
    "        if not seed.has_structure or 1 == random.randint(0, 1):\n",
    "            dumb_trials = min(len(seed.data), 1 << random.randint(1,5))\n",
    "            for i in range(dumb_trials):\n",
    "                candidate = self.mutator.mutate(candidate)\n",
    "        return candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonMutator(Mutator):\n",
    "    def mutate(self, inp):\n",
    "        return inp\n",
    "    \n",
    "n = 300\n",
    "dumb_mutator = NonMutator()\n",
    "smart_mutator = SmartMutator(EarleyParser(XML_GRAMMAR, tokens=XML_TOKENS))\n",
    "smart_greybox_fuzzer = SmartGreyboxFuzzer([valid_seed.data],\n",
    "                                          dumb_mutator,\n",
    "                                          smart_mutator, \n",
    "                                          PowerSchedule())\n",
    "start = time.time()\n",
    "smart_greybox_fuzzer.runs(parser_runner, trials=n)\n",
    "end = time.time()\n",
    "\n",
    "\"It took the smart greybox fuzzer %0.2f seconds to generate and execute %d inputs.\" % (end - start, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(fuzzer):\n",
    "    has_structure = 0\n",
    "    for seed in fuzzer.population:\n",
    "        if hasattr(seed, \"has_structure\") and seed.has_structure:\n",
    "            has_structure += 1\n",
    "\n",
    "    print(\"From the %d seeds in the population, %d (%0.2f%%) can be parsed.\" % (\n",
    "        len(fuzzer.population),\n",
    "        has_structure,\n",
    "        100 * has_structure / len(fuzzer.population)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stats(smart_greybox_fuzzer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\todo{Summary. High validity, small population}\n",
    "\n",
    "## Structural Mutation of Invalid Seeds\n",
    "\\todo{partial parsing}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_seed = Seed(\"<html><body><i>World</i><br/>>/body></html>\")\n",
    "table = parser.chart_parse(invalid_seed.data, parser.start_symbol())\n",
    "for column in table:\n",
    "    print(column)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in table if col.states]\n",
    "parsable = invalid_seed.data[:len(cols)-1]\n",
    "validity = 100 * len(parsable) / len(invalid_seed.data)\n",
    "\n",
    "\"This much could be parsed successfully: %s (%0.1f%%)\" % (parsable, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartMutator(SmartMutator):\n",
    "    def add_to_fragment_pool(self, seed):\n",
    "        super().add_to_fragment_pool(seed)\n",
    "        if not seed.has_structure:\n",
    "            try:\n",
    "                signal.setitimer(signal.ITIMER_REAL, 0.2) # set 500ms timeout\n",
    "                seed.regions = {k: set() for k in self.parser.cgrammar}\n",
    "                for column in self.parser.chart_parse(seed.data, self.parser.start_symbol()):\n",
    "                    for state in column.states:\n",
    "                        if (not self.is_excluded(state.name) and\n",
    "                                state.e_col.index - state.s_col.index > 1 and\n",
    "                                state.finished()):\n",
    "                            seed.regions[state.name].add((state.s_col.index, state.e_col.index))\n",
    "                signal.setitimer(signal.ITIMER_REAL, 0) # cancel timeout\n",
    "                seed.has_regions = True\n",
    "            except Timeout:\n",
    "                seed.has_regions = False\n",
    "        else:\n",
    "            seed.has_regions = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_mutator = SmartMutator(parser)\n",
    "smart_mutator.add_to_fragment_pool(invalid_seed)\n",
    "for key in invalid_seed.regions:\n",
    "    print(key)\n",
    "    for (s,e) in invalid_seed.regions[key]:\n",
    "        print(\"|-(%d,%d) : %s\" % (s, e, invalid_seed.data[s:e]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartMutator(SmartMutator):\n",
    "    \n",
    "    def swap_substructure(self, seed):\n",
    "        if not seed.has_structure and seed.has_regions:\n",
    "            regions = [r for r in seed.regions\n",
    "                         if (len(seed.regions[r]) > 0 and\n",
    "                            len(self.fragments[r]) > 0)]\n",
    "            if len(regions) == 0: return seed\n",
    "                \n",
    "            key = random.choice(list(regions))\n",
    "            s, e = random.choice(list(seed.regions[key]))\n",
    "            swap_structure = random.choice(self.fragments[key])\n",
    "            swap_string = tree_to_string(swap_structure)\n",
    "            new_seed = Seed(seed.data[:s] + swap_string + seed.data[e:])\n",
    "            new_seed.has_structure = False\n",
    "            new_seed.has_regions = False\n",
    "            return new_seed\n",
    "        else:\n",
    "            return super().swap_substructure(seed)\n",
    "        \n",
    "    def delete_substructure(self, seed):\n",
    "        if not seed.has_structure and seed.has_regions:\n",
    "            regions = [r for r in seed.regions\n",
    "                         if len(seed.regions[r]) > 0]\n",
    "            if len(regions) == 0: return seed\n",
    "\n",
    "            key = random.choice(list(regions))\n",
    "            s, e = random.choice(list(seed.regions[key]))\n",
    "            new_seed = Seed(seed.data[:s] + seed.data[e:])\n",
    "            new_seed.has_structure = False\n",
    "            new_seed.has_regions = False\n",
    "            return new_seed\n",
    "        else:\n",
    "            return super().delete_substructure(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_mutator = SmartMutator(parser)\n",
    "smart_mutator.add_to_fragment_pool(simple_seed)\n",
    "smart_mutator.mutate(invalid_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1000\n",
    "\n",
    "#seed1 = \"<a><b>f</b><d c=e>g</d></a>\"\n",
    "seed1 = \"<html a=b>Hi</html>\"\n",
    "dumb_mutator = Mutator()\n",
    "parser = EarleyParser(XML_GRAMMAR, tokens=XML_TOKENS)\n",
    "smarter_mutator = SmartMutator(parser)\n",
    "smarter_greybox_fuzzer = SmartGreyboxFuzzer([seed1],\n",
    "                                            dumb_mutator,\n",
    "                                            smarter_mutator, \n",
    "                                            PowerSchedule())\n",
    "start = time.time()\n",
    "smarter_greybox_fuzzer.runs(parser_runner, trials=n)\n",
    "end = time.time()\n",
    "\n",
    "\"It took the smarter greybox fuzzer %0.2f seconds to generate and execute %d inputs.\" % (end - start, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_more_stats(fuzzer, parser):\n",
    "    print_stats(fuzzer)\n",
    "    validity = 0\n",
    "    total = 0\n",
    "    for seed in fuzzer.population:\n",
    "        if not seed.data: continue\n",
    "        table = parser.chart_parse(seed.data, parser.start_symbol())\n",
    "        cols = [col for col in table if col.states]\n",
    "        parsable = invalid_seed.data[:len(cols)-1]\n",
    "        validity += len(parsable) / len(seed.data)\n",
    "        total += 1\n",
    "    print(\"On average, %0.1f%% of a seed in the population can be successfully parsed.\" % (100 * validity / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_more_stats(smarter_greybox_fuzzer, parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\todo{Summary. Lower validity but larger population.}\n",
    "\n",
    "\\todo{Try it. Deferred parsing.}\n",
    "\n",
    "## Validity-based Power Schedule\n",
    "\\todo{degree of validity, deferred parsing}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class AFLSmartSchedule(PowerSchedule):\n",
    "    \n",
    "    def __init__(self, parser, exponent):\n",
    "        self.parser = parser\n",
    "        self.exponent = exponent\n",
    "    \n",
    "    def parsable(self, seed):\n",
    "        table = self.parser.chart_parse(seed.data, parser.start_symbol())\n",
    "        cols = [col for col in table if col.states]\n",
    "        return seed.data[:len(cols)-1]\n",
    "    \n",
    "    def degree_of_validity(self, seed):\n",
    "        if hasattr(seed, \"validity\"): return seed.validity\n",
    "        seed.validity = (len(self.parsable(seed)) / len(seed.data)\n",
    "                         if len(seed.data) > 0 else 0)\n",
    "        return seed.validity\n",
    "    \n",
    "    def assignEnergy(self, population):\n",
    "        \"\"\"Assign exponential energy proportional to degree of validity\"\"\"\n",
    "        for seed in population:\n",
    "            seed.energy = ((self.degree_of_validity(seed) / math.log(len(seed.data))) ** self.exponent\n",
    "                           if len(seed.data) > 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_schedule = AFLSmartSchedule(parser, 1)\n",
    "print(\"%11s: %s\" % (\"Entire seed\", simple_seed))\n",
    "print(\"%11s: %s\" % (\"Parsable\", smart_schedule.parsable(simple_seed)))\n",
    "\n",
    "\"Degree of validity: %0.2f%%\" % (100 * smart_schedule.degree_of_validity(simple_seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%11s: %s\" % (\"Entire seed\", invalid_seed))\n",
    "print(\"%11s: %s\" % (\"Parsable\", smart_schedule.parsable(invalid_seed)))\n",
    "\n",
    "\"Degree of validity: %0.2f%%\" % (100 * smart_schedule.degree_of_validity(invalid_seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1000\n",
    "\n",
    "seed1 = \"<d c=e>g</d>\"\n",
    "\n",
    "dumb_mutator = Mutator()\n",
    "parser = EarleyParser(XML_GRAMMAR, tokens=XML_TOKENS)\n",
    "aflsmart_mutator = SmartMutator(parser)\n",
    "aflsmart_schedule = AFLSmartSchedule(parser, 1)\n",
    "aflsmart_greybox_fuzzer = SmartGreyboxFuzzer([seed1],\n",
    "                                            dumb_mutator,\n",
    "                                            aflsmart_mutator, \n",
    "                                            aflsmart_schedule)\n",
    "start = time.time()\n",
    "aflsmart_greybox_fuzzer.runs(parser_runner, trials=n)\n",
    "end = time.time()\n",
    "\n",
    "\"It took the aflsmart greybox fuzzer %0.2f seconds to generate and execute %d inputs.\" % (end - start, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_more_stats(aflsmart_greybox_fuzzer, parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\todo{Summary. Maximize validity and coverage}\n",
    "\n",
    "\\todo{Reference [AFLSmart](https://github.com/aflsmart/aflsmart) and \"[Smart Greybox Fuzzing](https://arxiv.org/abs/1811.09447)\" \\cite{aflsmart}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lessons Learned\n",
    "\n",
    "* We can generate a pool of fragments using the _LangFuzz_ approach, and use it to generate nearly valid strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "* In the [chapter on evolutionary fuzzing](EvoGrammarFuzzer.ipynb), we discuss how to systematically evolve a population of inputs through mutation and crossover operations (as discussed in this chapter) to achieve a specific goal such as code coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Background\n",
    "\n",
    "Recombining parsed inputs was pioneered by _Langfuzz_ \\cite{Holler2012}, which also gave its name to the main class of this chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": true,
    "run_control": {
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "\\todo{}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "source": [
    "**Solution.** \\todo{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "solution2": "hidden"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "solution2": "hidden"
   },
   "source": [
    "With these changes, our `LangFuzzer2` is able to use the pool of fragments when necessary, but can rely on the grammar when the pool is not sufficient."
   ]
  }
 ],
 "metadata": {
  "ipub": {
   "bibliography": "fuzzingbook.bib",
   "toc": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
